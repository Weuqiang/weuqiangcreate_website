"use strict";(globalThis.webpackChunkweuqiangcreate_website=globalThis.webpackChunkweuqiangcreate_website||[]).push([[4571],{6970(n,e,s){s.r(e),s.d(e,{assets:()=>d,contentTitle:()=>r,default:()=>o,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"\u4eba\u5de5\u667a\u80fd/\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357","title":"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357","description":"\u6df1\u5165\u7406\u89e3\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u539f\u7406\u3001\u5b9e\u73b0\u7ec6\u8282\u548c\u5b9e\u9645\u5e94\u7528\u3002","source":"@site/docs/docs/\u4eba\u5de5\u667a\u80fd/\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357.mdx","sourceDirName":"\u4eba\u5de5\u667a\u80fd","slug":"/\u4eba\u5de5\u667a\u80fd/\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":18,"frontMatter":{"sidebar_position":18,"title":"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357"},"sidebar":"tutorialSidebar","previous":{"title":"OpenClaw\u5b9e\u6218\u6307\u5357","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/OpenClaw\u5b9e\u6218\u6307\u5357"},"next":{"title":"\u673a\u5668\u5b66\u4e60","permalink":"/weuqiangcreate_website/docs/\u673a\u5668\u5b66\u4e60/"}}');var t=s(74848),a=s(28453);const l={sidebar_position:18,title:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357"},r="\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357",d={},c=[{value:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5b8c\u6574\u6280\u672f\u6587\u6863",id:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5b8c\u6574\u6280\u672f\u6587\u6863",level:2},{value:"\u7406\u8bba\u57fa\u7840",id:"\u7406\u8bba\u57fa\u7840",level:3},{value:"1. \u751f\u7269\u5b66\u7075\u611f",id:"1-\u751f\u7269\u5b66\u7075\u611f",level:4},{value:"2. \u6838\u5fc3\u6570\u5b66\u539f\u7406",id:"2-\u6838\u5fc3\u6570\u5b66\u539f\u7406",level:4},{value:"\u5b8c\u6574\u5b9e\u73b0",id:"\u5b8c\u6574\u5b9e\u73b0",level:3},{value:"1. \u6db2\u6001\u795e\u7ecf\u5143",id:"1-\u6db2\u6001\u795e\u7ecf\u5143",level:4},{value:"2. \u5b8c\u6574\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc",id:"2-\u5b8c\u6574\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc",level:4},{value:"\u9ad8\u7ea7\u7279\u6027",id:"\u9ad8\u7ea7\u7279\u6027",level:3},{value:"1. \u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f",id:"1-\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f",level:4},{value:"2. \u7a00\u758f\u8fde\u63a5",id:"2-\u7a00\u758f\u8fde\u63a5",level:4},{value:"\u5b9e\u6218\u6848\u4f8b1\uff1a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b",id:"\u5b9e\u6218\u6848\u4f8b1\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b",level:2},{value:"\u5b9e\u6218\u6848\u4f8b2\uff1a\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236",id:"\u5b9e\u6218\u6848\u4f8b2\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236",level:2},{value:"\u5b9e\u6218\u6848\u4f8b3\uff1a\u673a\u5668\u4eba\u63a7\u5236",id:"\u5b9e\u6218\u6848\u4f8b3\u673a\u5668\u4eba\u63a7\u5236",level:2},{value:"\u6027\u80fd\u5206\u6790",id:"\u6027\u80fd\u5206\u6790",level:2},{value:"1. \u53c2\u6570\u6548\u7387\u5bf9\u6bd4",id:"1-\u53c2\u6570\u6548\u7387\u5bf9\u6bd4",level:3},{value:"2. \u63a8\u7406\u901f\u5ea6\u5bf9\u6bd4",id:"2-\u63a8\u7406\u901f\u5ea6\u5bf9\u6bd4",level:3},{value:"\u53ef\u89c6\u5316\u5de5\u5177",id:"\u53ef\u89c6\u5316\u5de5\u5177",level:2},{value:"\u5b66\u4e60\u8d44\u6e90",id:"\u5b66\u4e60\u8d44\u6e90",level:2},{value:"\u8bba\u6587",id:"\u8bba\u6587",level:3},{value:"\u4ee3\u7801\u5e93",id:"\u4ee3\u7801\u5e93",level:3},{value:"\u5e94\u7528\u6848\u4f8b",id:"\u5e94\u7528\u6848\u4f8b",level:3},{value:"\u603b\u7ed3",id:"\u603b\u7ed3",level:2}];function h(n){const e={a:"a",admonition:"admonition",annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",math:"math",mfrac:"mfrac",mi:"mi",mo:"mo",mrow:"mrow",msub:"msub",ol:"ol",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...n.components},{DocCardList:s}=e;return s||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357",children:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u6df1\u5ea6\u6307\u5357"})}),"\n",(0,t.jsx)(e.admonition,{title:"\u5b66\u4e60\u76ee\u6807",type:"info",children:(0,t.jsx)(e.p,{children:"\u6df1\u5165\u7406\u89e3\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u7684\u6570\u5b66\u539f\u7406\u3001\u5b9e\u73b0\u7ec6\u8282\u548c\u5b9e\u9645\u5e94\u7528\u3002"})}),"\n",(0,t.jsx)(e.h2,{id:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5b8c\u6574\u6280\u672f\u6587\u6863",children:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5b8c\u6574\u6280\u672f\u6587\u6863"}),"\n",(0,t.jsx)(e.h3,{id:"\u7406\u8bba\u57fa\u7840",children:"\u7406\u8bba\u57fa\u7840"}),"\n",(0,t.jsx)(e.h4,{id:"1-\u751f\u7269\u5b66\u7075\u611f",children:"1. \u751f\u7269\u5b66\u7075\u611f"}),"\n",(0,t.jsx)(e.p,{children:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\uff08LNN\uff09\u7684\u7075\u611f\u6765\u81ea**\u79c0\u4e3d\u9690\u6746\u7ebf\u866b\uff08C. elegans\uff09**\u7684\u795e\u7ecf\u7cfb\u7edf\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u4ec5\u6709302\u4e2a\u795e\u7ecf\u5143"}),"\n",(0,t.jsx)(e.li,{children:"\u80fd\u591f\u5b8c\u6210\u590d\u6742\u7684\u884c\u4e3a\uff08\u89c5\u98df\u3001\u4ea4\u914d\u3001\u9003\u907f\uff09"}),"\n",(0,t.jsx)(e.li,{children:"\u795e\u7ecf\u5143\u4e4b\u95f4\u7684\u8fde\u63a5\u662f\u52a8\u6001\u7684"}),"\n"]}),"\n",(0,t.jsx)(e.h4,{id:"2-\u6838\u5fc3\u6570\u5b66\u539f\u7406",children:"2. \u6838\u5fc3\u6570\u5b66\u539f\u7406"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u795e\u7ecf\u5143"}),"\uff1a"]}),"\n",(0,t.jsx)(e.span,{className:"katex-display",children:(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"\u03c4"}),(0,t.jsxs)(e.mfrac,{children:[(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"d"}),(0,t.jsx)(e.mi,{children:"h"})]}),(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"d"}),(0,t.jsx)(e.mi,{children:"t"})]})]}),(0,t.jsx)(e.mo,{children:"="}),(0,t.jsx)(e.mo,{children:"\u2212"}),(0,t.jsx)(e.mi,{children:"h"}),(0,t.jsx)(e.mo,{children:"+"}),(0,t.jsx)(e.mi,{children:"f"}),(0,t.jsx)(e.mo,{stretchy:"false",children:"("}),(0,t.jsxs)(e.msub,{children:[(0,t.jsx)(e.mi,{children:"W"}),(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"i"}),(0,t.jsx)(e.mi,{children:"n"})]})]}),(0,t.jsx)(e.mi,{children:"x"}),(0,t.jsx)(e.mo,{children:"+"}),(0,t.jsxs)(e.msub,{children:[(0,t.jsx)(e.mi,{children:"W"}),(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"r"}),(0,t.jsx)(e.mi,{children:"e"}),(0,t.jsx)(e.mi,{children:"c"})]})]}),(0,t.jsx)(e.mi,{children:"h"}),(0,t.jsx)(e.mo,{children:"+"}),(0,t.jsx)(e.mi,{children:"b"}),(0,t.jsx)(e.mo,{stretchy:"false",children:")"})]}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\tau \\frac{dh}{dt} = -h + f(W_{in}x + W_{rec}h + b)"})]})})}),(0,t.jsxs)(e.span,{className:"katex-html","aria-hidden":"true",children:[(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"2.0574em",verticalAlign:"-0.686em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.1132em"},children:"\u03c4"}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mopen nulldelimiter"}),(0,t.jsx)(e.span,{className:"mfrac",children:(0,t.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,t.jsxs)(e.span,{className:"vlist-r",children:[(0,t.jsxs)(e.span,{className:"vlist",style:{height:"1.3714em"},children:[(0,t.jsxs)(e.span,{style:{top:"-2.314em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",children:"d"}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"t"})]})]}),(0,t.jsxs)(e.span,{style:{top:"-3.23em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,t.jsx)(e.span,{className:"frac-line",style:{borderBottomWidth:"0.04em"}})]}),(0,t.jsxs)(e.span,{style:{top:"-3.677em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"3em"}}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",children:"d"}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"h"})]})]})]}),(0,t.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,t.jsx)(e.span,{className:"vlist-r",children:(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.686em"},children:(0,t.jsx)(e.span,{})})})]})}),(0,t.jsx)(e.span,{className:"mclose nulldelimiter"})]}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,t.jsx)(e.span,{className:"mrel",children:"="}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.7778em",verticalAlign:"-0.0833em"}}),(0,t.jsx)(e.span,{className:"mord",children:"\u2212"}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"h"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,t.jsx)(e.span,{className:"mbin",children:"+"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,t.jsx)(e.span,{className:"mopen",children:"("}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"W"}),(0,t.jsx)(e.span,{className:"msupsub",children:(0,t.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,t.jsxs)(e.span,{className:"vlist-r",children:[(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.3117em"},children:(0,t.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(e.span,{className:"mord mtight",children:(0,t.jsx)(e.span,{className:"mord mathnormal mtight",children:"in"})})})]})}),(0,t.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,t.jsx)(e.span,{className:"vlist-r",children:(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,t.jsx)(e.span,{})})})]})})]}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"x"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,t.jsx)(e.span,{className:"mbin",children:"+"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.8444em",verticalAlign:"-0.15em"}}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"W"}),(0,t.jsx)(e.span,{className:"msupsub",children:(0,t.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,t.jsxs)(e.span,{className:"vlist-r",children:[(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,t.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(e.span,{className:"mord mtight",children:(0,t.jsx)(e.span,{className:"mord mathnormal mtight",children:"rec"})})})]})}),(0,t.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,t.jsx)(e.span,{className:"vlist-r",children:(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,t.jsx)(e.span,{})})})]})})]}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"h"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}}),(0,t.jsx)(e.span,{className:"mbin",children:"+"}),(0,t.jsx)(e.span,{className:"mspace",style:{marginRight:"0.2222em"}})]}),(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"b"}),(0,t.jsx)(e.span,{className:"mclose",children:")"})]})]})]})}),"\n",(0,t.jsx)(e.p,{children:"\u5176\u4e2d\uff1a"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsx)(e.mi,{children:"h"})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"h"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"h"})]})})]}),": \u9690\u85cf\u72b6\u6001"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsx)(e.mi,{children:"\u03c4"})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\tau"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.1132em"},children:"\u03c4"})]})})]}),": \u65f6\u95f4\u5e38\u6570\uff08\u53ef\u5b66\u4e60\uff09"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsx)(e.mi,{children:"f"})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"f"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.8889em",verticalAlign:"-0.1944em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"})]})})]}),": \u6fc0\u6d3b\u51fd\u6570"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsxs)(e.msub,{children:[(0,t.jsx)(e.mi,{children:"W"}),(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"i"}),(0,t.jsx)(e.mi,{children:"n"})]})]})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"W_{in}"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"W"}),(0,t.jsx)(e.span,{className:"msupsub",children:(0,t.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,t.jsxs)(e.span,{className:"vlist-r",children:[(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.3117em"},children:(0,t.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(e.span,{className:"mord mtight",children:(0,t.jsx)(e.span,{className:"mord mathnormal mtight",children:"in"})})})]})}),(0,t.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,t.jsx)(e.span,{className:"vlist-r",children:(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,t.jsx)(e.span,{})})})]})})]})]})})]}),": \u8f93\u5165\u6743\u91cd"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsxs)(e.msub,{children:[(0,t.jsx)(e.mi,{children:"W"}),(0,t.jsxs)(e.mrow,{children:[(0,t.jsx)(e.mi,{children:"r"}),(0,t.jsx)(e.mi,{children:"e"}),(0,t.jsx)(e.mi,{children:"c"})]})]})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"W_{rec}"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.15em"}}),(0,t.jsxs)(e.span,{className:"mord",children:[(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.13889em"},children:"W"}),(0,t.jsx)(e.span,{className:"msupsub",children:(0,t.jsxs)(e.span,{className:"vlist-t vlist-t2",children:[(0,t.jsxs)(e.span,{className:"vlist-r",children:[(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.1514em"},children:(0,t.jsxs)(e.span,{style:{top:"-2.55em",marginLeft:"-0.1389em",marginRight:"0.05em"},children:[(0,t.jsx)(e.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(e.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(e.span,{className:"mord mtight",children:(0,t.jsx)(e.span,{className:"mord mathnormal mtight",children:"rec"})})})]})}),(0,t.jsx)(e.span,{className:"vlist-s",children:"\u200b"})]}),(0,t.jsx)(e.span,{className:"vlist-r",children:(0,t.jsx)(e.span,{className:"vlist",style:{height:"0.15em"},children:(0,t.jsx)(e.span,{})})})]})})]})]})})]}),": \u5faa\u73af\u6743\u91cd"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsx)(e.mi,{children:"b"})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"b"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.6944em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",children:"b"})]})})]}),": \u504f\u7f6e"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u5173\u952e\u7279\u6027"}),"\uff1a"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsxs)(e.strong,{children:["\u65f6\u95f4\u5e38\u6570 ",(0,t.jsxs)(e.span,{className:"katex",children:[(0,t.jsx)(e.span,{className:"katex-mathml",children:(0,t.jsx)(e.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(e.semantics,{children:[(0,t.jsx)(e.mrow,{children:(0,t.jsx)(e.mi,{children:"\u03c4"})}),(0,t.jsx)(e.annotation,{encoding:"application/x-tex",children:"\\tau"})]})})}),(0,t.jsx)(e.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(e.span,{className:"base",children:[(0,t.jsx)(e.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(e.span,{className:"mord mathnormal",style:{marginRight:"0.1132em"},children:"\u03c4"})]})})]})," \u662f\u53ef\u5b66\u4e60\u7684"]}),"\uff1a\u4e0d\u540c\u795e\u7ecf\u5143\u53ef\u4ee5\u6709\u4e0d\u540c\u7684\u65f6\u95f4\u5c3a\u5ea6"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u5b66"}),"\uff1a\u66f4\u7b26\u5408\u771f\u5b9e\u795e\u7ecf\u5143\u7684\u884c\u4e3a"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u56e0\u679c\u6027"}),"\uff1a\u7406\u89e3\u65f6\u95f4\u56e0\u679c\u5173\u7cfb"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"\u5b8c\u6574\u5b9e\u73b0",children:"\u5b8c\u6574\u5b9e\u73b0"}),"\n",(0,t.jsx)(e.h4,{id:"1-\u6db2\u6001\u795e\u7ecf\u5143",children:"1. \u6db2\u6001\u795e\u7ecf\u5143"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport numpy as np\nfrom typing import Optional, Tuple\n\nclass LiquidNeuron(nn.Module):\n    """\u6db2\u6001\u795e\u7ecf\u5143\u7684\u5b8c\u6574\u5b9e\u73b0"""\n    \n    def __init__(self, \n                 input_size: int,\n                 hidden_size: int,\n                 activation: str = \'tanh\',\n                 use_bias: bool = True):\n        super().__init__()\n        \n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        \n        # \u65f6\u95f4\u5e38\u6570\uff08\u53ef\u5b66\u4e60\uff0c\u6bcf\u4e2a\u795e\u7ecf\u5143\u72ec\u7acb\uff09\n        self.tau = nn.Parameter(torch.rand(hidden_size) * 0.5 + 0.5)\n        \n        # \u8f93\u5165\u6743\u91cd\n        self.W_in = nn.Parameter(torch.randn(input_size, hidden_size) * 0.1)\n        \n        # \u5faa\u73af\u6743\u91cd\n        self.W_rec = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.1)\n        \n        # \u504f\u7f6e\n        if use_bias:\n            self.bias = nn.Parameter(torch.zeros(hidden_size))\n        else:\n            self.register_parameter(\'bias\', None)\n        \n        # \u6fc0\u6d3b\u51fd\u6570\n        if activation == \'tanh\':\n            self.activation = torch.tanh\n        elif activation == \'sigmoid\':\n            self.activation = torch.sigmoid\n        elif activation == \'relu\':\n            self.activation = torch.relu\n        else:\n            raise ValueError(f"Unknown activation: {activation}")\n    \n    def forward(self, \n                x: torch.Tensor,\n                h: torch.Tensor,\n                dt: float = 0.1) -> torch.Tensor:\n        """\n        \u524d\u5411\u4f20\u64ad\n        \n        Args:\n            x: \u8f93\u5165 (batch_size, input_size)\n            h: \u9690\u85cf\u72b6\u6001 (batch_size, hidden_size)\n            dt: \u65f6\u95f4\u6b65\u957f\n        \n        Returns:\n            \u65b0\u7684\u9690\u85cf\u72b6\u6001 (batch_size, hidden_size)\n        """\n        # \u8ba1\u7b97\u8f93\u5165\u8d21\u732e\n        input_contrib = torch.matmul(x, self.W_in)\n        \n        # \u8ba1\u7b97\u5faa\u73af\u8d21\u732e\n        recurrent_contrib = torch.matmul(h, self.W_rec)\n        \n        # \u7ec4\u5408\u8f93\u5165\n        combined = input_contrib + recurrent_contrib\n        if self.bias is not None:\n            combined = combined + self.bias\n        \n        # \u5e94\u7528\u6fc0\u6d3b\u51fd\u6570\n        f_h = self.activation(combined)\n        \n        # \u6db2\u6001\u52a8\u529b\u5b66\uff1adh/dt = (-h + f(x)) / tau\n        # \u4f7f\u7528\u6b27\u62c9\u65b9\u6cd5\uff1ah_new = h + dt * dh/dt\n        dh_dt = (-h + f_h) / self.tau\n        h_new = h + dt * dh_dt\n        \n        return h_new\n    \n    def get_time_constants(self) -> torch.Tensor:\n        """\u83b7\u53d6\u65f6\u95f4\u5e38\u6570"""\n        return self.tau.data\n\n\nclass LiquidCell(nn.Module):\n    """\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5355\u5143\uff08\u652f\u6301\u591a\u5c42\uff09"""\n    \n    def __init__(self,\n                 input_size: int,\n                 hidden_size: int,\n                 num_layers: int = 1,\n                 activation: str = \'tanh\',\n                 dropout: float = 0.0):\n        super().__init__()\n        \n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        # \u521b\u5efa\u591a\u5c42\u6db2\u6001\u795e\u7ecf\u5143\n        self.layers = nn.ModuleList()\n        for i in range(num_layers):\n            layer_input_size = input_size if i == 0 else hidden_size\n            self.layers.append(\n                LiquidNeuron(layer_input_size, hidden_size, activation)\n            )\n        \n        # Dropout\n        self.dropout = nn.Dropout(dropout) if dropout > 0 else None\n    \n    def forward(self,\n                x: torch.Tensor,\n                hidden: Optional[Tuple[torch.Tensor, ...]] = None,\n                dt: float = 0.1) -> Tuple[torch.Tensor, Tuple[torch.Tensor, ...]]:\n        """\n        \u524d\u5411\u4f20\u64ad\n        \n        Args:\n            x: \u8f93\u5165 (batch_size, input_size)\n            hidden: \u9690\u85cf\u72b6\u6001\u5143\u7ec4\n            dt: \u65f6\u95f4\u6b65\u957f\n        \n        Returns:\n            output: \u8f93\u51fa (batch_size, hidden_size)\n            new_hidden: \u65b0\u7684\u9690\u85cf\u72b6\u6001\u5143\u7ec4\n        """\n        batch_size = x.size(0)\n        \n        # \u521d\u59cb\u5316\u9690\u85cf\u72b6\u6001\n        if hidden is None:\n            hidden = tuple(\n                torch.zeros(batch_size, self.hidden_size, device=x.device)\n                for _ in range(self.num_layers)\n            )\n        \n        new_hidden = []\n        layer_input = x\n        \n        # \u901a\u8fc7\u6bcf\u4e00\u5c42\n        for i, (layer, h) in enumerate(zip(self.layers, hidden)):\n            h_new = layer(layer_input, h, dt)\n            new_hidden.append(h_new)\n            \n            # \u5e94\u7528dropout\uff08\u9664\u4e86\u6700\u540e\u4e00\u5c42\uff09\n            if self.dropout is not None and i < self.num_layers - 1:\n                layer_input = self.dropout(h_new)\n            else:\n                layer_input = h_new\n        \n        return layer_input, tuple(new_hidden)\n'})}),"\n",(0,t.jsx)(e.h4,{id:"2-\u5b8c\u6574\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc",children:"2. \u5b8c\u6574\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class LiquidNeuralNetwork(nn.Module):\n    """\u5b8c\u6574\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc"""\n    \n    def __init__(self,\n                 input_size: int,\n                 hidden_size: int,\n                 output_size: int,\n                 num_layers: int = 1,\n                 activation: str = \'tanh\',\n                 dropout: float = 0.0,\n                 output_activation: Optional[str] = None):\n        super().__init__()\n        \n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.num_layers = num_layers\n        \n        # \u6db2\u6001\u5355\u5143\n        self.liquid_cell = LiquidCell(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            activation=activation,\n            dropout=dropout\n        )\n        \n        # \u8f93\u51fa\u5c42\n        self.output_layer = nn.Linear(hidden_size, output_size)\n        \n        # \u8f93\u51fa\u6fc0\u6d3b\u51fd\u6570\n        if output_activation == \'sigmoid\':\n            self.output_activation = torch.sigmoid\n        elif output_activation == \'softmax\':\n            self.output_activation = lambda x: torch.softmax(x, dim=-1)\n        else:\n            self.output_activation = None\n    \n    def forward(self,\n                x: torch.Tensor,\n                hidden: Optional[Tuple[torch.Tensor, ...]] = None,\n                dt: float = 0.1) -> Tuple[torch.Tensor, Tuple[torch.Tensor, ...]]:\n        """\n        \u524d\u5411\u4f20\u64ad\n        \n        Args:\n            x: \u8f93\u5165 (batch_size, seq_len, input_size)\n            hidden: \u521d\u59cb\u9690\u85cf\u72b6\u6001\n            dt: \u65f6\u95f4\u6b65\u957f\n        \n        Returns:\n            outputs: \u8f93\u51fa\u5e8f\u5217 (batch_size, seq_len, output_size)\n            hidden: \u6700\u7ec8\u9690\u85cf\u72b6\u6001\n        """\n        batch_size, seq_len, _ = x.size()\n        \n        outputs = []\n        \n        # \u5904\u7406\u5e8f\u5217\n        for t in range(seq_len):\n            x_t = x[:, t, :]\n            \n            # \u901a\u8fc7\u6db2\u6001\u5355\u5143\n            h_t, hidden = self.liquid_cell(x_t, hidden, dt)\n            \n            # \u8f93\u51fa\u5c42\n            out_t = self.output_layer(h_t)\n            \n            # \u8f93\u51fa\u6fc0\u6d3b\n            if self.output_activation is not None:\n                out_t = self.output_activation(out_t)\n            \n            outputs.append(out_t)\n        \n        # \u5806\u53e0\u8f93\u51fa\n        outputs = torch.stack(outputs, dim=1)\n        \n        return outputs, hidden\n    \n    def get_time_constants(self) -> list:\n        """\u83b7\u53d6\u6240\u6709\u5c42\u7684\u65f6\u95f4\u5e38\u6570"""\n        time_constants = []\n        for layer in self.liquid_cell.layers:\n            time_constants.append(layer.get_time_constants())\n        return time_constants\n'})}),"\n",(0,t.jsx)(e.h3,{id:"\u9ad8\u7ea7\u7279\u6027",children:"\u9ad8\u7ea7\u7279\u6027"}),"\n",(0,t.jsx)(e.h4,{id:"1-\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f",children:"1. \u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class AdaptiveLiquidNeuron(LiquidNeuron):\n    """\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\u7684\u6db2\u6001\u795e\u7ecf\u5143"""\n    \n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        \n        # \u5b66\u4e60\u65f6\u95f4\u6b65\u957f\u7684\u6743\u91cd\n        self.dt_weight = nn.Parameter(torch.ones(self.hidden_size))\n    \n    def forward(self, x, h, dt=0.1):\n        """\u4f7f\u7528\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f"""\n        # \u8ba1\u7b97\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\n        adaptive_dt = dt * torch.sigmoid(self.dt_weight)\n        \n        # \u6807\u51c6\u6db2\u6001\u52a8\u529b\u5b66\n        input_contrib = torch.matmul(x, self.W_in)\n        recurrent_contrib = torch.matmul(h, self.W_rec)\n        combined = input_contrib + recurrent_contrib\n        \n        if self.bias is not None:\n            combined = combined + self.bias\n        \n        f_h = self.activation(combined)\n        \n        # \u4f7f\u7528\u81ea\u9002\u5e94\u65f6\u95f4\u6b65\u957f\n        dh_dt = (-h + f_h) / self.tau\n        h_new = h + adaptive_dt * dh_dt\n        \n        return h_new\n'})}),"\n",(0,t.jsx)(e.h4,{id:"2-\u7a00\u758f\u8fde\u63a5",children:"2. \u7a00\u758f\u8fde\u63a5"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class SparseLiquidNeuron(LiquidNeuron):\n    """\u7a00\u758f\u8fde\u63a5\u7684\u6db2\u6001\u795e\u7ecf\u5143"""\n    \n    def __init__(self, *args, sparsity: float = 0.5, **kwargs):\n        super().__init__(*args, **kwargs)\n        \n        # \u521b\u5efa\u7a00\u758f\u63a9\u7801\n        self.sparsity = sparsity\n        self.register_buffer(\n            \'rec_mask\',\n            self._create_sparse_mask(self.hidden_size, sparsity)\n        )\n    \n    def _create_sparse_mask(self, size: int, sparsity: float) -> torch.Tensor:\n        """\u521b\u5efa\u7a00\u758f\u63a9\u7801"""\n        mask = torch.rand(size, size) > sparsity\n        return mask.float()\n    \n    def forward(self, x, h, dt=0.1):\n        """\u5e94\u7528\u7a00\u758f\u63a9\u7801"""\n        input_contrib = torch.matmul(x, self.W_in)\n        \n        # \u5e94\u7528\u7a00\u758f\u63a9\u7801\u5230\u5faa\u73af\u6743\u91cd\n        sparse_W_rec = self.W_rec * self.rec_mask\n        recurrent_contrib = torch.matmul(h, sparse_W_rec)\n        \n        combined = input_contrib + recurrent_contrib\n        if self.bias is not None:\n            combined = combined + self.bias\n        \n        f_h = self.activation(combined)\n        dh_dt = (-h + f_h) / self.tau\n        h_new = h + dt * dh_dt\n        \n        return h_new\n'})}),"\n",(0,t.jsx)(e.h2,{id:"\u5b9e\u6218\u6848\u4f8b1\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b",children:"\u5b9e\u6218\u6848\u4f8b1\uff1a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass TimeSeriesLNN:\n    """\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6db2\u6001\u795e\u7ecf\u7f51\u7edc"""\n    \n    def __init__(self,\n                 input_size: int,\n                 hidden_size: int,\n                 output_size: int,\n                 num_layers: int = 2):\n        self.model = LiquidNeuralNetwork(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            output_size=output_size,\n            num_layers=num_layers\n        )\n        \n        self.criterion = nn.MSELoss()\n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n    \n    def train(self,\n              train_data: torch.Tensor,\n              train_labels: torch.Tensor,\n              epochs: int = 100,\n              batch_size: int = 32):\n        """\u8bad\u7ec3\u6a21\u578b"""\n        self.model.train()\n        \n        dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n        dataloader = torch.utils.data.DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=True\n        )\n        \n        losses = []\n        \n        for epoch in range(epochs):\n            epoch_loss = 0\n            \n            for batch_x, batch_y in dataloader:\n                self.optimizer.zero_grad()\n                \n                # \u524d\u5411\u4f20\u64ad\n                outputs, _ = self.model(batch_x)\n                \n                # \u8ba1\u7b97\u635f\u5931\n                loss = self.criterion(outputs, batch_y)\n                \n                # \u53cd\u5411\u4f20\u64ad\n                loss.backward()\n                self.optimizer.step()\n                \n                epoch_loss += loss.item()\n            \n            avg_loss = epoch_loss / len(dataloader)\n            losses.append(avg_loss)\n            \n            if (epoch + 1) % 10 == 0:\n                print(f\'Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.6f}\')\n        \n        return losses\n    \n    def predict(self, x: torch.Tensor) -> torch.Tensor:\n        """\u9884\u6d4b"""\n        self.model.eval()\n        \n        with torch.no_grad():\n            outputs, _ = self.model(x)\n        \n        return outputs\n    \n    def forecast(self,\n                 initial_sequence: torch.Tensor,\n                 steps: int) -> torch.Tensor:\n        """\u591a\u6b65\u9884\u6d4b"""\n        self.model.eval()\n        \n        predictions = []\n        current_seq = initial_sequence.clone()\n        hidden = None\n        \n        with torch.no_grad():\n            for _ in range(steps):\n                # \u9884\u6d4b\u4e0b\u4e00\u6b65\n                output, hidden = self.model(current_seq, hidden)\n                next_value = output[:, -1:, :]\n                \n                predictions.append(next_value)\n                \n                # \u66f4\u65b0\u5e8f\u5217\n                current_seq = torch.cat([current_seq[:, 1:, :], next_value], dim=1)\n        \n        return torch.cat(predictions, dim=1)\n\n# \u4f7f\u7528\u793a\u4f8b\uff1a\u6b63\u5f26\u6ce2\u9884\u6d4b\ndef sine_wave_example():\n    """\u6b63\u5f26\u6ce2\u9884\u6d4b\u793a\u4f8b"""\n    # \u751f\u6210\u6570\u636e\n    t = np.linspace(0, 100, 1000)\n    data = np.sin(t) + 0.1 * np.random.randn(1000)\n    \n    # \u521b\u5efa\u5e8f\u5217\n    seq_length = 50\n    X, y = [], []\n    \n    for i in range(len(data) - seq_length):\n        X.append(data[i:i+seq_length])\n        y.append(data[i+1:i+seq_length+1])\n    \n    X = torch.FloatTensor(X).unsqueeze(-1)\n    y = torch.FloatTensor(y).unsqueeze(-1)\n    \n    # \u8bad\u7ec3\u6a21\u578b\n    model = TimeSeriesLNN(input_size=1, hidden_size=32, output_size=1)\n    losses = model.train(X[:800], y[:800], epochs=50)\n    \n    # \u9884\u6d4b\n    test_x = X[800:810]\n    predictions = model.predict(test_x)\n    \n    # \u53ef\u89c6\u5316\n    plt.figure(figsize=(12, 4))\n    plt.plot(losses)\n    plt.title(\'Training Loss\')\n    plt.xlabel(\'Epoch\')\n    plt.ylabel(\'Loss\')\n    plt.show()\n    \n    # \u9884\u6d4b\u7ed3\u679c\n    plt.figure(figsize=(12, 4))\n    for i in range(5):\n        plt.plot(y[800+i].numpy(), label=f\'True {i}\', alpha=0.5)\n        plt.plot(predictions[i].numpy(), label=f\'Pred {i}\', linestyle=\'--\')\n    plt.legend()\n    plt.title(\'Predictions\')\n    plt.show()\n\nsine_wave_example()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"\u5b9e\u6218\u6848\u4f8b2\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236",children:"\u5b9e\u6218\u6848\u4f8b2\uff1a\u81ea\u52a8\u9a7e\u9a76\u63a7\u5236"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class AutonomousDrivingLNN:\n    """\u81ea\u52a8\u9a7e\u9a76\u6db2\u6001\u795e\u7ecf\u7f51\u7edc"""\n    \n    def __init__(self):\n        # \u8f93\u5165\uff1a\u4f20\u611f\u5668\u6570\u636e\uff08\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u3001\u8f6c\u5411\u89d2\u3001\u969c\u788d\u7269\u8ddd\u79bb\u7b49\uff09\n        # \u8f93\u51fa\uff1a\u63a7\u5236\u4fe1\u53f7\uff08\u8f6c\u5411\u3001\u6cb9\u95e8\u3001\u5239\u8f66\uff09\n        self.model = LiquidNeuralNetwork(\n            input_size=128,  # \u4f20\u611f\u5668\u7279\u5f81\n            hidden_size=64,\n            output_size=3,   # \u8f6c\u5411\u3001\u6cb9\u95e8\u3001\u5239\u8f66\n            num_layers=3,\n            activation=\'tanh\'\n        )\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001)\n    \n    def process_sensors(self, camera, lidar, imu):\n        """\u5904\u7406\u4f20\u611f\u5668\u6570\u636e"""\n        # \u63d0\u53d6\u7279\u5f81\n        camera_features = self._extract_camera_features(camera)\n        lidar_features = self._extract_lidar_features(lidar)\n        imu_features = self._extract_imu_features(imu)\n        \n        # \u878d\u5408\u7279\u5f81\n        features = torch.cat([camera_features, lidar_features, imu_features], dim=-1)\n        \n        return features\n    \n    def _extract_camera_features(self, camera):\n        """\u63d0\u53d6\u76f8\u673a\u7279\u5f81"""\n        # \u4f7f\u7528\u9884\u8bad\u7ec3\u7684CNN\n        # \u8fd9\u91cc\u7b80\u5316\u5904\u7406\n        return torch.randn(1, 64)\n    \n    def _extract_lidar_features(self, lidar):\n        """\u63d0\u53d6\u6fc0\u5149\u96f7\u8fbe\u7279\u5f81"""\n        # \u70b9\u4e91\u5904\u7406\n        return torch.randn(1, 32)\n    \n    def _extract_imu_features(self, imu):\n        """\u63d0\u53d6IMU\u7279\u5f81"""\n        # \u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u3001\u89d2\u901f\u5ea6\n        return torch.randn(1, 32)\n    \n    def control(self, sensor_data, hidden=None):\n        """\u751f\u6210\u63a7\u5236\u4fe1\u53f7"""\n        self.model.eval()\n        \n        with torch.no_grad():\n            # \u524d\u5411\u4f20\u64ad\n            output, hidden = self.model(sensor_data.unsqueeze(1), hidden)\n            \n            # \u89e3\u6790\u63a7\u5236\u4fe1\u53f7\n            steering = torch.tanh(output[0, 0, 0])  # [-1, 1]\n            throttle = torch.sigmoid(output[0, 0, 1])  # [0, 1]\n            brake = torch.sigmoid(output[0, 0, 2])  # [0, 1]\n        \n        return {\n            \'steering\': steering.item(),\n            \'throttle\': throttle.item(),\n            \'brake\': brake.item()\n        }, hidden\n    \n    def train_episode(self, states, actions, rewards):\n        """\u8bad\u7ec3\u4e00\u4e2aepisode"""\n        self.model.train()\n        \n        # \u8ba1\u7b97\u635f\u5931\uff08\u6a21\u4eff\u5b66\u4e60 + \u5f3a\u5316\u5b66\u4e60\uff09\n        predicted_actions, _ = self.model(states)\n        \n        # \u884c\u4e3a\u514b\u9686\u635f\u5931\n        bc_loss = nn.MSELoss()(predicted_actions, actions)\n        \n        # \u5956\u52b1\u52a0\u6743\n        weighted_loss = (bc_loss * rewards).mean()\n        \n        # \u53cd\u5411\u4f20\u64ad\n        self.optimizer.zero_grad()\n        weighted_loss.backward()\n        self.optimizer.step()\n        \n        return weighted_loss.item()\n'})}),"\n",(0,t.jsx)(e.h2,{id:"\u5b9e\u6218\u6848\u4f8b3\u673a\u5668\u4eba\u63a7\u5236",children:"\u5b9e\u6218\u6848\u4f8b3\uff1a\u673a\u5668\u4eba\u63a7\u5236"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class RobotControlLNN:\n    """\u673a\u5668\u4eba\u63a7\u5236\u6db2\u6001\u795e\u7ecf\u7f51\u7edc"""\n    \n    def __init__(self, num_joints: int):\n        self.num_joints = num_joints\n        \n        # \u8f93\u5165\uff1a\u5173\u8282\u72b6\u6001\uff08\u4f4d\u7f6e\u3001\u901f\u5ea6\u3001\u529b\u77e9\uff09+ \u76ee\u6807\u4f4d\u7f6e\n        # \u8f93\u51fa\uff1a\u5173\u8282\u63a7\u5236\u4fe1\u53f7\n        self.model = LiquidNeuralNetwork(\n            input_size=num_joints * 4,  # 3\u4e2a\u72b6\u6001 + 1\u4e2a\u76ee\u6807\n            hidden_size=128,\n            output_size=num_joints,\n            num_layers=2\n        )\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n    \n    def forward_kinematics(self, joint_angles):\n        """\u6b63\u5411\u8fd0\u52a8\u5b66"""\n        # \u8ba1\u7b97\u672b\u7aef\u6267\u884c\u5668\u4f4d\u7f6e\n        # \u8fd9\u91cc\u7b80\u5316\u5904\u7406\n        return torch.randn(3)  # x, y, z\n    \n    def inverse_kinematics(self, target_position):\n        """\u9006\u5411\u8fd0\u52a8\u5b66"""\n        # \u8ba1\u7b97\u76ee\u6807\u5173\u8282\u89d2\u5ea6\n        # \u8fd9\u91cc\u7b80\u5316\u5904\u7406\n        return torch.randn(self.num_joints)\n    \n    def control_step(self, \n                     joint_positions,\n                     joint_velocities,\n                     joint_torques,\n                     target_position,\n                     hidden=None):\n        """\u5355\u6b65\u63a7\u5236"""\n        # \u51c6\u5907\u8f93\u5165\n        target_joints = self.inverse_kinematics(target_position)\n        \n        input_data = torch.cat([\n            joint_positions,\n            joint_velocities,\n            joint_torques,\n            target_joints\n        ]).unsqueeze(0).unsqueeze(0)\n        \n        # \u751f\u6210\u63a7\u5236\u4fe1\u53f7\n        with torch.no_grad():\n            control_signals, hidden = self.model(input_data, hidden)\n        \n        return control_signals.squeeze(), hidden\n    \n    def train_trajectory(self, \n                        trajectory_states,\n                        trajectory_actions,\n                        epochs=100):\n        """\u8bad\u7ec3\u8f68\u8ff9\u8ddf\u8e2a"""\n        self.model.train()\n        \n        for epoch in range(epochs):\n            self.optimizer.zero_grad()\n            \n            # \u524d\u5411\u4f20\u64ad\n            predicted_actions, _ = self.model(trajectory_states)\n            \n            # \u8ba1\u7b97\u635f\u5931\n            loss = nn.MSELoss()(predicted_actions, trajectory_actions)\n            \n            # \u53cd\u5411\u4f20\u64ad\n            loss.backward()\n            self.optimizer.step()\n            \n            if (epoch + 1) % 10 == 0:\n                print(f\'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}\')\n'})}),"\n",(0,t.jsx)(e.h2,{id:"\u6027\u80fd\u5206\u6790",children:"\u6027\u80fd\u5206\u6790"}),"\n",(0,t.jsx)(e.h3,{id:"1-\u53c2\u6570\u6548\u7387\u5bf9\u6bd4",children:"1. \u53c2\u6570\u6548\u7387\u5bf9\u6bd4"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def compare_model_sizes():\n    """\u5bf9\u6bd4\u6a21\u578b\u5927\u5c0f"""\n    input_size = 10\n    hidden_size = 64\n    output_size = 1\n    \n    # LSTM\n    lstm = nn.LSTM(input_size, hidden_size, num_layers=2)\n    lstm_params = sum(p.numel() for p in lstm.parameters())\n    \n    # GRU\n    gru = nn.GRU(input_size, hidden_size, num_layers=2)\n    gru_params = sum(p.numel() for p in gru.parameters())\n    \n    # \u6db2\u6001\u795e\u7ecf\u7f51\u7edc\n    lnn = LiquidNeuralNetwork(input_size, hidden_size, output_size, num_layers=2)\n    lnn_params = sum(p.numel() for p in lnn.parameters())\n    \n    print(f"LSTM\u53c2\u6570\u91cf: {lstm_params:,}")\n    print(f"GRU\u53c2\u6570\u91cf: {gru_params:,}")\n    print(f"LNN\u53c2\u6570\u91cf: {lnn_params:,}")\n    print(f"\\nLNN\u76f8\u6bd4LSTM\u51cf\u5c11: {(1 - lnn_params/lstm_params)*100:.1f}%")\n    print(f"LNN\u76f8\u6bd4GRU\u51cf\u5c11: {(1 - lnn_params/gru_params)*100:.1f}%")\n\ncompare_model_sizes()\n'})}),"\n",(0,t.jsx)(e.h3,{id:"2-\u63a8\u7406\u901f\u5ea6\u5bf9\u6bd4",children:"2. \u63a8\u7406\u901f\u5ea6\u5bf9\u6bd4"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import time\n\ndef benchmark_inference():\n    \"\"\"\u63a8\u7406\u901f\u5ea6\u57fa\u51c6\u6d4b\u8bd5\"\"\"\n    batch_size = 32\n    seq_len = 100\n    input_size = 10\n    hidden_size = 64\n    \n    x = torch.randn(batch_size, seq_len, input_size)\n    \n    models = {\n        'LSTM': nn.LSTM(input_size, hidden_size),\n        'GRU': nn.GRU(input_size, hidden_size),\n        'LNN': LiquidNeuralNetwork(input_size, hidden_size, 1)\n    }\n    \n    for name, model in models.items():\n        model.eval()\n        \n        # \u9884\u70ed\n        with torch.no_grad():\n            if name == 'LNN':\n                _ = model(x)\n            else:\n                _ = model(x)\n        \n        # \u6d4b\u8bd5\n        start = time.time()\n        with torch.no_grad():\n            for _ in range(100):\n                if name == 'LNN':\n                    _ = model(x)\n                else:\n                    _ = model(x)\n        end = time.time()\n        \n        print(f\"{name}: {(end-start)/100*1000:.2f}ms per batch\")\n\nbenchmark_inference()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"\u53ef\u89c6\u5316\u5de5\u5177",children:"\u53ef\u89c6\u5316\u5de5\u5177"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def visualize_liquid_dynamics(model, input_sequence):\n    \"\"\"\u53ef\u89c6\u5316\u6db2\u6001\u52a8\u529b\u5b66\"\"\"\n    import matplotlib.pyplot as plt\n    \n    model.eval()\n    \n    # \u8bb0\u5f55\u9690\u85cf\u72b6\u6001\n    hidden_states = []\n    hidden = None\n    \n    with torch.no_grad():\n        for t in range(input_sequence.shape[1]):\n            x_t = input_sequence[:, t:t+1, :]\n            _, hidden = model(x_t, hidden)\n            \n            # \u8bb0\u5f55\u7b2c\u4e00\u5c42\u7684\u9690\u85cf\u72b6\u6001\n            hidden_states.append(hidden[0].squeeze().numpy())\n    \n    hidden_states = np.array(hidden_states)\n    \n    # \u7ed8\u5236\u795e\u7ecf\u5143\u6d3b\u52a8\n    plt.figure(figsize=(15, 8))\n    \n    # \u70ed\u56fe\n    plt.subplot(2, 1, 1)\n    plt.imshow(hidden_states.T, aspect='auto', cmap='viridis')\n    plt.colorbar(label='Activation')\n    plt.xlabel('Time Step')\n    plt.ylabel('Neuron')\n    plt.title('Liquid Neural Network Dynamics')\n    \n    # \u65f6\u95f4\u5e38\u6570\n    plt.subplot(2, 1, 2)\n    time_constants = model.get_time_constants()[0].numpy()\n    plt.bar(range(len(time_constants)), time_constants)\n    plt.xlabel('Neuron')\n    plt.ylabel('Time Constant (\u03c4)')\n    plt.title('Learned Time Constants')\n    \n    plt.tight_layout()\n    plt.show()\n\n# \u4f7f\u7528\nx = torch.randn(1, 100, 10)\nmodel = LiquidNeuralNetwork(10, 32, 1)\nvisualize_liquid_dynamics(model, x)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"\u5b66\u4e60\u8d44\u6e90",children:"\u5b66\u4e60\u8d44\u6e90"}),"\n",(0,t.jsx)(e.h3,{id:"\u8bba\u6587",children:"\u8bba\u6587"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:'"Liquid Time-constant Networks" (Hasani et al., 2020)'}),"\n",(0,t.jsx)(e.li,{children:'"Closed-form Continuous-time Neural Networks" (Hasani et al., 2022)'}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"\u4ee3\u7801\u5e93",children:"\u4ee3\u7801\u5e93"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["GitHub: ",(0,t.jsx)(e.a,{href:"https://github.com/raminmh/liquid_time_constant_networks",children:"https://github.com/raminmh/liquid_time_constant_networks"})]}),"\n",(0,t.jsxs)(e.li,{children:["PyTorch\u5b9e\u73b0: ",(0,t.jsx)(e.a,{href:"https://github.com/mlech26l/ncps",children:"https://github.com/mlech26l/ncps"})]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"\u5e94\u7528\u6848\u4f8b",children:"\u5e94\u7528\u6848\u4f8b"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u81ea\u52a8\u9a7e\u9a76"}),"\n",(0,t.jsx)(e.li,{children:"\u673a\u5668\u4eba\u63a7\u5236"}),"\n",(0,t.jsx)(e.li,{children:"\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b"}),"\n",(0,t.jsx)(e.li,{children:"\u4fe1\u53f7\u5904\u7406"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"\u603b\u7ed3",children:"\u603b\u7ed3"}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u7684\u6838\u5fc3\u4f18\u52bf"}),"\uff1a"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u6781\u81f4\u7684\u53c2\u6570\u6548\u7387"}),"\uff1a\u6bd4LSTM\u5c0f100-1000\u500d"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u52a8\u6001\u9002\u5e94\u80fd\u529b"}),"\uff1a\u6743\u91cd\u5728\u63a8\u7406\u65f6\u6301\u7eed\u53d8\u5316"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u9ad8\u5ea6\u53ef\u89e3\u91ca"}),"\uff1a\u53ef\u4ee5\u7406\u89e3\u6bcf\u4e2a\u795e\u7ecf\u5143\u7684\u4f5c\u7528"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u56e0\u679c\u63a8\u7406"}),"\uff1a\u7406\u89e3\u65f6\u95f4\u56e0\u679c\u5173\u7cfb"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"\u8fb9\u7f18\u90e8\u7f72"}),"\uff1a\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907"]}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u9002\u7528\u573a\u666f"}),"\uff1a"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"\u8fb9\u7f18\u8bbe\u5907\uff08\u624b\u673a\u3001IoT\uff09"}),"\n",(0,t.jsx)(e.li,{children:"\u5b9e\u65f6\u7cfb\u7edf\uff08\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\uff09"}),"\n",(0,t.jsx)(e.li,{children:"\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1"}),"\n",(0,t.jsx)(e.li,{children:"\u9700\u8981\u53ef\u89e3\u91ca\u6027\u7684\u5e94\u7528"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u5b66\u4e60\u8def\u5f84"}),"\uff1a"]}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"\u7406\u89e3ODE\u795e\u7ecf\u5143\u7684\u6570\u5b66\u539f\u7406"}),"\n",(0,t.jsx)(e.li,{children:"\u5b9e\u73b0\u57fa\u7840\u7684\u6db2\u6001\u795e\u7ecf\u5143"}),"\n",(0,t.jsx)(e.li,{children:"\u5e94\u7528\u5230\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1"}),"\n",(0,t.jsx)(e.li,{children:"\u63a2\u7d22\u9ad8\u7ea7\u7279\u6027\uff08\u81ea\u9002\u5e94\u3001\u7a00\u758f\uff09"}),"\n",(0,t.jsx)(e.li,{children:"\u90e8\u7f72\u5230\u5b9e\u9645\u5e94\u7528"}),"\n"]}),"\n",(0,t.jsx)(s,{})]})}function o(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(h,{...n})}):h(n)}},28453(n,e,s){s.d(e,{R:()=>l,x:()=>r});var i=s(96540);const t={},a=i.createContext(t);function l(n){const e=i.useContext(a);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:l(n.components),i.createElement(a.Provider,{value:e},n.children)}}}]);