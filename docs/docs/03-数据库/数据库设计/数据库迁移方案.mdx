---
sidebar_position: 12
title: 数据库迁移方案实战
tags: [数据库, 数据迁移, 零停机, 灰度发布]
---

# 数据库迁移方案实战

## 概述

数据库迁移是一个高风险操作，需要保证数据完整性、业务连续性和可回滚性。本文介绍多种迁移方案和最佳实践。

### 迁移场景

- **数据库升级**：MySQL 5.7 → MySQL 8.0
- **架构变更**：单库 → 分库分表
- **云迁移**：自建 → 云数据库
- **跨数据库**：MySQL → PostgreSQL

## 迁移方案

### 1. 停机迁移

最简单但影响最大的方案。

```bash
#!/bin/bash
# 停机迁移脚本

echo "1. 停止应用服务"
systemctl stop app-service

echo "2. 备份原数据库"
mysqldump -h old-db -u root -p database_name > backup.sql

echo "3. 导入新数据库"
mysql -h new-db -u root -p database_name < backup.sql

echo "4. 验证数据"
mysql -h new-db -u root -p -e "SELECT COUNT(*) FROM users"

echo "5. 更新应用配置"
sed -i 's/old-db/new-db/g' /etc/app/config.yml

echo "6. 启动应用服务"
systemctl start app-service

echo "迁移完成"
```

**优点**：
- 实现简单
- 数据一致性有保证

**缺点**：
- 需要停机
- 影响业务

### 2. 主从复制迁移

利用 MySQL 主从复制实现零停机迁移。

#### 步骤1：建立主从关系

```sql
-- 在旧库（主库）上创建复制用户
CREATE USER 'repl'@'%' IDENTIFIED BY 'password';
GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
FLUSH PRIVILEGES;

-- 查看主库状态
SHOW MASTER STATUS;
-- 记录 File 和 Position
```

```sql
-- 在新库（从库）上配置主从
CHANGE MASTER TO
  MASTER_HOST='old-db-host',
  MASTER_USER='repl',
  MASTER_PASSWORD='password',
  MASTER_LOG_FILE='mysql-bin.000001',
  MASTER_LOG_POS=154;

-- 启动从库
START SLAVE;

-- 检查从库状态
SHOW SLAVE STATUS\G
-- 确保 Slave_IO_Running 和 Slave_SQL_Running 都是 Yes
```

#### 步骤2：等待数据同步

```bash
#!/bin/bash
# 检查主从延迟

while true; do
  delay=$(mysql -h new-db -u root -p -e "SHOW SLAVE STATUS\G" | grep "Seconds_Behind_Master" | awk '{print $2}')
  
  if [ "$delay" == "0" ]; then
    echo "数据已同步"
    break
  else
    echo "延迟: ${delay}秒"
    sleep 5
  fi
done
```

#### 步骤3：切换流量

```javascript
// 应用层双写验证
class DatabaseMigration {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.writeToNew = false;
    this.readFromNew = false;
  }
  
  // 阶段1：只写旧库
  async write(data) {
    return await this.oldDb.insert(data);
  }
  
  // 阶段2：双写（旧库为主）
  async writePhase2(data) {
    const result = await this.oldDb.insert(data);
    
    // 异步写入新库
    this.newDb.insert(data).catch(err => {
      console.error('新库写入失败', err);
      // 记录失败，后续补偿
    });
    
    return result;
  }
  
  // 阶段3：双写（新库为主）
  async writePhase3(data) {
    const result = await this.newDb.insert(data);
    
    // 异步写入旧库
    this.oldDb.insert(data).catch(err => {
      console.error('旧库写入失败', err);
    });
    
    return result;
  }
  
  // 阶段4：只写新库
  async writePhase4(data) {
    return await this.newDb.insert(data);
  }
  
  // 读取数据
  async read(id) {
    if (this.readFromNew) {
      // 从新库读取
      const data = await this.newDb.query(id);
      if (data) return data;
      
      // 新库没有，降级到旧库
      return await this.oldDb.query(id);
    } else {
      // 从旧库读取
      return await this.oldDb.query(id);
    }
  }
}
```

#### 步骤4：数据校验

```javascript
// 数据一致性校验
class DataValidator {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
  }
  
  async validateTable(tableName, primaryKey = 'id') {
    console.log(`开始校验表: ${tableName}`);
    
    // 1. 校验总数
    const oldCount = await this.oldDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    const newCount = await this.newDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    
    if (oldCount.count !== newCount.count) {
      console.error(`数据量不一致: 旧库=${oldCount.count}, 新库=${newCount.count}`);
      return false;
    }
    
    // 2. 抽样校验
    const sampleSize = 1000;
    const samples = await this.oldDb.query(`
      SELECT ${primaryKey} FROM ${tableName}
      ORDER BY RAND()
      LIMIT ${sampleSize}
    `);
    
    let errorCount = 0;
    for (const sample of samples) {
      const oldData = await this.oldDb.query(`SELECT * FROM ${tableName} WHERE ${primaryKey} = ?`, [sample[primaryKey]]);
      const newData = await this.newDb.query(`SELECT * FROM ${tableName} WHERE ${primaryKey} = ?`, [sample[primaryKey]]);
      
      if (JSON.stringify(oldData) !== JSON.stringify(newData)) {
        console.error(`数据不一致: ${primaryKey}=${sample[primaryKey]}`);
        errorCount++;
      }
    }
    
    console.log(`校验完成: 抽样${sampleSize}条, 错误${errorCount}条`);
    return errorCount === 0;
  }
  
  async validateChecksum(tableName) {
    // 使用 CHECKSUM TABLE 快速校验
    const oldChecksum = await this.oldDb.query(`CHECKSUM TABLE ${tableName}`);
    const newChecksum = await this.newDb.query(`CHECKSUM TABLE ${tableName}`);
    
    return oldChecksum[0].Checksum === newChecksum[0].Checksum;
  }
}
```

### 3. 逻辑备份迁移

使用 mysqldump 或 mydumper 进行逻辑备份。

```bash
#!/bin/bash
# 使用 mydumper 进行并行备份

# 安装 mydumper
# apt-get install mydumper

# 备份（并行导出）
mydumper \
  --host=old-db \
  --user=root \
  --password=password \
  --database=mydb \
  --outputdir=/backup \
  --threads=8 \
  --compress \
  --verbose=3

# 恢复（并行导入）
myloader \
  --host=new-db \
  --user=root \
  --password=password \
  --database=mydb \
  --directory=/backup \
  --threads=8 \
  --verbose=3
```

### 4. 物理备份迁移

使用 Percona XtraBackup 进行物理备份。

```bash
#!/bin/bash
# 使用 XtraBackup 进行物理备份

# 安装 XtraBackup
# apt-get install percona-xtrabackup-80

# 全量备份
xtrabackup \
  --backup \
  --host=old-db \
  --user=root \
  --password=password \
  --target-dir=/backup/full

# 准备备份
xtrabackup \
  --prepare \
  --target-dir=/backup/full

# 恢复到新库
# 1. 停止新库
systemctl stop mysql

# 2. 清空数据目录
rm -rf /var/lib/mysql/*

# 3. 恢复数据
xtrabackup \
  --copy-back \
  --target-dir=/backup/full

# 4. 修改权限
chown -R mysql:mysql /var/lib/mysql

# 5. 启动新库
systemctl start mysql
```

### 5. 增量迁移

使用 binlog 实现增量同步。

```javascript
// 使用 Canal 监听 binlog
const Canal = require('canal-node-client');

class BinlogSync {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.canal = new Canal({
      host: 'old-db',
      port: 11111,
      destination: 'example',
      username: '',
      password: '',
    });
  }
  
  async start() {
    this.canal.subscribe({
      database: 'mydb',
      table: 'users',
    });
    
    this.canal.on('entry', async (entry) => {
      const { eventType, rowDatas } = entry;
      
      for (const rowData of rowDatas) {
        switch (eventType) {
          case 'INSERT':
            await this.handleInsert(rowData);
            break;
          case 'UPDATE':
            await this.handleUpdate(rowData);
            break;
          case 'DELETE':
            await this.handleDelete(rowData);
            break;
        }
      }
    });
    
    this.canal.connect();
  }
  
  async handleInsert(rowData) {
    const data = this.parseRowData(rowData.afterColumns);
    await this.newDb.insert(data);
  }
  
  async handleUpdate(rowData) {
    const before = this.parseRowData(rowData.beforeColumns);
    const after = this.parseRowData(rowData.afterColumns);
    await this.newDb.update(after, { id: before.id });
  }
  
  async handleDelete(rowData) {
    const data = this.parseRowData(rowData.beforeColumns);
    await this.newDb.delete({ id: data.id });
  }
  
  parseRowData(columns) {
    const data = {};
    for (const col of columns) {
      data[col.name] = col.value;
    }
    return data;
  }
}
```

## 跨数据库迁移

### MySQL → PostgreSQL

```javascript
// 数据类型映射
const typeMapping = {
  'INT': 'INTEGER',
  'BIGINT': 'BIGINT',
  'VARCHAR': 'VARCHAR',
  'TEXT': 'TEXT',
  'DATETIME': 'TIMESTAMP',
  'DECIMAL': 'NUMERIC',
  'TINYINT': 'SMALLINT',
  'JSON': 'JSONB',
};

class MySQLToPostgreSQL {
  constructor(mysqlDb, pgDb) {
    this.mysqlDb = mysqlDb;
    this.pgDb = pgDb;
  }
  
  async migrateTable(tableName) {
    // 1. 获取表结构
    const columns = await this.mysqlDb.query(`
      SELECT 
        COLUMN_NAME,
        DATA_TYPE,
        CHARACTER_MAXIMUM_LENGTH,
        IS_NULLABLE,
        COLUMN_DEFAULT
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_NAME = ?
    `, [tableName]);
    
    // 2. 生成 PostgreSQL 建表语句
    const createTableSQL = this.generateCreateTable(tableName, columns);
    await this.pgDb.query(createTableSQL);
    
    // 3. 迁移数据
    let offset = 0;
    const batchSize = 1000;
    
    while (true) {
      const rows = await this.mysqlDb.query(`
        SELECT * FROM ${tableName}
        LIMIT ${offset}, ${batchSize}
      `);
      
      if (rows.length === 0) break;
      
      // 批量插入
      await this.pgDb.batchInsert(tableName, rows);
      
      offset += batchSize;
      console.log(`已迁移 ${offset} 条数据`);
    }
  }
  
  generateCreateTable(tableName, columns) {
    const columnDefs = columns.map(col => {
      let def = `"${col.COLUMN_NAME}" ${this.mapType(col)}`;
      
      if (col.IS_NULLABLE === 'NO') {
        def += ' NOT NULL';
      }
      
      if (col.COLUMN_DEFAULT) {
        def += ` DEFAULT ${col.COLUMN_DEFAULT}`;
      }
      
      return def;
    });
    
    return `CREATE TABLE "${tableName}" (${columnDefs.join(', ')})`;
  }
  
  mapType(column) {
    const mysqlType = column.DATA_TYPE.toUpperCase();
    let pgType = typeMapping[mysqlType] || mysqlType;
    
    if (column.CHARACTER_MAXIMUM_LENGTH) {
      pgType += `(${column.CHARACTER_MAXIMUM_LENGTH})`;
    }
    
    return pgType;
  }
}
```

## 灰度发布

### 1. 按用户灰度

```javascript
class GrayRelease {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.grayUserIds = new Set();
    this.grayPercent = 0;
  }
  
  // 设置灰度比例
  setGrayPercent(percent) {
    this.grayPercent = percent;
  }
  
  // 添加灰度用户
  addGrayUser(userId) {
    this.grayUserIds.add(userId);
  }
  
  // 判断是否灰度用户
  isGrayUser(userId) {
    // 白名单用户
    if (this.grayUserIds.has(userId)) {
      return true;
    }
    
    // 按比例灰度
    return (userId % 100) < this.grayPercent;
  }
  
  // 选择数据库
  getDatabase(userId) {
    return this.isGrayUser(userId) ? this.newDb : this.oldDb;
  }
  
  // 查询数据
  async query(userId, sql, params) {
    const db = this.getDatabase(userId);
    return await db.query(sql, params);
  }
  
  // 写入数据
  async insert(userId, data) {
    const db = this.getDatabase(userId);
    return await db.insert(data);
  }
}

// 使用示例
const gray = new GrayRelease(oldDb, newDb);

// 阶段1：0% 灰度（只有白名单用户）
gray.addGrayUser(12345);
gray.setGrayPercent(0);

// 阶段2：5% 灰度
gray.setGrayPercent(5);

// 阶段3：20% 灰度
gray.setGrayPercent(20);

// 阶段4：50% 灰度
gray.setGrayPercent(50);

// 阶段5：100% 灰度
gray.setGrayPercent(100);
```

### 2. 按地区灰度

```javascript
class RegionGrayRelease {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.grayRegions = new Set();
  }
  
  // 添加灰度地区
  addGrayRegion(region) {
    this.grayRegions.add(region);
  }
  
  // 选择数据库
  getDatabase(region) {
    return this.grayRegions.has(region) ? this.newDb : this.oldDb;
  }
}

// 使用示例
const gray = new RegionGrayRelease(oldDb, newDb);

// 阶段1：北京灰度
gray.addGrayRegion('beijing');

// 阶段2：上海灰度
gray.addGrayRegion('shanghai');

// 阶段3：全国灰度
gray.addGrayRegion('*');
```

## 回滚方案

### 1. 快速回滚

```javascript
class RollbackManager {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.currentDb = newDb;
  }
  
  // 切换到新库
  switchToNew() {
    this.currentDb = this.newDb;
    console.log('已切换到新库');
  }
  
  // 回滚到旧库
  rollback() {
    this.currentDb = this.oldDb;
    console.log('已回滚到旧库');
  }
  
  // 获取当前数据库
  getCurrentDb() {
    return this.currentDb;
  }
}
```

### 2. 数据回滚

```javascript
// 记录变更日志
class ChangeLog {
  constructor(db) {
    this.db = db;
  }
  
  async logChange(operation, tableName, data) {
    await this.db.query(`
      INSERT INTO change_log (operation, table_name, data, created_at)
      VALUES (?, ?, ?, NOW())
    `, [operation, tableName, JSON.stringify(data)]);
  }
  
  async rollbackChanges(startTime, endTime) {
    const logs = await this.db.query(`
      SELECT * FROM change_log
      WHERE created_at BETWEEN ? AND ?
      ORDER BY id DESC
    `, [startTime, endTime]);
    
    for (const log of logs) {
      const data = JSON.parse(log.data);
      
      switch (log.operation) {
        case 'INSERT':
          // 回滚插入：删除数据
          await this.db.delete(log.table_name, { id: data.id });
          break;
        case 'UPDATE':
          // 回滚更新：恢复旧数据
          await this.db.update(log.table_name, data.before, { id: data.id });
          break;
        case 'DELETE':
          // 回滚删除：重新插入
          await this.db.insert(log.table_name, data);
          break;
      }
    }
  }
}
```

## 监控和告警

### 1. 迁移进度监控

```javascript
class MigrationMonitor {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
  }
  
  async getProgress(tableName) {
    const oldCount = await this.oldDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    const newCount = await this.newDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    
    const progress = (newCount.count / oldCount.count * 100).toFixed(2);
    
    return {
      tableName,
      oldCount: oldCount.count,
      newCount: newCount.count,
      progress: `${progress}%`,
    };
  }
  
  async monitorAll(tables) {
    const results = [];
    
    for (const table of tables) {
      const progress = await this.getProgress(table);
      results.push(progress);
      
      console.log(`${table}: ${progress.progress}`);
    }
    
    return results;
  }
}
```

### 2. 性能监控

```javascript
class PerformanceMonitor {
  constructor(db) {
    this.db = db;
  }
  
  async getSlowQueries() {
    return await this.db.query(`
      SELECT 
        query_time,
        lock_time,
        rows_examined,
        sql_text
      FROM mysql.slow_log
      WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR)
      ORDER BY query_time DESC
      LIMIT 10
    `);
  }
  
  async getConnectionCount() {
    const result = await this.db.query('SHOW STATUS LIKE "Threads_connected"');
    return result[0].Value;
  }
  
  async getQPS() {
    const result = await this.db.query('SHOW GLOBAL STATUS LIKE "Questions"');
    return result[0].Value;
  }
}
```

### 3. 告警通知

```javascript
class AlertManager {
  constructor(webhookUrl) {
    this.webhookUrl = webhookUrl;
  }
  
  async sendAlert(title, message, level = 'warning') {
    const payload = {
      title,
      message,
      level,
      timestamp: new Date().toISOString(),
    };
    
    await fetch(this.webhookUrl, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(payload),
    });
  }
  
  async alertDataInconsistency(tableName, details) {
    await this.sendAlert(
      '数据不一致告警',
      `表 ${tableName} 数据不一致: ${details}`,
      'error'
    );
  }
  
  async alertMigrationFailed(error) {
    await this.sendAlert(
      '迁移失败告警',
      `迁移过程出错: ${error.message}`,
      'critical'
    );
  }
}
```

## 最佳实践

### 1. 迁移前准备

```markdown
## 迁移前检查清单

### 数据准备
- [ ] 完整备份原数据库
- [ ] 评估数据量和迁移时间
- [ ] 准备足够的存储空间
- [ ] 测试备份恢复流程

### 环境准备
- [ ] 新数据库环境就绪
- [ ] 网络连通性测试
- [ ] 权限配置正确
- [ ] 监控系统部署

### 应用准备
- [ ] 代码支持双写
- [ ] 配置支持动态切换
- [ ] 准备回滚方案
- [ ] 通知相关人员

### 测试验证
- [ ] 在测试环境完整演练
- [ ] 性能测试通过
- [ ] 数据一致性验证
- [ ] 应用功能测试
```

### 2. 迁移步骤

```markdown
## 迁移执行步骤

### 阶段1：准备阶段（T-7天）
1. 完成所有准备工作
2. 在测试环境完整演练
3. 制定详细的迁移计划

### 阶段2：数据同步（T-3天）
1. 建立主从复制
2. 等待数据完全同步
3. 验证数据一致性

### 阶段3：双写阶段（T-1天）
1. 应用开启双写模式
2. 监控双写性能
3. 验证数据一致性

### 阶段4：灰度切换（T天）
1. 5% 用户切换到新库
2. 监控1小时，无问题继续
3. 20% → 50% → 100% 逐步切换

### 阶段5：清理阶段（T+7天）
1. 确认新库稳定运行
2. 停止双写
3. 下线旧库
```

### 3. 应急预案

```markdown
## 应急预案

### 场景1：数据不一致
- 立即停止写入新库
- 分析不一致原因
- 修复数据后继续

### 场景2：性能下降
- 检查慢查询
- 优化索引
- 必要时回滚

### 场景3：应用报错
- 立即回滚到旧库
- 分析错误日志
- 修复问题后重新迁移

### 场景4：数据丢失
- 立即停止迁移
- 从备份恢复
- 重新开始迁移
```

## 总结

数据库迁移是一个复杂的工程，需要：

1. **充分准备**：备份、测试、演练
2. **灰度发布**：逐步切换，降低风险
3. **实时监控**：及时发现问题
4. **快速回滚**：出现问题立即回滚

## 延伸阅读

- [MySQL 主从复制](https://dev.mysql.com/doc/refman/8.0/en/replication.html)
- [Percona XtraBackup](https://www.percona.com/software/mysql-database/percona-xtrabackup)
- [Canal - 阿里巴巴 MySQL binlog 增量订阅](https://github.com/alibaba/canal)
- [数据库迁移最佳实践](https://aws.amazon.com/cn/dms/resources/)

