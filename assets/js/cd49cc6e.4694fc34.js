"use strict";(globalThis.webpackChunkweuqiangcreate_website=globalThis.webpackChunkweuqiangcreate_website||[]).push([[71982],{50250(n,e,s){s.r(e),s.d(e,{assets:()=>o,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>l,toc:()=>a});const l=JSON.parse('{"id":"\u4eba\u5de5\u667a\u80fd/\u5927\u8bed\u8a00\u6a21\u578b","title":"\u5927\u8bed\u8a00\u6a21\u578b","description":"\u672c\u7ae0\u8282\u4ecb\u7ecd\u5927\u8bed\u8a00\u6a21\u578b\u7684\u539f\u7406\u3001\u67b6\u6784\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u5e94\u7528\uff0c\u6db5\u76d6GPT\u3001BERT\u3001LLaMA\u7b49\u4e3b\u6d41\u6a21\u578b\u3002","source":"@site/docs/docs/\u4eba\u5de5\u667a\u80fd/\u5927\u8bed\u8a00\u6a21\u578b.mdx","sourceDirName":"\u4eba\u5de5\u667a\u80fd","slug":"/\u4eba\u5de5\u667a\u80fd/\u5927\u8bed\u8a00\u6a21\u578b","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u5927\u8bed\u8a00\u6a21\u578b","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10,"title":"\u5927\u8bed\u8a00\u6a21\u578b"},"sidebar":"tutorialSidebar","previous":{"title":"\u81ea\u7136\u8bed\u8a00\u5904\u7406","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u81ea\u7136\u8bed\u8a00\u5904\u7406"},"next":{"title":"\u591a\u6a21\u6001AI","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u591a\u6a21\u6001AI"}}');var r=s(74848),i=s(28453);const t={sidebar_position:10,title:"\u5927\u8bed\u8a00\u6a21\u578b"},d="\u5927\u8bed\u8a00\u6a21\u578b\uff08Large Language Models\uff09",o={},a=[{value:"\u4ec0\u4e48\u662f\u5927\u8bed\u8a00\u6a21\u578b",id:"\u4ec0\u4e48\u662f\u5927\u8bed\u8a00\u6a21\u578b",level:2},{value:"LLM\u7684\u7279\u70b9",id:"llm\u7684\u7279\u70b9",level:3},{value:"LLM\u53d1\u5c55\u5386\u7a0b",id:"llm\u53d1\u5c55\u5386\u7a0b",level:2},{value:"\u7b2c\u4e00\u9636\u6bb5\uff1a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff082018-2019\uff09",id:"\u7b2c\u4e00\u9636\u6bb5\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b2018-2019",level:3},{value:"\u7b2c\u4e8c\u9636\u6bb5\uff1a\u5927\u89c4\u6a21LLM\uff082020-2022\uff09",id:"\u7b2c\u4e8c\u9636\u6bb5\u5927\u89c4\u6a21llm2020-2022",level:3},{value:"\u7b2c\u4e09\u9636\u6bb5\uff1a\u5bf9\u9f50\u4e0e\u5e94\u7528\uff082022-\u81f3\u4eca\uff09",id:"\u7b2c\u4e09\u9636\u6bb5\u5bf9\u9f50\u4e0e\u5e94\u75282022-\u81f3\u4eca",level:3},{value:"LLM\u6838\u5fc3\u6280\u672f",id:"llm\u6838\u5fc3\u6280\u672f",level:2},{value:"1. Transformer\u67b6\u6784",id:"1-transformer\u67b6\u6784",level:3},{value:"2. \u9884\u8bad\u7ec3\u65b9\u6cd5",id:"2-\u9884\u8bad\u7ec3\u65b9\u6cd5",level:3},{value:"3. \u5fae\u8c03\u65b9\u6cd5",id:"3-\u5fae\u8c03\u65b9\u6cd5",level:3},{value:"4. RLHF\uff08\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\uff09",id:"4-rlhf\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60",level:3},{value:"\u4e3b\u6d41LLM\u5bf9\u6bd4",id:"\u4e3b\u6d41llm\u5bf9\u6bd4",level:2},{value:"GPT\u7cfb\u5217",id:"gpt\u7cfb\u5217",level:3},{value:"\u5f00\u6e90LLM",id:"\u5f00\u6e90llm",level:3},{value:"\u5bf9\u6bd4\u8868\u683c",id:"\u5bf9\u6bd4\u8868\u683c",level:3},{value:"LLM\u5e94\u7528\u5f00\u53d1",id:"llm\u5e94\u7528\u5f00\u53d1",level:2},{value:"1. \u4f7f\u7528Transformers\u5e93",id:"1-\u4f7f\u7528transformers\u5e93",level:3},{value:"2. \u4f7f\u7528LangChain",id:"2-\u4f7f\u7528langchain",level:3},{value:"3. RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09",id:"3-rag\u68c0\u7d22\u589e\u5f3a\u751f\u6210",level:3},{value:"4. Function Calling",id:"4-function-calling",level:3},{value:"Prompt Engineering",id:"prompt-engineering",level:2},{value:"\u57fa\u672c\u539f\u5219",id:"\u57fa\u672c\u539f\u5219",level:3},{value:"\u9ad8\u7ea7\u6280\u5de7",id:"\u9ad8\u7ea7\u6280\u5de7",level:3},{value:"\u6a21\u578b\u8bc4\u4f30",id:"\u6a21\u578b\u8bc4\u4f30",level:2},{value:"\u81ea\u52a8\u8bc4\u4f30\u6307\u6807",id:"\u81ea\u52a8\u8bc4\u4f30\u6307\u6807",level:3},{value:"\u4eba\u5de5\u8bc4\u4f30",id:"\u4eba\u5de5\u8bc4\u4f30",level:3},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"1. \u6a21\u578b\u9009\u62e9",id:"1-\u6a21\u578b\u9009\u62e9",level:3},{value:"2. Prompt\u4f18\u5316",id:"2-prompt\u4f18\u5316",level:3},{value:"3. \u5b89\u5168\u6027",id:"3-\u5b89\u5168\u6027",level:3},{value:"4. \u6210\u672c\u4f18\u5316",id:"4-\u6210\u672c\u4f18\u5316",level:3},{value:"\u672a\u6765\u8d8b\u52bf",id:"\u672a\u6765\u8d8b\u52bf",level:2},{value:"\u603b\u7ed3",id:"\u603b\u7ed3",level:2}];function c(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...n.components},{DocCardList:s}=e;return s||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"\u5927\u8bed\u8a00\u6a21\u578blarge-language-models",children:"\u5927\u8bed\u8a00\u6a21\u578b\uff08Large Language Models\uff09"})}),"\n",(0,r.jsx)(e.admonition,{title:"\u7ae0\u8282\u6982\u8ff0",type:"info",children:(0,r.jsx)(e.p,{children:"\u672c\u7ae0\u8282\u4ecb\u7ecd\u5927\u8bed\u8a00\u6a21\u578b\u7684\u539f\u7406\u3001\u67b6\u6784\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u5e94\u7528\uff0c\u6db5\u76d6GPT\u3001BERT\u3001LLaMA\u7b49\u4e3b\u6d41\u6a21\u578b\u3002"})}),"\n",(0,r.jsx)(e.h2,{id:"\u4ec0\u4e48\u662f\u5927\u8bed\u8a00\u6a21\u578b",children:"\u4ec0\u4e48\u662f\u5927\u8bed\u8a00\u6a21\u578b"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09"})," \u662f\u57fa\u4e8eTransformer\u67b6\u6784\uff0c\u5728\u6d77\u91cf\u6587\u672c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5177\u6709\u5f3a\u5927\u7684\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002"]}),"\n",(0,r.jsx)(e.h3,{id:"llm\u7684\u7279\u70b9",children:"LLM\u7684\u7279\u70b9"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u89c4\u6a21\u5316"}),"\uff1a"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u53c2\u6570\u91cf\uff1a\u4ece\u6570\u4ebf\u5230\u6570\u5343\u4ebf\uff08GPT-3: 175B, GPT-4: 1.7T+\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u8bad\u7ec3\u6570\u636e\uff1aTB\u7ea7\u6587\u672c\u6570\u636e"}),"\n",(0,r.jsx)(e.li,{children:"\u8ba1\u7b97\u8d44\u6e90\uff1a\u6570\u5343\u5757GPU/TPU"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u6d8c\u73b0\u80fd\u529b\uff08Emergent Abilities\uff09"}),"\uff1a"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08In-Context Learning\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u601d\u7ef4\u94fe\u63a8\u7406\uff08Chain-of-Thought\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u6307\u4ee4\u9075\u5faa\uff08Instruction Following\uff09"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u901a\u7528\u6027"}),"\uff1a"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u96f6\u6837\u672c\u5b66\u4e60\uff08Zero-Shot\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u5c11\u6837\u672c\u5b66\u4e60\uff08Few-Shot\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u591a\u4efb\u52a1\u5904\u7406"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"llm\u53d1\u5c55\u5386\u7a0b",children:"LLM\u53d1\u5c55\u5386\u7a0b"}),"\n",(0,r.jsx)(e.h3,{id:"\u7b2c\u4e00\u9636\u6bb5\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b2018-2019",children:"\u7b2c\u4e00\u9636\u6bb5\uff1a\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff082018-2019\uff09"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"BERT\uff082018\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u53cc\u5411\u7f16\u7801\u5668"}),"\n",(0,r.jsx)(e.li,{children:"\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08MLM\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"GPT-2\uff082019\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5355\u5411\u89e3\u7801\u5668"}),"\n",(0,r.jsx)(e.li,{children:"\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b"}),"\n",(0,r.jsx)(e.li,{children:"1.5B\u53c2\u6570"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u7b2c\u4e8c\u9636\u6bb5\u5927\u89c4\u6a21llm2020-2022",children:"\u7b2c\u4e8c\u9636\u6bb5\uff1a\u5927\u89c4\u6a21LLM\uff082020-2022\uff09"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"GPT-3\uff082020\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"175B\u53c2\u6570"}),"\n",(0,r.jsx)(e.li,{children:"Few-Shot Learning"}),"\n",(0,r.jsx)(e.li,{children:"\u5f3a\u5927\u7684\u751f\u6210\u80fd\u529b"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"T5\u3001BART\u3001mT5"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784"}),"\n",(0,r.jsx)(e.li,{children:"\u591a\u4efb\u52a1\u7edf\u4e00\u6846\u67b6"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u7b2c\u4e09\u9636\u6bb5\u5bf9\u9f50\u4e0e\u5e94\u75282022-\u81f3\u4eca",children:"\u7b2c\u4e09\u9636\u6bb5\uff1a\u5bf9\u9f50\u4e0e\u5e94\u7528\uff082022-\u81f3\u4eca\uff09"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"ChatGPT\uff082022.11\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u57fa\u4e8eGPT-3.5"}),"\n",(0,r.jsx)(e.li,{children:"RLHF\u5bf9\u9f50"}),"\n",(0,r.jsx)(e.li,{children:"\u5bf9\u8bdd\u80fd\u529b\u7a81\u7834"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"GPT-4\uff082023.03\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u591a\u6a21\u6001\u80fd\u529b"}),"\n",(0,r.jsx)(e.li,{children:"\u66f4\u5f3a\u63a8\u7406\u80fd\u529b"}),"\n",(0,r.jsx)(e.li,{children:"\u66f4\u957f\u4e0a\u4e0b\u6587"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u5f00\u6e90LLM\u7206\u53d1"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"LLaMA\u7cfb\u5217\uff08Meta\uff09"}),"\n",(0,r.jsx)(e.li,{children:"Mistral\u7cfb\u5217"}),"\n",(0,r.jsx)(e.li,{children:"Qwen\u7cfb\u5217\uff08\u963f\u91cc\uff09"}),"\n",(0,r.jsx)(e.li,{children:"ChatGLM\u7cfb\u5217\uff08\u667a\u8c31\uff09"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"llm\u6838\u5fc3\u6280\u672f",children:"LLM\u6838\u5fc3\u6280\u672f"}),"\n",(0,r.jsx)(e.h3,{id:"1-transformer\u67b6\u6784",children:"1. Transformer\u67b6\u6784"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport math\n\nclass MultiHeadAttention(nn.Module):\n    """\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236"""\n    \n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        # Q, K, V\u6295\u5f71\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        \n        # \u8f93\u51fa\u6295\u5f71\n        self.W_o = nn.Linear(d_model, d_model)\n    \n    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n        """\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u529b"""\n        # Q, K, V: (batch, num_heads, seq_len, d_k)\n        \n        # \u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        \n        # \u5e94\u7528mask\uff08\u7528\u4e8e\u56e0\u679c\u6ce8\u610f\u529b\uff09\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n        \n        # Softmax\u5f52\u4e00\u5316\n        attention_weights = torch.softmax(scores, dim=-1)\n        \n        # \u52a0\u6743\u6c42\u548c\n        output = torch.matmul(attention_weights, V)\n        \n        return output, attention_weights\n    \n    def forward(self, x, mask=None):\n        batch_size, seq_len, _ = x.shape\n        \n        # \u7ebf\u6027\u6295\u5f71\u5e76\u5206\u5934\n        Q = self.W_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.W_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.W_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n        \n        # \u6ce8\u610f\u529b\u8ba1\u7b97\n        output, attention_weights = self.scaled_dot_product_attention(Q, K, V, mask)\n        \n        # \u5408\u5e76\u591a\u5934\n        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.d_model)\n        \n        # \u8f93\u51fa\u6295\u5f71\n        output = self.W_o(output)\n        \n        return output, attention_weights\n\n\nclass FeedForward(nn.Module):\n    """\u524d\u9988\u795e\u7ecf\u7f51\u7edc"""\n    \n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.activation = nn.GELU()\n    \n    def forward(self, x):\n        return self.linear2(self.dropout(self.activation(self.linear1(x))))\n\n\nclass TransformerBlock(nn.Module):\n    """Transformer\u5757"""\n    \n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        \n        # \u591a\u5934\u6ce8\u610f\u529b\n        self.attention = MultiHeadAttention(d_model, num_heads)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        \n        # \u524d\u9988\u7f51\u7edc\n        self.ffn = FeedForward(d_model, d_ff, dropout)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout2 = nn.Dropout(dropout)\n    \n    def forward(self, x, mask=None):\n        # \u6ce8\u610f\u529b + \u6b8b\u5dee\u8fde\u63a5\n        attn_output, _ = self.attention(x, mask)\n        x = self.norm1(x + self.dropout1(attn_output))\n        \n        # \u524d\u9988 + \u6b8b\u5dee\u8fde\u63a5\n        ffn_output = self.ffn(x)\n        x = self.norm2(x + self.dropout2(ffn_output))\n        \n        return x\n\n\nclass GPTModel(nn.Module):\n    """\u7b80\u5316\u7684GPT\u6a21\u578b"""\n    \n    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_len, dropout=0.1):\n        super().__init__()\n        \n        self.d_model = d_model\n        \n        # Token\u5d4c\u5165\n        self.token_embedding = nn.Embedding(vocab_size, d_model)\n        \n        # \u4f4d\u7f6e\u7f16\u7801\n        self.position_embedding = nn.Embedding(max_seq_len, d_model)\n        \n        # Transformer\u5757\n        self.blocks = nn.ModuleList([\n            TransformerBlock(d_model, num_heads, d_ff, dropout)\n            for _ in range(num_layers)\n        ])\n        \n        # \u8f93\u51fa\u5c42\n        self.ln_f = nn.LayerNorm(d_model)\n        self.head = nn.Linear(d_model, vocab_size, bias=False)\n        \n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        batch_size, seq_len = x.shape\n        \n        # Token\u5d4c\u5165\n        token_emb = self.token_embedding(x)\n        \n        # \u4f4d\u7f6e\u7f16\u7801\n        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0)\n        pos_emb = self.position_embedding(positions)\n        \n        # \u7ec4\u5408\u5d4c\u5165\n        x = self.dropout(token_emb + pos_emb)\n        \n        # \u56e0\u679cmask\uff08\u9632\u6b62\u770b\u5230\u672a\u6765\u4fe1\u606f\uff09\n        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).unsqueeze(0).unsqueeze(0)\n        \n        # \u901a\u8fc7Transformer\u5757\n        for block in self.blocks:\n            x = block(x, mask)\n        \n        # \u8f93\u51fa\n        x = self.ln_f(x)\n        logits = self.head(x)\n        \n        return logits\n\n# \u521b\u5efa\u6a21\u578b\nmodel = GPTModel(\n    vocab_size=50257,\n    d_model=768,\n    num_heads=12,\n    num_layers=12,\n    d_ff=3072,\n    max_seq_len=1024\n)\n\nprint(f"\u6a21\u578b\u53c2\u6570\u91cf: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u9884\u8bad\u7ec3\u65b9\u6cd5",children:"2. \u9884\u8bad\u7ec3\u65b9\u6cd5"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\uff08GPT\u7cfb\u5217\uff09"}),"\uff1a"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def autoregressive_loss(model, input_ids, labels):\n    """\n    \u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u635f\u5931\n    \u9884\u6d4b\u4e0b\u4e00\u4e2atoken\n    """\n    # \u524d\u5411\u4f20\u64ad\n    logits = model(input_ids)\n    \n    # \u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\n    # logits: (batch, seq_len, vocab_size)\n    # labels: (batch, seq_len)\n    loss = nn.CrossEntropyLoss()(\n        logits.view(-1, logits.size(-1)),\n        labels.view(-1)\n    )\n    \n    return loss\n\n# \u8bad\u7ec3\u793a\u4f8b\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n\nfor batch in dataloader:\n    input_ids = batch[\'input_ids\']\n    labels = batch[\'labels\']\n    \n    # \u524d\u5411\u4f20\u64ad\n    loss = autoregressive_loss(model, input_ids, labels)\n    \n    # \u53cd\u5411\u4f20\u64ad\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff08BERT\u7cfb\u5217\uff09"}),"\uff1a"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def masked_language_model_loss(model, input_ids, labels, mask_token_id):\n    """\n    \u63a9\u7801\u8bed\u8a00\u6a21\u578b\u635f\u5931\n    \u9884\u6d4b\u88abmask\u7684token\n    """\n    # \u968f\u673amask 15%\u7684token\n    mask_prob = 0.15\n    mask = torch.rand(input_ids.shape) < mask_prob\n    \n    # \u4fdd\u5b58\u539f\u59cbtoken\u4f5c\u4e3a\u6807\u7b7e\n    labels = input_ids.clone()\n    labels[~mask] = -100  # \u53ea\u8ba1\u7b97mask\u4f4d\u7f6e\u7684\u635f\u5931\n    \n    # \u66ff\u6362\u4e3a[MASK]\n    input_ids[mask] = mask_token_id\n    \n    # \u524d\u5411\u4f20\u64ad\n    logits = model(input_ids)\n    \n    # \u8ba1\u7b97\u635f\u5931\n    loss = nn.CrossEntropyLoss()(\n        logits.view(-1, logits.size(-1)),\n        labels.view(-1)\n    )\n    \n    return loss\n'})}),"\n",(0,r.jsx)(e.h3,{id:"3-\u5fae\u8c03\u65b9\u6cd5",children:"3. \u5fae\u8c03\u65b9\u6cd5"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5168\u53c2\u6570\u5fae\u8c03\uff08Full Fine-Tuning\uff09"}),"\uff1a"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n\n# \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b\nmodel = AutoModelForCausalLM.from_pretrained("gpt2")\ntokenizer = AutoTokenizer.from_pretrained("gpt2")\n\n# \u51c6\u5907\u6570\u636e\ndef tokenize_function(examples):\n    return tokenizer(examples["text"], truncation=True, max_length=512)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n# \u8bad\u7ec3\u914d\u7f6e\ntraining_args = TrainingArguments(\n    output_dir="./results",\n    num_train_epochs=3,\n    per_device_train_batch_size=4,\n    learning_rate=2e-5,\n    warmup_steps=500,\n    logging_steps=100,\n)\n\n# \u8bad\u7ec3\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets["train"],\n)\n\ntrainer.train()\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"LoRA\uff08Low-Rank Adaptation\uff09"}),"\uff1a"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from peft import LoraConfig, get_peft_model\n\n# LoRA\u914d\u7f6e\nlora_config = LoraConfig(\n    r=8,  # \u79e9\n    lora_alpha=32,\n    target_modules=["q_proj", "v_proj"],  # \u5e94\u7528LoRA\u7684\u6a21\u5757\n    lora_dropout=0.1,\n    bias="none",\n)\n\n# \u5e94\u7528LoRA\nmodel = get_peft_model(model, lora_config)\n\n# \u67e5\u770b\u53ef\u8bad\u7ec3\u53c2\u6570\nmodel.print_trainable_parameters()\n# \u8f93\u51fa: trainable params: 294,912 || all params: 124,439,808 || trainable%: 0.24%\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"P-Tuning / Prompt Tuning"}),"\uff1a"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class PromptTuning(nn.Module):\n    """Prompt Tuning\u5b9e\u73b0"""\n    \n    def __init__(self, model, num_virtual_tokens, embedding_dim):\n        super().__init__()\n        self.model = model\n        self.num_virtual_tokens = num_virtual_tokens\n        \n        # \u53ef\u5b66\u4e60\u7684soft prompt\n        self.soft_prompt = nn.Parameter(\n            torch.randn(num_virtual_tokens, embedding_dim)\n        )\n    \n    def forward(self, input_ids):\n        # \u83b7\u53d6\u8f93\u5165\u5d4c\u5165\n        inputs_embeds = self.model.get_input_embeddings()(input_ids)\n        \n        # \u5728\u524d\u9762\u6dfb\u52a0soft prompt\n        batch_size = inputs_embeds.shape[0]\n        soft_prompt_batch = self.soft_prompt.unsqueeze(0).expand(batch_size, -1, -1)\n        \n        # \u62fc\u63a5\n        inputs_embeds = torch.cat([soft_prompt_batch, inputs_embeds], dim=1)\n        \n        # \u524d\u5411\u4f20\u64ad\n        outputs = self.model(inputs_embeds=inputs_embeds)\n        \n        return outputs\n'})}),"\n",(0,r.jsx)(e.h3,{id:"4-rlhf\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60",children:"4. RLHF\uff08\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\uff09"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class RewardModel(nn.Module):\n    """\u5956\u52b1\u6a21\u578b"""\n    \n    def __init__(self, base_model):\n        super().__init__()\n        self.base_model = base_model\n        self.reward_head = nn.Linear(base_model.config.hidden_size, 1)\n    \n    def forward(self, input_ids):\n        # \u83b7\u53d6\u6700\u540e\u4e00\u5c42\u9690\u85cf\u72b6\u6001\n        outputs = self.base_model(input_ids, output_hidden_states=True)\n        last_hidden_state = outputs.hidden_states[-1]\n        \n        # \u53d6\u6700\u540e\u4e00\u4e2atoken\u7684\u9690\u85cf\u72b6\u6001\n        last_token_hidden = last_hidden_state[:, -1, :]\n        \n        # \u8ba1\u7b97\u5956\u52b1\n        reward = self.reward_head(last_token_hidden)\n        \n        return reward\n\n\ndef ppo_loss(policy_model, ref_model, reward_model, states, actions, old_log_probs):\n    """\n    PPO\u635f\u5931\u51fd\u6570\n    """\n    # \u5f53\u524d\u7b56\u7565\u7684log\u6982\u7387\n    logits = policy_model(states)\n    log_probs = torch.log_softmax(logits, dim=-1)\n    action_log_probs = log_probs.gather(-1, actions.unsqueeze(-1)).squeeze(-1)\n    \n    # \u91cd\u8981\u6027\u91c7\u6837\u6bd4\u7387\n    ratio = torch.exp(action_log_probs - old_log_probs)\n    \n    # \u8ba1\u7b97\u5956\u52b1\n    rewards = reward_model(states)\n    \n    # \u53c2\u8003\u6a21\u578b\u7684KL\u6563\u5ea6\u60e9\u7f5a\n    ref_logits = ref_model(states)\n    ref_log_probs = torch.log_softmax(ref_logits, dim=-1)\n    kl_penalty = torch.sum(\n        torch.exp(log_probs) * (log_probs - ref_log_probs),\n        dim=-1\n    )\n    \n    # PPO\u76ee\u6807\n    advantages = rewards - 0.1 * kl_penalty\n    \n    # Clipped surrogate objective\n    epsilon = 0.2\n    surr1 = ratio * advantages\n    surr2 = torch.clamp(ratio, 1 - epsilon, 1 + epsilon) * advantages\n    \n    loss = -torch.min(surr1, surr2).mean()\n    \n    return loss\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u4e3b\u6d41llm\u5bf9\u6bd4",children:"\u4e3b\u6d41LLM\u5bf9\u6bd4"}),"\n",(0,r.jsx)(e.h3,{id:"gpt\u7cfb\u5217",children:"GPT\u7cfb\u5217"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"GPT-3.5 / GPT-4"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u67b6\u6784"}),": Decoder-only Transformer"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u53c2\u6570"}),": GPT-3.5: 175B, GPT-4: 1.7T+"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u7279\u70b9"}),":","\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5f3a\u5927\u7684\u751f\u6210\u80fd\u529b"}),"\n",(0,r.jsx)(e.li,{children:"\u4e0a\u4e0b\u6587\u5b66\u4e60"}),"\n",(0,r.jsx)(e.li,{children:"\u591a\u6a21\u6001\uff08GPT-4\uff09"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u5e94\u7528"}),": ChatGPT, API\u670d\u52a1"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u5f00\u6e90llm",children:"\u5f00\u6e90LLM"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"LLaMA\u7cfb\u5217\uff08Meta\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from transformers import LlamaForCausalLM, LlamaTokenizer\n\n# \u52a0\u8f7dLLaMA\u6a21\u578b\nmodel = LlamaForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")\ntokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")\n\n# \u751f\u6210\u6587\u672c\nprompt = "Once upon a time"\ninputs = tokenizer(prompt, return_tensors="pt")\noutputs = model.generate(**inputs, max_length=100)\ntext = tokenizer.decode(outputs[0])\nprint(text)\n'})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u7279\u70b9"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5f00\u6e90\u53ef\u5546\u7528"}),"\n",(0,r.jsx)(e.li,{children:"\u591a\u79cd\u89c4\u6a21\uff087B, 13B, 70B\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u4f18\u79c0\u7684\u6027\u80fd"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Mistral\u7cfb\u5217"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Mistral-7B: \u6027\u80fd\u8d85\u8d8aLLaMA-13B"}),"\n",(0,r.jsx)(e.li,{children:"Mixtral-8x7B: MoE\u67b6\u6784"}),"\n",(0,r.jsx)(e.li,{children:"\u957f\u4e0a\u4e0b\u6587\u652f\u6301\uff0832K\uff09"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Qwen\u7cfb\u5217\uff08\u963f\u91cc\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u591a\u8bed\u8a00\u652f\u6301"}),"\n",(0,r.jsx)(e.li,{children:"\u4ee3\u7801\u80fd\u529b\u5f3a"}),"\n",(0,r.jsx)(e.li,{children:"\u5de5\u5177\u8c03\u7528"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u5bf9\u6bd4\u8868\u683c",children:"\u5bf9\u6bd4\u8868\u683c"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u6a21\u578b"}),(0,r.jsx)(e.th,{children:"\u53c2\u6570\u91cf"}),(0,r.jsx)(e.th,{children:"\u4e0a\u4e0b\u6587\u957f\u5ea6"}),(0,r.jsx)(e.th,{children:"\u5f00\u6e90"}),(0,r.jsx)(e.th,{children:"\u591a\u6a21\u6001"}),(0,r.jsx)(e.th,{children:"\u7279\u70b9"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"GPT-4"}),(0,r.jsx)(e.td,{children:"1.7T+"}),(0,r.jsx)(e.td,{children:"128K"}),(0,r.jsx)(e.td,{children:"\u274c"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u6700\u5f3a\u6027\u80fd"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Claude 3"}),(0,r.jsx)(e.td,{children:"?"}),(0,r.jsx)(e.td,{children:"200K"}),(0,r.jsx)(e.td,{children:"\u274c"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u957f\u4e0a\u4e0b\u6587"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Gemini Pro"}),(0,r.jsx)(e.td,{children:"?"}),(0,r.jsx)(e.td,{children:"32K"}),(0,r.jsx)(e.td,{children:"\u274c"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"Google"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"LLaMA-2-70B"}),(0,r.jsx)(e.td,{children:"70B"}),(0,r.jsx)(e.td,{children:"4K"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u274c"}),(0,r.jsx)(e.td,{children:"\u5f00\u6e90\u6807\u6746"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Mistral-7B"}),(0,r.jsx)(e.td,{children:"7B"}),(0,r.jsx)(e.td,{children:"32K"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u274c"}),(0,r.jsx)(e.td,{children:"\u9ad8\u6027\u4ef7\u6bd4"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"Qwen-72B"}),(0,r.jsx)(e.td,{children:"72B"}),(0,r.jsx)(e.td,{children:"32K"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u2705"}),(0,r.jsx)(e.td,{children:"\u4e2d\u6587\u53cb\u597d"})]})]})]}),"\n",(0,r.jsx)(e.h2,{id:"llm\u5e94\u7528\u5f00\u53d1",children:"LLM\u5e94\u7528\u5f00\u53d1"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u4f7f\u7528transformers\u5e93",children:"1. \u4f7f\u7528Transformers\u5e93"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from transformers import pipeline\n\n# \u6587\u672c\u751f\u6210\ngenerator = pipeline("text-generation", model="gpt2")\nresult = generator("The future of AI is", max_length=50, num_return_sequences=3)\n\nfor i, text in enumerate(result):\n    print(f"\\n\u751f\u6210{i+1}: {text[\'generated_text\']}")\n\n# \u95ee\u7b54\nqa_pipeline = pipeline("question-answering")\ncontext = "Paris is the capital of France. It is known for the Eiffel Tower."\nquestion = "What is Paris known for?"\nanswer = qa_pipeline(question=question, context=context)\nprint(f"\u7b54\u6848: {answer[\'answer\']}")\n\n# \u6587\u672c\u5206\u7c7b\nclassifier = pipeline("sentiment-analysis")\nresult = classifier("I love this product!")\nprint(result)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u4f7f\u7528langchain",children:"2. \u4f7f\u7528LangChain"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\n\n# \u521b\u5efaLLM\nllm = OpenAI(temperature=0.7)\n\n# \u521b\u5efaPrompt\u6a21\u677f\ntemplate = """\n\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684{role}\u3002\n\u8bf7\u56de\u7b54\u4ee5\u4e0b\u95ee\u9898\uff1a{question}\n"""\n\nprompt = PromptTemplate(\n    input_variables=["role", "question"],\n    template=template\n)\n\n# \u521b\u5efaChain\nchain = LLMChain(llm=llm, prompt=prompt)\n\n# \u8fd0\u884c\nresult = chain.run(role="Python\u7a0b\u5e8f\u5458", question="\u5982\u4f55\u4f18\u5316\u4ee3\u7801\u6027\u80fd\uff1f")\nprint(result)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"3-rag\u68c0\u7d22\u589e\u5f3a\u751f\u6210",children:"3. RAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\n\n# \u51c6\u5907\u6587\u6863\ndocuments = [\n    "Python\u662f\u4e00\u79cd\u9ad8\u7ea7\u7f16\u7a0b\u8bed\u8a00\u3002",\n    "\u673a\u5668\u5b66\u4e60\u662f\u4eba\u5de5\u667a\u80fd\u7684\u4e00\u4e2a\u5206\u652f\u3002",\n    "\u6df1\u5ea6\u5b66\u4e60\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u3002"\n]\n\n# \u521b\u5efa\u5411\u91cf\u6570\u636e\u5e93\nembeddings = OpenAIEmbeddings()\nvectorstore = FAISS.from_texts(documents, embeddings)\n\n# \u521b\u5efa\u68c0\u7d22QA\u94fe\nqa_chain = RetrievalQA.from_chain_type(\n    llm=OpenAI(),\n    chain_type="stuff",\n    retriever=vectorstore.as_retriever()\n)\n\n# \u67e5\u8be2\nquery = "\u4ec0\u4e48\u662f\u6df1\u5ea6\u5b66\u4e60\uff1f"\nanswer = qa_chain.run(query)\nprint(answer)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"4-function-calling",children:"4. Function Calling"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import json\nfrom openai import OpenAI\n\nclient = OpenAI()\n\n# \u5b9a\u4e49\u51fd\u6570\nfunctions = [\n    {\n        "name": "get_weather",\n        "description": "\u83b7\u53d6\u6307\u5b9a\u57ce\u5e02\u7684\u5929\u6c14",\n        "parameters": {\n            "type": "object",\n            "properties": {\n                "city": {\n                    "type": "string",\n                    "description": "\u57ce\u5e02\u540d\u79f0"\n                }\n            },\n            "required": ["city"]\n        }\n    }\n]\n\n# \u8c03\u7528\nresponse = client.chat.completions.create(\n    model="gpt-4",\n    messages=[{"role": "user", "content": "\u5317\u4eac\u4eca\u5929\u5929\u6c14\u600e\u4e48\u6837\uff1f"}],\n    functions=functions,\n    function_call="auto"\n)\n\n# \u5904\u7406\u51fd\u6570\u8c03\u7528\nif response.choices[0].message.function_call:\n    function_name = response.choices[0].message.function_call.name\n    arguments = json.loads(response.choices[0].message.function_call.arguments)\n    \n    print(f"\u8c03\u7528\u51fd\u6570: {function_name}")\n    print(f"\u53c2\u6570: {arguments}")\n'})}),"\n",(0,r.jsx)(e.h2,{id:"prompt-engineering",children:"Prompt Engineering"}),"\n",(0,r.jsx)(e.h3,{id:"\u57fa\u672c\u539f\u5219",children:"\u57fa\u672c\u539f\u5219"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"1. \u6e05\u6670\u660e\u786e"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u274c \u5dee: \u5199\u70b9\u4e1c\u897f\n\u2705 \u597d: \u5199\u4e00\u7bc7500\u5b57\u7684\u6587\u7ae0\uff0c\u4ecb\u7ecd\u4eba\u5de5\u667a\u80fd\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"2. \u63d0\u4f9b\u4e0a\u4e0b\u6587"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u4f60\u662f\u4e00\u4e2a\u4e13\u4e1a\u7684Python\u7a0b\u5e8f\u5458\u3002\n\u7528\u6237\u662f\u521d\u5b66\u8005\uff0c\u9700\u8981\u7b80\u5355\u6613\u61c2\u7684\u89e3\u91ca\u3002\n\u8bf7\u89e3\u91ca\u4ec0\u4e48\u662f\u5217\u8868\u63a8\u5bfc\u5f0f\uff0c\u5e76\u7ed9\u51fa3\u4e2a\u5b9e\u7528\u4f8b\u5b50\u3002\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"3. \u4f7f\u7528\u793a\u4f8b\uff08Few-Shot\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u5c06\u4ee5\u4e0b\u53e5\u5b50\u7ffb\u8bd1\u6210\u82f1\u6587\uff1a\n\n\u8f93\u5165: \u4eca\u5929\u5929\u6c14\u5f88\u597d\n\u8f93\u51fa: The weather is nice today\n\n\u8f93\u5165: \u6211\u559c\u6b22\u7f16\u7a0b\n\u8f93\u51fa: I love programming\n\n\u8f93\u5165: \u4eba\u5de5\u667a\u80fd\u5f88\u6709\u8da3\n\u8f93\u51fa:\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u9ad8\u7ea7\u6280\u5de7",children:"\u9ad8\u7ea7\u6280\u5de7"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u601d\u7ef4\u94fe\uff08Chain-of-Thought\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u95ee\u9898: \u4e00\u4e2a\u5546\u5e97\u670923\u4e2a\u82f9\u679c\uff0c\u5356\u51fa\u4e8617\u4e2a\uff0c\u53c8\u8fdb\u4e8630\u4e2a\uff0c\u73b0\u5728\u6709\u591a\u5c11\u4e2a\uff1f\n\n\u8ba9\u6211\u4eec\u4e00\u6b65\u6b65\u601d\u8003:\n1. \u521d\u59cb: 23\u4e2a\u82f9\u679c\n2. \u5356\u51fa17\u4e2a\u540e: 23 - 17 = 6\u4e2a\n3. \u53c8\u8fdb30\u4e2a\u540e: 6 + 30 = 36\u4e2a\n\n\u7b54\u6848: 36\u4e2a\u82f9\u679c\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u81ea\u6211\u4e00\u81f4\u6027\uff08Self-Consistency\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# \u751f\u6210\u591a\u4e2a\u7b54\u6848\uff0c\u9009\u62e9\u6700\u4e00\u81f4\u7684\nanswers = []\nfor _ in range(5):\n    response = llm.generate(prompt)\n    answers.append(response)\n\n# \u6295\u7968\u9009\u62e9\u6700\u5e38\u89c1\u7684\u7b54\u6848\nfrom collections import Counter\nmost_common = Counter(answers).most_common(1)[0][0]\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"ReAct\uff08\u63a8\u7406+\u884c\u52a8\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u95ee\u9898: 2024\u5e74\u5965\u8fd0\u4f1a\u5728\u54ea\u91cc\u4e3e\u529e\uff1f\n\n\u601d\u8003: \u6211\u9700\u8981\u67e5\u627e2024\u5e74\u5965\u8fd0\u4f1a\u7684\u4e3e\u529e\u5730\n\u884c\u52a8: \u641c\u7d22[2024\u5e74\u5965\u8fd0\u4f1a\u4e3e\u529e\u5730]\n\u89c2\u5bdf: 2024\u5e74\u590f\u5b63\u5965\u8fd0\u4f1a\u5c06\u5728\u6cd5\u56fd\u5df4\u9ece\u4e3e\u529e\n\u601d\u8003: \u6211\u5df2\u7ecf\u627e\u5230\u4e86\u7b54\u6848\n\u7b54\u6848: 2024\u5e74\u5965\u8fd0\u4f1a\u5728\u6cd5\u56fd\u5df4\u9ece\u4e3e\u529e\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\u6a21\u578b\u8bc4\u4f30",children:"\u6a21\u578b\u8bc4\u4f30"}),"\n",(0,r.jsx)(e.h3,{id:"\u81ea\u52a8\u8bc4\u4f30\u6307\u6807",children:"\u81ea\u52a8\u8bc4\u4f30\u6307\u6807"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u56f0\u60d1\u5ea6\uff08Perplexity\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'def calculate_perplexity(model, tokenizer, text):\n    """\u8ba1\u7b97\u56f0\u60d1\u5ea6"""\n    encodings = tokenizer(text, return_tensors=\'pt\')\n    \n    with torch.no_grad():\n        outputs = model(**encodings, labels=encodings[\'input_ids\'])\n        loss = outputs.loss\n    \n    perplexity = torch.exp(loss)\n    return perplexity.item()\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"BLEU\uff08\u673a\u5668\u7ffb\u8bd1\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"from nltk.translate.bleu_score import sentence_bleu\n\nreference = [['this', 'is', 'a', 'test']]\ncandidate = ['this', 'is', 'test']\n\nscore = sentence_bleu(reference, candidate)\nprint(f'BLEU score: {score}')\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"ROUGE\uff08\u6587\u672c\u6458\u8981\uff09"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from rouge import Rouge\n\nrouge = Rouge()\n\nhypothesis = "the cat is on the mat"\nreference = "the cat sat on the mat"\n\nscores = rouge.get_scores(hypothesis, reference)\nprint(scores)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\u4eba\u5de5\u8bc4\u4f30",children:"\u4eba\u5de5\u8bc4\u4f30"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u8bc4\u4f30\u7ef4\u5ea6"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u51c6\u786e\u6027\uff08Accuracy\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u6d41\u7545\u6027\uff08Fluency\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u76f8\u5173\u6027\uff08Relevance\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u4e00\u81f4\u6027\uff08Consistency\uff09"}),"\n",(0,r.jsx)(e.li,{children:"\u5b89\u5168\u6027\uff08Safety\uff09"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u6a21\u578b\u9009\u62e9",children:"1. \u6a21\u578b\u9009\u62e9"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u4efb\u52a1\u590d\u6742\u5ea6"}),": \u7b80\u5355\u4efb\u52a1\u7528\u5c0f\u6a21\u578b\uff0c\u590d\u6742\u4efb\u52a1\u7528\u5927\u6a21\u578b"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u6210\u672c\u8003\u8651"}),": \u5e73\u8861\u6027\u80fd\u548c\u6210\u672c"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u5ef6\u8fdf\u8981\u6c42"}),": \u5b9e\u65f6\u5e94\u7528\u9009\u62e9\u5feb\u901f\u6a21\u578b"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u9690\u79c1\u8981\u6c42"}),": \u654f\u611f\u6570\u636e\u4f7f\u7528\u672c\u5730\u90e8\u7f72"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-prompt\u4f18\u5316",children:"2. Prompt\u4f18\u5316"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u8fed\u4ee3\u6d4b\u8bd5\u4e0d\u540c\u7684prompt"}),"\n",(0,r.jsx)(e.li,{children:"\u4f7f\u7528\u6e29\u5ea6\u53c2\u6570\u63a7\u5236\u521b\u9020\u6027"}),"\n",(0,r.jsx)(e.li,{children:"\u8bbe\u7f6e\u5408\u7406\u7684max_tokens"}),"\n",(0,r.jsx)(e.li,{children:"\u4f7f\u7528stop sequences"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"3-\u5b89\u5168\u6027",children:"3. \u5b89\u5168\u6027"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u5185\u5bb9\u8fc7\u6ee4"}),"\n",(0,r.jsx)(e.li,{children:"\u8f93\u5165\u9a8c\u8bc1"}),"\n",(0,r.jsx)(e.li,{children:"\u8f93\u51fa\u5ba1\u6838"}),"\n",(0,r.jsx)(e.li,{children:"\u9632\u6b62prompt\u6ce8\u5165"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"4-\u6210\u672c\u4f18\u5316",children:"4. \u6210\u672c\u4f18\u5316"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7f13\u5b58\u5e38\u89c1\u67e5\u8be2"}),"\n",(0,r.jsx)(e.li,{children:"\u6279\u5904\u7406\u8bf7\u6c42"}),"\n",(0,r.jsx)(e.li,{children:"\u4f7f\u7528\u66f4\u5c0f\u7684\u6a21\u578b"}),"\n",(0,r.jsx)(e.li,{children:"\u4f18\u5316prompt\u957f\u5ea6"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u672a\u6765\u8d8b\u52bf",children:"\u672a\u6765\u8d8b\u52bf"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u66f4\u5927\u7684\u6a21\u578b"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u53c2\u6570\u91cf\u6301\u7eed\u589e\u957f"}),"\n",(0,r.jsx)(e.li,{children:"\u66f4\u5f3a\u7684\u6d8c\u73b0\u80fd\u529b"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u66f4\u957f\u7684\u4e0a\u4e0b\u6587"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u4ece4K\u5230100K+"}),"\n",(0,r.jsx)(e.li,{children:"\u5904\u7406\u66f4\u590d\u6742\u7684\u4efb\u52a1"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u591a\u6a21\u6001\u878d\u5408"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u6587\u672c+\u56fe\u50cf+\u97f3\u9891+\u89c6\u9891"}),"\n",(0,r.jsx)(e.li,{children:"\u7edf\u4e00\u7684\u591a\u6a21\u6001\u6a21\u578b"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u66f4\u597d\u7684\u5bf9\u9f50"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u66f4\u5b89\u5168\u3001\u66f4\u6709\u7528"}),"\n",(0,r.jsx)(e.li,{children:"\u51cf\u5c11\u5e7b\u89c9"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u6548\u7387\u63d0\u5347"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u91cf\u5316\u3001\u526a\u679d"}),"\n",(0,r.jsx)(e.li,{children:"\u66f4\u5feb\u7684\u63a8\u7406\u901f\u5ea6"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u603b\u7ed3",children:"\u603b\u7ed3"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5173\u952e\u8981\u70b9"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"LLM\u57fa\u4e8eTransformer\u67b6\u6784"}),"\n",(0,r.jsx)(e.li,{children:"\u9884\u8bad\u7ec3+\u5fae\u8c03\u662f\u4e3b\u6d41\u8303\u5f0f"}),"\n",(0,r.jsx)(e.li,{children:"RLHF\u5b9e\u73b0\u4eba\u7c7b\u5bf9\u9f50"}),"\n",(0,r.jsx)(e.li,{children:"Prompt Engineering\u5f88\u91cd\u8981"}),"\n",(0,r.jsx)(e.li,{children:"\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u548c\u65b9\u6cd5"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5b66\u4e60\u5efa\u8bae"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7406\u89e3Transformer\u539f\u7406"}),"\n",(0,r.jsx)(e.li,{children:"\u5b9e\u8df5\u4e0d\u540c\u7684\u5fae\u8c03\u65b9\u6cd5"}),"\n",(0,r.jsx)(e.li,{children:"\u5b66\u4e60Prompt Engineering"}),"\n",(0,r.jsx)(e.li,{children:"\u5173\u6ce8\u6700\u65b0\u7814\u7a76\u8fdb\u5c55"}),"\n"]}),"\n",(0,r.jsx)(s,{})]})}function h(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(c,{...n})}):c(n)}},28453(n,e,s){s.d(e,{R:()=>t,x:()=>d});var l=s(96540);const r={},i=l.createContext(r);function t(n){const e=l.useContext(i);return l.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function d(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:t(n.components),l.createElement(i.Provider,{value:e},n.children)}}}]);