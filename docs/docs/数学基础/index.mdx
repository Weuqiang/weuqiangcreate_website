---
sidebar_position: 2
title: 
---

import DocCardList from '@theme/DocCardList';

#  - AI

"AI"****

## 


- 
- 
- 

AI""

## 

### 1.  - AI

****

```python
# 
output = model(input)

# 
output = W3 @ (W2 @ (W1 @ input + b1) + b2) + b3
```

****
- 
- 
- 
- 

### 2.  - 

****AI

```python
# AI
predictions = [0.7, 0.2, 0.1]  # [, , ]
# """70%"
```

****
- 
- 
- 
- 

### 3.  - 

****

```python
# 
for epoch in range(1000):
    loss = compute_loss(model, data)
    grad = compute_gradient(loss)  # 
    model.params -= learning_rate * grad  # 
```

****
- 
- 
- 
- 

### 4.  - 

****

```python
# 
loss = -sum(y_true * log(y_pred))
# 
```

****
- KL
- 
- 
- 

### 5.  - 

****

```python
# 
SGD, Momentum, Adam, AdaGrad...
# 
```

****
- 
- 
- 
- 

## 

###  

1. ****
2. ****
3. ****

###  

1. ****
2. ****
3. ****

## 

```mermaid
graph LR
    A[] --> D[]
    B[] --> D
    C[] --> D
    D --> E[]
    F[] --> E
    G[] --> E
```

### 2-3

1. ****
2. ****
3. ****

****

### 2-3

4. ****KL
5. ****Adam

****

### 

- 
- 
- Transformer
- 

## 

### 1. 



```python
# 
θ = θ - α∇J(θ)

# 
 =  -  × 
```

### 2. 



```python
# 
def gradient_descent(f, df, x0, lr=0.1, steps=100):
    x = x0
    for _ in range(steps):
        x = x - lr * df(x)
    return x
```

### 3. 



```python
import matplotlib.pyplot as plt

# 
x = np.linspace(-5, 5, 100)
y = x**2
plt.plot(x, y)
plt.show()
```

### 4. 



- → 
- → 
- AdamSGD→ 

## 

### Python

```python
import numpy as np        # 
import scipy as sp        # 
import matplotlib.pyplot as plt  # 
import sympy as sym       # 
```

### 

- **3Blue1Brown**
- **Khan Academy**
- **MIT OpenCourseWare**

### 

- - 3Blue1Brown
- - 
- - Goodfellow

## 

### Q: AI

**A**: ********

- 
- 
- 

### Q: 

**A**: 

- ****
- ****
- ****

### Q: 

**A**: 

- ****12
- ****3
- ****

### Q: 

**A**: ****

```python
# 
# 
```

## 



<DocCardList />

****AI



