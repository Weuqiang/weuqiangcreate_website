"use strict";(globalThis.webpackChunkweuqiangcreate_website=globalThis.webpackChunkweuqiangcreate_website||[]).push([[55452],{44474(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>p,frontMatter:()=>l,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"\u4eba\u5de5\u667a\u80fd/\u751f\u6210\u5f0fAI","title":"\u751f\u6210\u5f0fAI (AIGC)","description":"\u672c\u7ae0\u8282\u4ecb\u7ecd\u751f\u6210\u5f0fAI\u7684\u539f\u7406\u548c\u5e94\u7528\uff0c\u6db5\u76d6\u6587\u672c\u751f\u6210\u3001\u56fe\u50cf\u751f\u6210\u3001\u89c6\u9891\u751f\u6210\u3001\u97f3\u4e50\u751f\u6210\u7b49\u524d\u6cbf\u6280\u672f\u3002","source":"@site/docs/docs/\u4eba\u5de5\u667a\u80fd/\u751f\u6210\u5f0fAI.mdx","sourceDirName":"\u4eba\u5de5\u667a\u80fd","slug":"/\u4eba\u5de5\u667a\u80fd/\u751f\u6210\u5f0fAI","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u751f\u6210\u5f0fAI","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":13,"frontMatter":{"sidebar_position":13,"title":"\u751f\u6210\u5f0fAI (AIGC)"},"sidebar":"tutorialSidebar","previous":{"title":"AI Agent\u667a\u80fd\u4f53","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/AI-Agent"},"next":{"title":"AI\u5b9e\u6218\u9879\u76ee","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/AI\u5b9e\u6218\u9879\u76ee"}}');var r=i(74848),s=i(28453);const l={sidebar_position:13,title:"\u751f\u6210\u5f0fAI (AIGC)"},a="\u751f\u6210\u5f0fAI\uff08AIGC\uff09",o={},d=[{value:"\u4ec0\u4e48\u662f\u751f\u6210\u5f0fAI",id:"\u4ec0\u4e48\u662f\u751f\u6210\u5f0fai",level:2},{value:"AIGC vs \u5224\u522b\u5f0fAI",id:"aigc-vs-\u5224\u522b\u5f0fai",level:3},{value:"\u6838\u5fc3\u6280\u672f",id:"\u6838\u5fc3\u6280\u672f",level:2},{value:"1. \u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09",id:"1-\u751f\u6210\u5bf9\u6297\u7f51\u7edcgan",level:3},{value:"2. \u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09",id:"2-\u53d8\u5206\u81ea\u7f16\u7801\u5668vae",level:3},{value:"3. Diffusion\u6a21\u578b",id:"3-diffusion\u6a21\u578b",level:3},{value:"\u6587\u672c\u751f\u6210",id:"\u6587\u672c\u751f\u6210",level:2},{value:"1. GPT\u7cfb\u5217",id:"1-gpt\u7cfb\u5217",level:3},{value:"2. \u521b\u610f\u5199\u4f5c",id:"2-\u521b\u610f\u5199\u4f5c",level:3},{value:"\u56fe\u50cf\u751f\u6210",id:"\u56fe\u50cf\u751f\u6210",level:2},{value:"1. Stable Diffusion",id:"1-stable-diffusion",level:3},{value:"2. DALL-E",id:"2-dall-e",level:3},{value:"\u89c6\u9891\u751f\u6210",id:"\u89c6\u9891\u751f\u6210",level:2},{value:"1. \u6587\u672c\u5230\u89c6\u9891",id:"1-\u6587\u672c\u5230\u89c6\u9891",level:3},{value:"\u97f3\u4e50\u751f\u6210",id:"\u97f3\u4e50\u751f\u6210",level:2},{value:"1. MusicGen",id:"1-musicgen",level:3},{value:"\u5e94\u7528\u573a\u666f",id:"\u5e94\u7528\u573a\u666f",level:2},{value:"1. \u5185\u5bb9\u521b\u4f5c",id:"1-\u5185\u5bb9\u521b\u4f5c",level:3},{value:"2. \u8bbe\u8ba1\u8f85\u52a9",id:"2-\u8bbe\u8ba1\u8f85\u52a9",level:3},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"1. Prompt\u5de5\u7a0b",id:"1-prompt\u5de5\u7a0b",level:3},{value:"2. \u8d28\u91cf\u63a7\u5236",id:"2-\u8d28\u91cf\u63a7\u5236",level:3},{value:"\u672a\u6765\u8d8b\u52bf",id:"\u672a\u6765\u8d8b\u52bf",level:2},{value:"\u603b\u7ed3",id:"\u603b\u7ed3",level:2}];function c(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components},{DocCardList:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"\u751f\u6210\u5f0faiaigc",children:"\u751f\u6210\u5f0fAI\uff08AIGC\uff09"})}),"\n",(0,r.jsx)(n.admonition,{title:"\u7ae0\u8282\u6982\u8ff0",type:"info",children:(0,r.jsx)(n.p,{children:"\u672c\u7ae0\u8282\u4ecb\u7ecd\u751f\u6210\u5f0fAI\u7684\u539f\u7406\u548c\u5e94\u7528\uff0c\u6db5\u76d6\u6587\u672c\u751f\u6210\u3001\u56fe\u50cf\u751f\u6210\u3001\u89c6\u9891\u751f\u6210\u3001\u97f3\u4e50\u751f\u6210\u7b49\u524d\u6cbf\u6280\u672f\u3002"})}),"\n",(0,r.jsx)(n.h2,{id:"\u4ec0\u4e48\u662f\u751f\u6210\u5f0fai",children:"\u4ec0\u4e48\u662f\u751f\u6210\u5f0fAI"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"\u751f\u6210\u5f0fAI\uff08Generative AI, AIGC\uff09"})," \u662f\u80fd\u591f\u521b\u9020\u65b0\u5185\u5bb9\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u5305\u62ec\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u3001\u89c6\u9891\u7b49\u3002"]}),"\n",(0,r.jsx)(n.h3,{id:"aigc-vs-\u5224\u522b\u5f0fai",children:"AIGC vs \u5224\u522b\u5f0fAI"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"\u7279\u6027"}),(0,r.jsx)(n.th,{children:"\u5224\u522b\u5f0fAI"}),(0,r.jsx)(n.th,{children:"\u751f\u6210\u5f0fAI"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u76ee\u6807"}),(0,r.jsx)(n.td,{children:"\u5206\u7c7b/\u9884\u6d4b"}),(0,r.jsx)(n.td,{children:"\u751f\u6210\u65b0\u5185\u5bb9"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u8f93\u51fa"}),(0,r.jsx)(n.td,{children:"\u6807\u7b7e/\u6570\u503c"}),(0,r.jsx)(n.td,{children:"\u6587\u672c/\u56fe\u50cf/\u97f3\u9891"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u5e94\u7528"}),(0,r.jsx)(n.td,{children:"\u8bc6\u522b\u3001\u68c0\u6d4b"}),(0,r.jsx)(n.td,{children:"\u521b\u4f5c\u3001\u8bbe\u8ba1"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"\u793a\u4f8b"}),(0,r.jsx)(n.td,{children:"\u56fe\u50cf\u5206\u7c7b"}),(0,r.jsx)(n.td,{children:"\u56fe\u50cf\u751f\u6210"})]})]})]}),"\n",(0,r.jsx)(n.h2,{id:"\u6838\u5fc3\u6280\u672f",children:"\u6838\u5fc3\u6280\u672f"}),"\n",(0,r.jsx)(n.h3,{id:"1-\u751f\u6210\u5bf9\u6297\u7f51\u7edcgan",children:"1. \u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\n\nclass Generator(nn.Module):\n    """\u751f\u6210\u5668"""\n    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):\n        super().__init__()\n        self.img_shape = img_shape\n        \n        self.model = nn.Sequential(\n            nn.Linear(latent_dim, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 256),\n            nn.BatchNorm1d(256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 512),\n            nn.BatchNorm1d(512),\n            nn.LeakyReLU(0.2),\n            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),\n            nn.Tanh()\n        )\n    \n    def forward(self, z):\n        img = self.model(z)\n        img = img.view(img.size(0), *self.img_shape)\n        return img\n\n\nclass Discriminator(nn.Module):\n    """\u5224\u522b\u5668"""\n    def __init__(self, img_shape=(1, 28, 28)):\n        super().__init__()\n        \n        self.model = nn.Sequential(\n            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),\n            nn.LeakyReLU(0.2),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n        return validity\n\n\n# \u8bad\u7ec3GAN\ndef train_gan(generator, discriminator, dataloader, epochs=100):\n    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)\n    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n    adversarial_loss = nn.BCELoss()\n    \n    for epoch in range(epochs):\n        for i, (imgs, _) in enumerate(dataloader):\n            batch_size = imgs.size(0)\n            \n            # \u771f\u5b9e\u548c\u5047\u6807\u7b7e\n            real = torch.ones(batch_size, 1)\n            fake = torch.zeros(batch_size, 1)\n            \n            # \u8bad\u7ec3\u5224\u522b\u5668\n            optimizer_D.zero_grad()\n            \n            # \u771f\u5b9e\u56fe\u50cf\n            real_loss = adversarial_loss(discriminator(imgs), real)\n            \n            # \u751f\u6210\u5047\u56fe\u50cf\n            z = torch.randn(batch_size, 100)\n            gen_imgs = generator(z)\n            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n            \n            d_loss = (real_loss + fake_loss) / 2\n            d_loss.backward()\n            optimizer_D.step()\n            \n            # \u8bad\u7ec3\u751f\u6210\u5668\n            optimizer_G.zero_grad()\n            \n            g_loss = adversarial_loss(discriminator(gen_imgs), real)\n            g_loss.backward()\n            optimizer_G.step()\n        \n        print(f"Epoch {epoch}: D_loss={d_loss.item():.4f}, G_loss={g_loss.item():.4f}")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-\u53d8\u5206\u81ea\u7f16\u7801\u5668vae",children:"2. \u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class VAE(nn.Module):\n    """\u53d8\u5206\u81ea\u7f16\u7801\u5668"""\n    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n        super().__init__()\n        \n        # \u7f16\u7801\u5668\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n        \n        # \u89e3\u7801\u5668\n        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n        self.fc4 = nn.Linear(hidden_dim, input_dim)\n    \n    def encode(self, x):\n        h = torch.relu(self.fc1(x))\n        return self.fc_mu(h), self.fc_logvar(h)\n    \n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5 * logvar)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n    \n    def decode(self, z):\n        h = torch.relu(self.fc3(z))\n        return torch.sigmoid(self.fc4(h))\n    \n    def forward(self, x):\n        mu, logvar = self.encode(x.view(-1, 784))\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n\ndef vae_loss(recon_x, x, mu, logvar):\n    """VAE\u635f\u5931\u51fd\u6570"""\n    # \u91cd\u5efa\u635f\u5931\n    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction=\'sum\')\n    \n    # KL\u6563\u5ea6\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    \n    return BCE + KLD\n'})}),"\n",(0,r.jsx)(n.h3,{id:"3-diffusion\u6a21\u578b",children:"3. Diffusion\u6a21\u578b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class DiffusionModel(nn.Module):\n    """\u6269\u6563\u6a21\u578b"""\n    def __init__(self, timesteps=1000):\n        super().__init__()\n        self.timesteps = timesteps\n        \n        # \u5b9a\u4e49\u566a\u58f0\u8c03\u5ea6\n        self.betas = torch.linspace(0.0001, 0.02, timesteps)\n        self.alphas = 1 - self.betas\n        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n    \n    def forward_diffusion(self, x0, t):\n        """\u524d\u5411\u6269\u6563\u8fc7\u7a0b\uff08\u52a0\u566a\u58f0\uff09"""\n        noise = torch.randn_like(x0)\n        sqrt_alphas_cumprod_t = self.alphas_cumprod[t].sqrt()\n        sqrt_one_minus_alphas_cumprod_t = (1 - self.alphas_cumprod[t]).sqrt()\n        \n        # x_t = sqrt(alpha_t) * x_0 + sqrt(1-alpha_t) * noise\n        return sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise, noise\n    \n    def reverse_diffusion(self, model, x_t, t):\n        """\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\uff08\u53bb\u566a\u58f0\uff09"""\n        # \u9884\u6d4b\u566a\u58f0\n        predicted_noise = model(x_t, t)\n        \n        # \u8ba1\u7b97x_{t-1}\n        alpha_t = self.alphas[t]\n        alpha_cumprod_t = self.alphas_cumprod[t]\n        beta_t = self.betas[t]\n        \n        # \u53bb\u566a\u58f0\n        x_t_minus_1 = (x_t - beta_t / (1 - alpha_cumprod_t).sqrt() * predicted_noise) / alpha_t.sqrt()\n        \n        return x_t_minus_1\n    \n    def sample(self, model, shape):\n        """\u4ece\u566a\u58f0\u751f\u6210\u56fe\u50cf"""\n        # \u4ece\u7eaf\u566a\u58f0\u5f00\u59cb\n        x = torch.randn(shape)\n        \n        # \u9010\u6b65\u53bb\u566a\n        for t in reversed(range(self.timesteps)):\n            x = self.reverse_diffusion(model, x, t)\n        \n        return x\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u6587\u672c\u751f\u6210",children:"\u6587\u672c\u751f\u6210"}),"\n",(0,r.jsx)(n.h3,{id:"1-gpt\u7cfb\u5217",children:"1. GPT\u7cfb\u5217"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from transformers import GPT2LMHeadModel, GPT2Tokenizer\n\nclass TextGenerator:\n    """\u6587\u672c\u751f\u6210\u5668"""\n    def __init__(self, model_name="gpt2"):\n        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n    \n    def generate(self, prompt, max_length=100, temperature=0.7, top_p=0.9):\n        """\u751f\u6210\u6587\u672c"""\n        inputs = self.tokenizer.encode(prompt, return_tensors="pt")\n        \n        outputs = self.model.generate(\n            inputs,\n            max_length=max_length,\n            temperature=temperature,\n            top_p=top_p,\n            do_sample=True,\n            num_return_sequences=1\n        )\n        \n        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n        return text\n\n# \u4f7f\u7528\ngenerator = TextGenerator()\ntext = generator.generate("Once upon a time", max_length=200)\nprint(text)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-\u521b\u610f\u5199\u4f5c",children:"2. \u521b\u610f\u5199\u4f5c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class CreativeWriter:\n    """\u521b\u610f\u5199\u4f5c\u52a9\u624b"""\n    def __init__(self):\n        from openai import OpenAI\n        self.client = OpenAI()\n    \n    def write_story(self, theme, style="fantasy", length="short"):\n        """\u5199\u6545\u4e8b"""\n        prompt = f"""Write a {length} {style} story about: {theme}\n\nStory:"""\n        \n        response = self.client.chat.completions.create(\n            model="gpt-4",\n            messages=[{"role": "user", "content": prompt}],\n            temperature=0.8\n        )\n        \n        return response.choices[0].message.content\n    \n    def write_poem(self, topic, style="modern"):\n        """\u5199\u8bd7"""\n        prompt = f"Write a {style} poem about: {topic}"\n        \n        response = self.client.chat.completions.create(\n            model="gpt-4",\n            messages=[{"role": "user", "content": prompt}],\n            temperature=0.9\n        )\n        \n        return response.choices[0].message.content\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u56fe\u50cf\u751f\u6210",children:"\u56fe\u50cf\u751f\u6210"}),"\n",(0,r.jsx)(n.h3,{id:"1-stable-diffusion",children:"1. Stable Diffusion"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from diffusers import StableDiffusionPipeline\nimport torch\n\nclass ImageGenerator:\n    """\u56fe\u50cf\u751f\u6210\u5668"""\n    def __init__(self, model_id="stabilityai/stable-diffusion-2-1"):\n        self.pipe = StableDiffusionPipeline.from_pretrained(\n            model_id,\n            torch_dtype=torch.float16\n        )\n        self.pipe = self.pipe.to("cuda")\n    \n    def generate(self, prompt, negative_prompt="", num_images=1, \n                 guidance_scale=7.5, num_inference_steps=50):\n        """\u751f\u6210\u56fe\u50cf"""\n        images = self.pipe(\n            prompt=prompt,\n            negative_prompt=negative_prompt,\n            num_images_per_prompt=num_images,\n            guidance_scale=guidance_scale,\n            num_inference_steps=num_inference_steps\n        ).images\n        \n        return images\n    \n    def img2img(self, prompt, init_image, strength=0.75):\n        """\u56fe\u50cf\u5230\u56fe\u50cf"""\n        from diffusers import StableDiffusionImg2ImgPipeline\n        \n        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n            "stabilityai/stable-diffusion-2-1",\n            torch_dtype=torch.float16\n        ).to("cuda")\n        \n        images = pipe(\n            prompt=prompt,\n            image=init_image,\n            strength=strength\n        ).images\n        \n        return images\n\n# \u4f7f\u7528\ngenerator = ImageGenerator()\nimages = generator.generate(\n    prompt="a beautiful landscape with mountains and lake, sunset, highly detailed",\n    negative_prompt="blurry, low quality, distorted",\n    num_images=4\n)\n\nfor i, img in enumerate(images):\n    img.save(f"generated_{i}.png")\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-dall-e",children:"2. DALL-E"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from openai import OpenAI\n\nclass DALLEGenerator:\n    """DALL-E\u56fe\u50cf\u751f\u6210"""\n    def __init__(self):\n        self.client = OpenAI()\n    \n    def generate(self, prompt, size="1024x1024", quality="standard", n=1):\n        """\u751f\u6210\u56fe\u50cf"""\n        response = self.client.images.generate(\n            model="dall-e-3",\n            prompt=prompt,\n            size=size,\n            quality=quality,\n            n=n\n        )\n        \n        return [img.url for img in response.data]\n    \n    def edit(self, image, mask, prompt):\n        """\u7f16\u8f91\u56fe\u50cf"""\n        response = self.client.images.edit(\n            image=open(image, "rb"),\n            mask=open(mask, "rb"),\n            prompt=prompt\n        )\n        \n        return response.data[0].url\n\n# \u4f7f\u7528\ndalle = DALLEGenerator()\nurls = dalle.generate("A futuristic city with flying cars")\nprint(urls)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u89c6\u9891\u751f\u6210",children:"\u89c6\u9891\u751f\u6210"}),"\n",(0,r.jsx)(n.h3,{id:"1-\u6587\u672c\u5230\u89c6\u9891",children:"1. \u6587\u672c\u5230\u89c6\u9891"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class VideoGenerator:\n    """\u89c6\u9891\u751f\u6210\u5668\uff08\u6982\u5ff5\u793a\u4f8b\uff09"""\n    def __init__(self):\n        # \u5b9e\u9645\u9700\u8981\u4f7f\u7528\u5982Runway\u3001Pika\u7b49API\n        pass\n    \n    def text_to_video(self, prompt, duration=5, fps=24):\n        """\u6587\u672c\u751f\u6210\u89c6\u9891"""\n        # 1. \u751f\u6210\u5173\u952e\u5e27\n        keyframes = self._generate_keyframes(prompt, duration, fps)\n        \n        # 2. \u63d2\u503c\u751f\u6210\u4e2d\u95f4\u5e27\n        frames = self._interpolate_frames(keyframes, fps)\n        \n        # 3. \u5408\u6210\u89c6\u9891\n        video = self._compose_video(frames, fps)\n        \n        return video\n    \n    def image_to_video(self, image, motion_prompt):\n        """\u56fe\u50cf\u751f\u6210\u89c6\u9891"""\n        # \u4f7f\u7528Runway Gen-2\u7b49API\n        pass\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u97f3\u4e50\u751f\u6210",children:"\u97f3\u4e50\u751f\u6210"}),"\n",(0,r.jsx)(n.h3,{id:"1-musicgen",children:"1. MusicGen"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from audiocraft.models import MusicGen\nimport torchaudio\n\nclass MusicGenerator:\n    """\u97f3\u4e50\u751f\u6210\u5668"""\n    def __init__(self):\n        self.model = MusicGen.get_pretrained(\'facebook/musicgen-medium\')\n    \n    def generate(self, descriptions, duration=10):\n        """\u751f\u6210\u97f3\u4e50"""\n        self.model.set_generation_params(duration=duration)\n        \n        wav = self.model.generate(descriptions)\n        \n        return wav\n    \n    def save(self, wav, filename, sample_rate=32000):\n        """\u4fdd\u5b58\u97f3\u9891"""\n        torchaudio.save(filename, wav[0].cpu(), sample_rate)\n\n# \u4f7f\u7528\ngenerator = MusicGenerator()\nwav = generator.generate(["upbeat electronic dance music"])\ngenerator.save(wav, "generated_music.wav")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u5e94\u7528\u573a\u666f",children:"\u5e94\u7528\u573a\u666f"}),"\n",(0,r.jsx)(n.h3,{id:"1-\u5185\u5bb9\u521b\u4f5c",children:"1. \u5185\u5bb9\u521b\u4f5c"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class ContentCreator:\n    """\u5185\u5bb9\u521b\u4f5c\u52a9\u624b"""\n    def __init__(self):\n        self.text_gen = TextGenerator()\n        self.image_gen = ImageGenerator()\n    \n    def create_blog_post(self, topic):\n        """\u521b\u5efa\u535a\u5ba2\u6587\u7ae0"""\n        # \u751f\u6210\u6807\u9898\n        title = self.text_gen.generate(f"Blog title about {topic}:", max_length=20)\n        \n        # \u751f\u6210\u5185\u5bb9\n        content = self.text_gen.generate(f"Write a blog post about {topic}:", max_length=500)\n        \n        # \u751f\u6210\u914d\u56fe\n        image_prompt = f"illustration for blog post about {topic}"\n        images = self.image_gen.generate(image_prompt, num_images=1)\n        \n        return {\n            "title": title,\n            "content": content,\n            "image": images[0]\n        }\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-\u8bbe\u8ba1\u8f85\u52a9",children:"2. \u8bbe\u8ba1\u8f85\u52a9"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class DesignAssistant:\n    """\u8bbe\u8ba1\u52a9\u624b"""\n    def __init__(self):\n        self.image_gen = ImageGenerator()\n    \n    def generate_logo(self, company_name, style):\n        """\u751f\u6210Logo"""\n        prompt = f"professional logo for {company_name}, {style} style, simple, clean"\n        return self.image_gen.generate(prompt, num_images=5)\n    \n    def generate_ui_mockup(self, description):\n        """\u751f\u6210UI\u8bbe\u8ba1"""\n        prompt = f"modern UI design mockup, {description}, clean interface, professional"\n        return self.image_gen.generate(prompt)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,r.jsx)(n.h3,{id:"1-prompt\u5de5\u7a0b",children:"1. Prompt\u5de5\u7a0b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# \u597d\u7684\u56fe\u50cf\u751f\u6210Prompt\nGOOD_PROMPT = """\na beautiful landscape painting,\nmountains in the background,\nlake in the foreground,\nsunset lighting,\nhighly detailed,\n8k resolution,\ntrending on artstation\n"""\n\n# \u8d1f\u9762Prompt\nNEGATIVE_PROMPT = """\nblurry, low quality, distorted,\nugly, bad anatomy, watermark\n"""\n'})}),"\n",(0,r.jsx)(n.h3,{id:"2-\u8d28\u91cf\u63a7\u5236",children:"2. \u8d28\u91cf\u63a7\u5236"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'class QualityControl:\n    """\u751f\u6210\u5185\u5bb9\u8d28\u91cf\u63a7\u5236"""\n    def __init__(self):\n        self.nsfw_detector = NSFWDetector()\n        self.quality_scorer = QualityScorer()\n    \n    def filter_generated_content(self, content):\n        """\u8fc7\u6ee4\u751f\u6210\u5185\u5bb9"""\n        # \u68c0\u6d4b\u4e0d\u9002\u5f53\u5185\u5bb9\n        if self.nsfw_detector.is_nsfw(content):\n            return None\n        \n        # \u8bc4\u4f30\u8d28\u91cf\n        score = self.quality_scorer.score(content)\n        if score < 0.7:\n            return None\n        \n        return content\n'})}),"\n",(0,r.jsx)(n.h2,{id:"\u672a\u6765\u8d8b\u52bf",children:"\u672a\u6765\u8d8b\u52bf"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u66f4\u9ad8\u8d28\u91cf"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u66f4\u771f\u5b9e\u7684\u56fe\u50cf\u548c\u89c6\u9891"}),"\n",(0,r.jsx)(n.li,{children:"\u66f4\u81ea\u7136\u7684\u6587\u672c\u548c\u8bed\u97f3"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u66f4\u5f3a\u63a7\u5236"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u7cbe\u786e\u7684\u98ce\u683c\u63a7\u5236"}),"\n",(0,r.jsx)(n.li,{children:"\u7ec6\u7c92\u5ea6\u7684\u7f16\u8f91\u80fd\u529b"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u591a\u6a21\u6001\u878d\u5408"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u6587\u672c+\u56fe\u50cf+\u97f3\u9891+\u89c6\u9891\u7edf\u4e00\u751f\u6210"}),"\n",(0,r.jsx)(n.li,{children:"\u8de8\u6a21\u6001\u7f16\u8f91"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u5b9e\u65f6\u751f\u6210"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u4f4e\u5ef6\u8fdf"}),"\n",(0,r.jsx)(n.li,{children:"\u4ea4\u4e92\u5f0f\u521b\u4f5c"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"\u4e2a\u6027\u5316"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u9002\u5e94\u7528\u6237\u98ce\u683c"}),"\n",(0,r.jsx)(n.li,{children:"\u5b9a\u5236\u5316\u751f\u6210"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"\u603b\u7ed3",children:"\u603b\u7ed3"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"\u5173\u952e\u8981\u70b9"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"\u751f\u6210\u5f0fAI\u521b\u9020\u65b0\u5185\u5bb9"}),"\n",(0,r.jsx)(n.li,{children:"GAN\u3001VAE\u3001Diffusion\u662f\u6838\u5fc3\u6280\u672f"}),"\n",(0,r.jsx)(n.li,{children:"\u5e94\u7528\u5e7f\u6cdb\uff1a\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u3001\u97f3\u4e50"}),"\n",(0,r.jsx)(n.li,{children:"Prompt\u5de5\u7a0b\u5f88\u91cd\u8981"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"\u5b66\u4e60\u5efa\u8bae"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\u7406\u89e3\u751f\u6210\u6a21\u578b\u539f\u7406"}),"\n",(0,r.jsx)(n.li,{children:"\u5b9e\u8df5\u4e0d\u540c\u7684\u751f\u6210\u4efb\u52a1"}),"\n",(0,r.jsx)(n.li,{children:"\u5b66\u4e60Prompt\u5de5\u7a0b"}),"\n",(0,r.jsx)(n.li,{children:"\u5173\u6ce8\u6700\u65b0\u6a21\u578b\u548c\u5de5\u5177"}),"\n"]}),"\n",(0,r.jsx)(i,{})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453(e,n,i){i.d(n,{R:()=>l,x:()=>a});var t=i(96540);const r={},s=t.createContext(r);function l(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);