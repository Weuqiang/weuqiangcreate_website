---
sidebar_position: 13
title: AI (AIGC)
---

# AIAIGC

:::info 
AI
:::

## AI

**AIGenerative AI, AIGC** 

### AIGC vs AI

|  | AI | AI |
|------|----------|----------|
|  | / |  |
|  | / | // |
|  |  |  |
|  |  |  |

## 

### 1. GAN

```python
import torch
import torch.nn as nn

class Generator(nn.Module):
    """"""
    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):
        super().__init__()
        self.img_shape = img_shape
        
        self.model = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.LeakyReLU(0.2),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, int(torch.prod(torch.tensor(img_shape)))),
            nn.Tanh()
        )
    
    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), *self.img_shape)
        return img


class Discriminator(nn.Module):
    """"""
    def __init__(self, img_shape=(1, 28, 28)):
        super().__init__()
        
        self.model = nn.Sequential(
            nn.Linear(int(torch.prod(torch.tensor(img_shape))), 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )
    
    def forward(self, img):
        img_flat = img.view(img.size(0), -1)
        validity = self.model(img_flat)
        return validity


# GAN
def train_gan(generator, discriminator, dataloader, epochs=100):
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)
    adversarial_loss = nn.BCELoss()
    
    for epoch in range(epochs):
        for i, (imgs, _) in enumerate(dataloader):
            batch_size = imgs.size(0)
            
            # 
            real = torch.ones(batch_size, 1)
            fake = torch.zeros(batch_size, 1)
            
            # 
            optimizer_D.zero_grad()
            
            # 
            real_loss = adversarial_loss(discriminator(imgs), real)
            
            # 
            z = torch.randn(batch_size, 100)
            gen_imgs = generator(z)
            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
            
            d_loss = (real_loss + fake_loss) / 2
            d_loss.backward()
            optimizer_D.step()
            
            # 
            optimizer_G.zero_grad()
            
            g_loss = adversarial_loss(discriminator(gen_imgs), real)
            g_loss.backward()
            optimizer_G.step()
        
        print(f"Epoch {epoch}: D_loss={d_loss.item():.4f}, G_loss={g_loss.item():.4f}")
```

### 2. VAE

```python
class VAE(nn.Module):
    """"""
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super().__init__()
        
        # 
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        
        # 
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)
    
    def encode(self, x):
        h = torch.relu(self.fc1(x))
        return self.fc_mu(h), self.fc_logvar(h)
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = torch.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h))
    
    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar


def vae_loss(recon_x, x, mu, logvar):
    """VAE"""
    # 
    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    
    # KL
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    
    return BCE + KLD
```

### 3. Diffusion

```python
class DiffusionModel(nn.Module):
    """"""
    def __init__(self, timesteps=1000):
        super().__init__()
        self.timesteps = timesteps
        
        # 
        self.betas = torch.linspace(0.0001, 0.02, timesteps)
        self.alphas = 1 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
    
    def forward_diffusion(self, x0, t):
        """"""
        noise = torch.randn_like(x0)
        sqrt_alphas_cumprod_t = self.alphas_cumprod[t].sqrt()
        sqrt_one_minus_alphas_cumprod_t = (1 - self.alphas_cumprod[t]).sqrt()
        
        # x_t = sqrt(alpha_t) * x_0 + sqrt(1-alpha_t) * noise
        return sqrt_alphas_cumprod_t * x0 + sqrt_one_minus_alphas_cumprod_t * noise, noise
    
    def reverse_diffusion(self, model, x_t, t):
        """"""
        # 
        predicted_noise = model(x_t, t)
        
        # x_{t-1}
        alpha_t = self.alphas[t]
        alpha_cumprod_t = self.alphas_cumprod[t]
        beta_t = self.betas[t]
        
        # 
        x_t_minus_1 = (x_t - beta_t / (1 - alpha_cumprod_t).sqrt() * predicted_noise) / alpha_t.sqrt()
        
        return x_t_minus_1
    
    def sample(self, model, shape):
        """"""
        # 
        x = torch.randn(shape)
        
        # 
        for t in reversed(range(self.timesteps)):
            x = self.reverse_diffusion(model, x, t)
        
        return x
```

## 

### 1. GPT

```python
from transformers import GPT2LMHeadModel, GPT2Tokenizer

class TextGenerator:
    """"""
    def __init__(self, model_name="gpt2"):
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
        self.model = GPT2LMHeadModel.from_pretrained(model_name)
    
    def generate(self, prompt, max_length=100, temperature=0.7, top_p=0.9):
        """"""
        inputs = self.tokenizer.encode(prompt, return_tensors="pt")
        
        outputs = self.model.generate(
            inputs,
            max_length=max_length,
            temperature=temperature,
            top_p=top_p,
            do_sample=True,
            num_return_sequences=1
        )
        
        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return text

# 
generator = TextGenerator()
text = generator.generate("Once upon a time", max_length=200)
print(text)
```

### 2. 

```python
class CreativeWriter:
    """"""
    def __init__(self):
        from openai import OpenAI
        self.client = OpenAI()
    
    def write_story(self, theme, style="fantasy", length="short"):
        """"""
        prompt = f"""Write a {length} {style} story about: {theme}

Story:"""
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8
        )
        
        return response.choices[0].message.content
    
    def write_poem(self, topic, style="modern"):
        """"""
        prompt = f"Write a {style} poem about: {topic}"
        
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.9
        )
        
        return response.choices[0].message.content
```

## 

### 1. Stable Diffusion

```python
from diffusers import StableDiffusionPipeline
import torch

class ImageGenerator:
    """"""
    def __init__(self, model_id="stabilityai/stable-diffusion-2-1"):
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16
        )
        self.pipe = self.pipe.to("cuda")
    
    def generate(self, prompt, negative_prompt="", num_images=1, 
                 guidance_scale=7.5, num_inference_steps=50):
        """"""
        images = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_images_per_prompt=num_images,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps
        ).images
        
        return images
    
    def img2img(self, prompt, init_image, strength=0.75):
        """"""
        from diffusers import StableDiffusionImg2ImgPipeline
        
        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
            "stabilityai/stable-diffusion-2-1",
            torch_dtype=torch.float16
        ).to("cuda")
        
        images = pipe(
            prompt=prompt,
            image=init_image,
            strength=strength
        ).images
        
        return images

# 
generator = ImageGenerator()
images = generator.generate(
    prompt="a beautiful landscape with mountains and lake, sunset, highly detailed",
    negative_prompt="blurry, low quality, distorted",
    num_images=4
)

for i, img in enumerate(images):
    img.save(f"generated_{i}.png")
```

### 2. DALL-E

```python
from openai import OpenAI

class DALLEGenerator:
    """DALL-E"""
    def __init__(self):
        self.client = OpenAI()
    
    def generate(self, prompt, size="1024x1024", quality="standard", n=1):
        """"""
        response = self.client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            size=size,
            quality=quality,
            n=n
        )
        
        return [img.url for img in response.data]
    
    def edit(self, image, mask, prompt):
        """"""
        response = self.client.images.edit(
            image=open(image, "rb"),
            mask=open(mask, "rb"),
            prompt=prompt
        )
        
        return response.data[0].url

# 
dalle = DALLEGenerator()
urls = dalle.generate("A futuristic city with flying cars")
print(urls)
```

## 

### 1. 

```python
class VideoGenerator:
    """"""
    def __init__(self):
        # RunwayPikaAPI
        pass
    
    def text_to_video(self, prompt, duration=5, fps=24):
        """"""
        # 1. 
        keyframes = self._generate_keyframes(prompt, duration, fps)
        
        # 2. 
        frames = self._interpolate_frames(keyframes, fps)
        
        # 3. 
        video = self._compose_video(frames, fps)
        
        return video
    
    def image_to_video(self, image, motion_prompt):
        """"""
        # Runway Gen-2API
        pass
```

## 

### 1. MusicGen

```python
from audiocraft.models import MusicGen
import torchaudio

class MusicGenerator:
    """"""
    def __init__(self):
        self.model = MusicGen.get_pretrained('facebook/musicgen-medium')
    
    def generate(self, descriptions, duration=10):
        """"""
        self.model.set_generation_params(duration=duration)
        
        wav = self.model.generate(descriptions)
        
        return wav
    
    def save(self, wav, filename, sample_rate=32000):
        """"""
        torchaudio.save(filename, wav[0].cpu(), sample_rate)

# 
generator = MusicGenerator()
wav = generator.generate(["upbeat electronic dance music"])
generator.save(wav, "generated_music.wav")
```

## 

### 1. 

```python
class ContentCreator:
    """"""
    def __init__(self):
        self.text_gen = TextGenerator()
        self.image_gen = ImageGenerator()
    
    def create_blog_post(self, topic):
        """"""
        # 
        title = self.text_gen.generate(f"Blog title about {topic}:", max_length=20)
        
        # 
        content = self.text_gen.generate(f"Write a blog post about {topic}:", max_length=500)
        
        # 
        image_prompt = f"illustration for blog post about {topic}"
        images = self.image_gen.generate(image_prompt, num_images=1)
        
        return {
            "title": title,
            "content": content,
            "image": images[0]
        }
```

### 2. 

```python
class DesignAssistant:
    """"""
    def __init__(self):
        self.image_gen = ImageGenerator()
    
    def generate_logo(self, company_name, style):
        """Logo"""
        prompt = f"professional logo for {company_name}, {style} style, simple, clean"
        return self.image_gen.generate(prompt, num_images=5)
    
    def generate_ui_mockup(self, description):
        """UI"""
        prompt = f"modern UI design mockup, {description}, clean interface, professional"
        return self.image_gen.generate(prompt)
```

## 

### 1. Prompt

```python
# Prompt
GOOD_PROMPT = """
a beautiful landscape painting,
mountains in the background,
lake in the foreground,
sunset lighting,
highly detailed,
8k resolution,
trending on artstation
"""

# Prompt
NEGATIVE_PROMPT = """
blurry, low quality, distorted,
ugly, bad anatomy, watermark
"""
```

### 2. 

```python
class QualityControl:
    """"""
    def __init__(self):
        self.nsfw_detector = NSFWDetector()
        self.quality_scorer = QualityScorer()
    
    def filter_generated_content(self, content):
        """"""
        # 
        if self.nsfw_detector.is_nsfw(content):
            return None
        
        # 
        score = self.quality_scorer.score(content)
        if score < 0.7:
            return None
        
        return content
```

## 

****
- 
- 

****
- 
- 

****
- +++
- 

****
- 
- 

****
- 
- 

## 

****:
1. AI
2. GANVAEDiffusion
3. 
4. Prompt

****:
- 
- 
- Prompt
- 

<DocCardList />

