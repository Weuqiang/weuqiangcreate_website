---
title: Agent
sidebar_position: 4
---

Agent   AI Agent 

:::info

:::

Agent



Function Call MCP

human-in-the-loop

|           | /            |                                            |                                                                                                                               |
| ----------------- | ------------------------ | ---------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| / | Coze                     | •                                      | • • • • • • Token•  |
|           | LangChainAutoGenMG | • • •  | •                                                                                                               |

## Agent 

### Agent 

|        |                                                                  |                                                                  |                                                                  |
|------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------------------------------------|
|    |                        | “”                 |                    |
| Agent 1.0  |                    | “”“” |                                    |
| Agent 2.0  | API     | “”Agent     |          |
| Agent 2.5  | API       | “PS”“” |    |

### 



#### 

```python showLineNumbers
import openai
import re
import datetime

#  OpenAI API Key
openai.api_key = "YOUR_API_KEY"

# 
def get_current_weather(location):
    # 
    return f"{location}"

# 
def get_current_time():
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return f": {now}"

def prompt_engineered_function_call(user_input):
    """
    
    1. "" get_current_weather 
       CALL get_current_weather(location="<>")
    2. "" get_current_time 
       CALL get_current_time()
    3. """"
    """
    prompt = f"""

1. ""
   CALL get_current_weather(location="<>")
2. ""
   CALL get_current_time()
3. """"


{user_input}
    """
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # 
        messages=[
            {"role": "system", "content": ""},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    return response.choices[0].message.content.strip()

if __name__ == '__main__':
    user_query = input(": ")
    model_reply = prompt_engineered_function_call(user_query)
    print(":", model_reply)
    
    # 
    if model_reply.startswith("CALL get_current_weather"):
        #  location 
        match = re.search(r'location="(.+?)"', model_reply)
        if match:
            location = match.group(1)
            result = get_current_weather(location)
            print(":", result)
        else:
            print("")
    elif model_reply.startswith("CALL get_current_time"):
        result = get_current_time()
        print(":", result)
    else:
        print(":", model_reply)
```

#### function calling

function calling  OpenAI 

```python showLineNumbers
import openai
import json

#  OpenAI API Key
openai.api_key = "YOUR_API_KEY"

# 
def get_current_weather(location):
    # 
    return f"{location}"

# Function Schema
functions = [
    {
        "name": "get_current_weather",
        "description": "",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": ""}
            },
            "required": ["location"]
        }
    }
]

def large_model_integration(user_input):
    """
    
    
    """
    # 
    response = openai.ChatCompletion.create(
        model="gpt-4-0613",  # 
        messages=[{"role": "user", "content": user_input}],
        functions=functions,
        function_call="auto"  # 
    )

    message = response["choices"][0]["message"]

    # 
    if message.get("function_call"):
        func_name = message["function_call"]["name"]
        arguments = message["function_call"]["arguments"]

        # 
        args = json.loads(arguments)

        # 
        if func_name == "get_current_weather":
            result = get_current_weather(**args)
            return f" {func_name} : {result}"
        else:
            return ""
    else:
        # 
        return message.get("content", "")

if __name__ == '__main__':
    user_query = input(": ")
    result = large_model_integration(user_query)
    print(result)

```

#### Mcp

APIAPI

Mcp
1.
2.
3.
4. API  

MCP 
1.  MCP 
2. MCPAPI
3. MCP 


#### A2A

A2A  Agent  Agent 


### 

![alt text](https://langchain-ai.github.io/langgraph/concepts/img/multi_agent/architectures.png)

https://langchain-ai.github.io/langgraph/concepts/multi_agent/

### LLM



MASFT

|            |  (%) |              |  (%) |
| ------------------ | ------------ | -------------------- | ------------ |
|  | 37.2         |          | 15.2         |
|                    |              |          | 5.5          |
|                    |              |              | 7.59         |
|                    |              |          | 1.57         |
|                    |              |      | 6.54         |
|    | 31.4         |              | 2.09         |
|                    |              |          | 6.02         |
|                    |              |              | 5.5          |
|                    |              |              | 9.16         |
|                    |              |  | 8.64         |
|                    |              | -      | 2.36         |
|  | 31.4         |              | 13.61        |
|                    |              |        | 4.71         |
|                    |              |            | 13.09        |


 https://www.aimodels.fyi/papers/arxiv/why-do-multi-agent-llm-systems-fail

## 

langchain

langgraphlanggraph-swarm

AutoGen

MG

## 

### 



### Human-in-the-loop



### 



