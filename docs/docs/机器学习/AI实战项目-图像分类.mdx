---
sidebar_position: 20
title: AI
tags: [AI, , PyTorch, , CNN]
---

# AI

## 



### 

- ****: PyTorch
- ****: NumPy, Pandas, OpenCV
- ****: Matplotlib, TensorBoard
- ****: Flask, Docker
- ****: React

### 

-  
-  CNN
-  
-  API
-  Web

## 

### 1. 

```python
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt

# CIFAR-10
def download_dataset():
    """CIFAR-10"""
    
    # 
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), 
                           (0.2023, 0.1994, 0.2010)),
    ])
    
    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), 
                           (0.2023, 0.1994, 0.2010)),
    ])
    
    # 
    trainset = torchvision.datasets.CIFAR10(
        root='./data', 
        train=True,
        download=True, 
        transform=transform_train
    )
    
    trainloader = DataLoader(
        trainset, 
        batch_size=128,
        shuffle=True, 
        num_workers=2
    )
    
    # 
    testset = torchvision.datasets.CIFAR10(
        root='./data', 
        train=False,
        download=True, 
        transform=transform_test
    )
    
    testloader = DataLoader(
        testset, 
        batch_size=100,
        shuffle=False, 
        num_workers=2
    )
    
    # 
    classes = ('plane', 'car', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck')
    
    return trainloader, testloader, classes

# 
def visualize_data(dataloader, classes):
    """"""
    dataiter = iter(dataloader)
    images, labels = next(dataiter)
    
    # 
    fig, axes = plt.subplots(2, 5, figsize=(12, 6))
    for i, ax in enumerate(axes.flat):
        # 
        img = images[i] / 2 + 0.5
        npimg = img.numpy()
        ax.imshow(np.transpose(npimg, (1, 2, 0)))
        ax.set_title(classes[labels[i]])
        ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('sample_images.png')
    print("")
```

### 2. 

```python
from torch.utils.data import Dataset
from PIL import Image
import os

class CustomImageDataset(Dataset):
    """"""
    
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images = []
        self.labels = []
        
        # 
        for label_idx, class_name in enumerate(os.listdir(root_dir)):
            class_dir = os.path.join(root_dir, class_name)
            if os.path.isdir(class_dir):
                for img_name in os.listdir(class_dir):
                    img_path = os.path.join(class_dir, img_name)
                    self.images.append(img_path)
                    self.labels.append(label_idx)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]
        
        if self.transform:
            image = self.transform(image)
        
        return image, label
```

## 

### 1. ResNet

```python
import torch.nn as nn
import torch.nn.functional as F

class BasicBlock(nn.Module):
    """ResNet"""
    expansion = 1
    
    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock, self).__init__()
        
        self.conv1 = nn.Conv2d(
            in_channels, out_channels, 
            kernel_size=3, stride=stride, 
            padding=1, bias=False
        )
        self.bn1 = nn.BatchNorm2d(out_channels)
        
        self.conv2 = nn.Conv2d(
            out_channels, out_channels,
            kernel_size=3, stride=1,
            padding=1, bias=False
        )
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(
                    in_channels, out_channels,
                    kernel_size=1, stride=stride, bias=False
                ),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out

class ResNet(nn.Module):
    """ResNet"""
    
    def __init__(self, block, num_blocks, num_classes=10):
        super(ResNet, self).__init__()
        self.in_channels = 64
        
        self.conv1 = nn.Conv2d(
            3, 64, kernel_size=3,
            stride=1, padding=1, bias=False
        )
        self.bn1 = nn.BatchNorm2d(64)
        
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        
        self.linear = nn.Linear(512 * block.expansion, num_classes)
    
    def _make_layer(self, block, out_channels, num_blocks, stride):
        strides = [stride] + [1] * (num_blocks - 1)
        layers = []
        for stride in strides:
            layers.append(block(self.in_channels, out_channels, stride))
            self.in_channels = out_channels * block.expansion
        return nn.Sequential(*layers)
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        out = out.view(out.size(0), -1)
        out = self.linear(out)
        return out

def ResNet18(num_classes=10):
    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)

def ResNet34(num_classes=10):
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)
```

### 2. CNN

```python
class SimpleCNN(nn.Module):
    """CNN"""
    
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        
        self.features = nn.Sequential(
            # 
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # 
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # 
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(128 * 4 * 4, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x
```

## 

### 1. 

```python
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter

class Trainer:
    """"""
    
    def __init__(self, model, trainloader, testloader, device='cuda'):
        self.model = model.to(device)
        self.trainloader = trainloader
        self.testloader = testloader
        self.device = device
        
        # 
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = optim.SGD(
            model.parameters(),
            lr=0.1,
            momentum=0.9,
            weight_decay=5e-4
        )
        
        # 
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=200
        )
        
        # TensorBoard
        self.writer = SummaryWriter('runs/image_classification')
        
        # 
        self.best_acc = 0
    
    def train_epoch(self, epoch):
        """epoch"""
        self.model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, targets) in enumerate(self.trainloader):
            inputs, targets = inputs.to(self.device), targets.to(self.device)
            
            # 
            self.optimizer.zero_grad()
            outputs = self.model(inputs)
            loss = self.criterion(outputs, targets)
            
            # 
            loss.backward()
            self.optimizer.step()
            
            # 
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            if batch_idx % 100 == 0:
                print(f'Epoch: {epoch} | Batch: {batch_idx} | '
                      f'Loss: {train_loss/(batch_idx+1):.3f} | '
                      f'Acc: {100.*correct/total:.2f}%')
        
        # TensorBoard
        self.writer.add_scalar('Train/Loss', train_loss/len(self.trainloader), epoch)
        self.writer.add_scalar('Train/Acc', 100.*correct/total, epoch)
        
        return train_loss/len(self.trainloader), 100.*correct/total
    
    def test(self, epoch):
        """"""
        self.model.eval()
        test_loss = 0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for inputs, targets in self.testloader:
                inputs, targets = inputs.to(self.device), targets.to(self.device)
                outputs = self.model(inputs)
                loss = self.criterion(outputs, targets)
                
                test_loss += loss.item()
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
        
        acc = 100.*correct/total
        print(f'Test Loss: {test_loss/len(self.testloader):.3f} | '
              f'Test Acc: {acc:.2f}%')
        
        # TensorBoard
        self.writer.add_scalar('Test/Loss', test_loss/len(self.testloader), epoch)
        self.writer.add_scalar('Test/Acc', acc, epoch)
        
        # 
        if acc > self.best_acc:
            print(f'Saving model... (Acc: {acc:.2f}%)')
            torch.save({
                'epoch': epoch,
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'acc': acc,
            }, 'best_model.pth')
            self.best_acc = acc
        
        return test_loss/len(self.testloader), acc
    
    def train(self, num_epochs=200):
        """"""
        for epoch in range(num_epochs):
            print(f'\nEpoch: {epoch+1}/{num_epochs}')
            train_loss, train_acc = self.train_epoch(epoch)
            test_loss, test_acc = self.test(epoch)
            self.scheduler.step()
        
        self.writer.close()
        print(f'\nBest Test Acc: {self.best_acc:.2f}%')

# 
if __name__ == '__main__':
    # 
    trainloader, testloader, classes = download_dataset()
    
    # 
    model = ResNet18(num_classes=10)
    
    # 
    trainer = Trainer(model, trainloader, testloader)
    trainer.train(num_epochs=200)
```

### 2. 

```python
from torch.cuda.amp import autocast, GradScaler

class MixedPrecisionTrainer(Trainer):
    """"""
    
    def __init__(self, model, trainloader, testloader, device='cuda'):
        super().__init__(model, trainloader, testloader, device)
        self.scaler = GradScaler()
    
    def train_epoch(self, epoch):
        """"""
        self.model.train()
        train_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (inputs, targets) in enumerate(self.trainloader):
            inputs, targets = inputs.to(self.device), targets.to(self.device)
            
            self.optimizer.zero_grad()
            
            # 
            with autocast():
                outputs = self.model(inputs)
                loss = self.criterion(outputs, targets)
            
            # 
            self.scaler.scale(loss).backward()
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            # 
            train_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
        
        return train_loss/len(self.trainloader), 100.*correct/total
```

## 

### 1. 

```python
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

def evaluate_model(model, testloader, classes, device='cuda'):
    """"""
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for inputs, labels in testloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, preds = outputs.max(1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())
    
    # 
    cm = confusion_matrix(all_labels, all_preds)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('confusion_matrix.png')
    
    # 
    print('\nClassification Report:')
    print(classification_report(all_labels, all_preds, target_names=classes))
    
    return cm
```

### 2. 

```python
def visualize_predictions(model, testloader, classes, device='cuda', num_images=10):
    """"""
    model.eval()
    dataiter = iter(testloader)
    images, labels = next(dataiter)
    
    images = images.to(device)
    outputs = model(images)
    _, preds = outputs.max(1)
    
    # 
    fig, axes = plt.subplots(2, 5, figsize=(15, 6))
    for i, ax in enumerate(axes.flat):
        if i >= num_images:
            break
        
        # 
        img = images[i].cpu() / 2 + 0.5
        npimg = img.numpy()
        ax.imshow(np.transpose(npimg, (1, 2, 0)))
        
        true_label = classes[labels[i]]
        pred_label = classes[preds[i]]
        color = 'green' if labels[i] == preds[i] else 'red'
        
        ax.set_title(f'True: {true_label}\nPred: {pred_label}', color=color)
        ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('predictions.png')
```

## 

### 1. Flask API

```python
from flask import Flask, request, jsonify
from PIL import Image
import io
import base64

app = Flask(__name__)

# 
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = ResNet18(num_classes=10)
checkpoint = torch.load('best_model.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.to(device)
model.eval()

# 
classes = ('plane', 'car', 'bird', 'cat', 'deer', 
           'dog', 'frog', 'horse', 'ship', 'truck')

# 
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), 
                       (0.2023, 0.1994, 0.2010)),
])

@app.route('/predict', methods=['POST'])
def predict():
    """"""
    try:
        # 
        if 'image' in request.files:
            image = Image.open(request.files['image']).convert('RGB')
        elif 'image_base64' in request.json:
            image_data = base64.b64decode(request.json['image_base64'])
            image = Image.open(io.BytesIO(image_data)).convert('RGB')
        else:
            return jsonify({'error': 'No image provided'}), 400
        
        # 
        image_tensor = transform(image).unsqueeze(0).to(device)
        
        # 
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = F.softmax(outputs, dim=1)
            confidence, predicted = probabilities.max(1)
        
        # 
        result = {
            'class': classes[predicted.item()],
            'confidence': confidence.item(),
            'probabilities': {
                classes[i]: prob.item() 
                for i, prob in enumerate(probabilities[0])
            }
        }
        
        return jsonify(result)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/health', methods=['GET'])
def health():
    """"""
    return jsonify({'status': 'healthy'})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=False)
```

### 2. Docker

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# 
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 
COPY app.py .
COPY best_model.pth .

EXPOSE 5000

CMD ["python", "app.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "5000:5000"
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## 

```jsx
// React
import React, { useState } from 'react';
import axios from 'axios';

function ImageClassifier() {
  const [image, setImage] = useState(null);
  const [preview, setPreview] = useState(null);
  const [result, setResult] = useState(null);
  const [loading, setLoading] = useState(false);
  
  const handleImageChange = (e) => {
    const file = e.target.files[0];
    setImage(file);
    setPreview(URL.createObjectURL(file));
  };
  
  const handleSubmit = async () => {
    if (!image) return;
    
    setLoading(true);
    const formData = new FormData();
    formData.append('image', image);
    
    try {
      const response = await axios.post('http://localhost:5000/predict', formData);
      setResult(response.data);
    } catch (error) {
      console.error('Error:', error);
    } finally {
      setLoading(false);
    }
  };
  
  return (
    <div className="classifier">
      <h1></h1>
      
      <input type="file" accept="image/*" onChange={handleImageChange} />
      
      {preview && (
        <div className="preview">
          <img src={preview} alt="Preview" style={{ maxWidth: '300px' }} />
        </div>
      )}
      
      <button onClick={handleSubmit} disabled={!image || loading}>
        {loading ? '...' : ''}
      </button>
      
      {result && (
        <div className="result">
          <h2></h2>
          <p>: {result.class}</p>
          <p>: {(result.confidence * 100).toFixed(2)}%</p>
          
          <h3>:</h3>
          <ul>
            {Object.entries(result.probabilities).map(([cls, prob]) => (
              <li key={cls}>
                {cls}: {(prob * 100).toFixed(2)}%
              </li>
            ))}
          </ul>
        </div>
      )}
    </div>
  );
}

export default ImageClassifier;
```

## 



1. ****: 
2. ****: CNNResNet
3. ****: 
4. ****: 
5. ****: Flask APIDocker
6. ****: React

## 

- [PyTorch](https://pytorch.org/docs/)
- [](https://www.deeplearningbook.org/)
- [CS231n](http://cs231n.stanford.edu/)

