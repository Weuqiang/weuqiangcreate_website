---
sidebar_position: 12
title: 
tags: [, , , ]
---

# 

## 



### 

- ****MySQL 5.7 → MySQL 8.0
- **** → 
- **** → 
- ****MySQL → PostgreSQL

## 

### 1. 



```bash
#!/bin/bash
# 

echo "1. "
systemctl stop app-service

echo "2. "
mysqldump -h old-db -u root -p database_name > backup.sql

echo "3. "
mysql -h new-db -u root -p database_name < backup.sql

echo "4. "
mysql -h new-db -u root -p -e "SELECT COUNT(*) FROM users"

echo "5. "
sed -i 's/old-db/new-db/g' /etc/app/config.yml

echo "6. "
systemctl start app-service

echo ""
```

****
- 
- 

****
- 
- 

### 2. 

 MySQL 

#### 1

```sql
-- 
CREATE USER 'repl'@'%' IDENTIFIED BY 'password';
GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
FLUSH PRIVILEGES;

-- 
SHOW MASTER STATUS;
--  File  Position
```

```sql
-- 
CHANGE MASTER TO
  MASTER_HOST='old-db-host',
  MASTER_USER='repl',
  MASTER_PASSWORD='password',
  MASTER_LOG_FILE='mysql-bin.000001',
  MASTER_LOG_POS=154;

-- 
START SLAVE;

-- 
SHOW SLAVE STATUS\G
--  Slave_IO_Running  Slave_SQL_Running  Yes
```

#### 2

```bash
#!/bin/bash
# 

while true; do
  delay=$(mysql -h new-db -u root -p -e "SHOW SLAVE STATUS\G" | grep "Seconds_Behind_Master" | awk '{print $2}')
  
  if [ "$delay" == "0" ]; then
    echo ""
    break
  else
    echo ": ${delay}"
    sleep 5
  fi
done
```

#### 3

```javascript
// 
class DatabaseMigration {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.writeToNew = false;
    this.readFromNew = false;
  }
  
  // 1
  async write(data) {
    return await this.oldDb.insert(data);
  }
  
  // 2
  async writePhase2(data) {
    const result = await this.oldDb.insert(data);
    
    // 
    this.newDb.insert(data).catch(err => {
      console.error('', err);
      // 
    });
    
    return result;
  }
  
  // 3
  async writePhase3(data) {
    const result = await this.newDb.insert(data);
    
    // 
    this.oldDb.insert(data).catch(err => {
      console.error('', err);
    });
    
    return result;
  }
  
  // 4
  async writePhase4(data) {
    return await this.newDb.insert(data);
  }
  
  // 
  async read(id) {
    if (this.readFromNew) {
      // 
      const data = await this.newDb.query(id);
      if (data) return data;
      
      // 
      return await this.oldDb.query(id);
    } else {
      // 
      return await this.oldDb.query(id);
    }
  }
}
```

#### 4

```javascript
// 
class DataValidator {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
  }
  
  async validateTable(tableName, primaryKey = 'id') {
    console.log(`: ${tableName}`);
    
    // 1. 
    const oldCount = await this.oldDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    const newCount = await this.newDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    
    if (oldCount.count !== newCount.count) {
      console.error(`: =${oldCount.count}, =${newCount.count}`);
      return false;
    }
    
    // 2. 
    const sampleSize = 1000;
    const samples = await this.oldDb.query(`
      SELECT ${primaryKey} FROM ${tableName}
      ORDER BY RAND()
      LIMIT ${sampleSize}
    `);
    
    let errorCount = 0;
    for (const sample of samples) {
      const oldData = await this.oldDb.query(`SELECT * FROM ${tableName} WHERE ${primaryKey} = ?`, [sample[primaryKey]]);
      const newData = await this.newDb.query(`SELECT * FROM ${tableName} WHERE ${primaryKey} = ?`, [sample[primaryKey]]);
      
      if (JSON.stringify(oldData) !== JSON.stringify(newData)) {
        console.error(`: ${primaryKey}=${sample[primaryKey]}`);
        errorCount++;
      }
    }
    
    console.log(`: ${sampleSize}, ${errorCount}`);
    return errorCount === 0;
  }
  
  async validateChecksum(tableName) {
    //  CHECKSUM TABLE 
    const oldChecksum = await this.oldDb.query(`CHECKSUM TABLE ${tableName}`);
    const newChecksum = await this.newDb.query(`CHECKSUM TABLE ${tableName}`);
    
    return oldChecksum[0].Checksum === newChecksum[0].Checksum;
  }
}
```

### 3. 

 mysqldump  mydumper 

```bash
#!/bin/bash
#  mydumper 

#  mydumper
# apt-get install mydumper

# 
mydumper \
  --host=old-db \
  --user=root \
  --password=password \
  --database=mydb \
  --outputdir=/backup \
  --threads=8 \
  --compress \
  --verbose=3

# 
myloader \
  --host=new-db \
  --user=root \
  --password=password \
  --database=mydb \
  --directory=/backup \
  --threads=8 \
  --verbose=3
```

### 4. 

 Percona XtraBackup 

```bash
#!/bin/bash
#  XtraBackup 

#  XtraBackup
# apt-get install percona-xtrabackup-80

# 
xtrabackup \
  --backup \
  --host=old-db \
  --user=root \
  --password=password \
  --target-dir=/backup/full

# 
xtrabackup \
  --prepare \
  --target-dir=/backup/full

# 
# 1. 
systemctl stop mysql

# 2. 
rm -rf /var/lib/mysql/*

# 3. 
xtrabackup \
  --copy-back \
  --target-dir=/backup/full

# 4. 
chown -R mysql:mysql /var/lib/mysql

# 5. 
systemctl start mysql
```

### 5. 

 binlog 

```javascript
//  Canal  binlog
const Canal = require('canal-node-client');

class BinlogSync {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.canal = new Canal({
      host: 'old-db',
      port: 11111,
      destination: 'example',
      username: '',
      password: '',
    });
  }
  
  async start() {
    this.canal.subscribe({
      database: 'mydb',
      table: 'users',
    });
    
    this.canal.on('entry', async (entry) => {
      const { eventType, rowDatas } = entry;
      
      for (const rowData of rowDatas) {
        switch (eventType) {
          case 'INSERT':
            await this.handleInsert(rowData);
            break;
          case 'UPDATE':
            await this.handleUpdate(rowData);
            break;
          case 'DELETE':
            await this.handleDelete(rowData);
            break;
        }
      }
    });
    
    this.canal.connect();
  }
  
  async handleInsert(rowData) {
    const data = this.parseRowData(rowData.afterColumns);
    await this.newDb.insert(data);
  }
  
  async handleUpdate(rowData) {
    const before = this.parseRowData(rowData.beforeColumns);
    const after = this.parseRowData(rowData.afterColumns);
    await this.newDb.update(after, { id: before.id });
  }
  
  async handleDelete(rowData) {
    const data = this.parseRowData(rowData.beforeColumns);
    await this.newDb.delete({ id: data.id });
  }
  
  parseRowData(columns) {
    const data = {};
    for (const col of columns) {
      data[col.name] = col.value;
    }
    return data;
  }
}
```

## 

### MySQL → PostgreSQL

```javascript
// 
const typeMapping = {
  'INT': 'INTEGER',
  'BIGINT': 'BIGINT',
  'VARCHAR': 'VARCHAR',
  'TEXT': 'TEXT',
  'DATETIME': 'TIMESTAMP',
  'DECIMAL': 'NUMERIC',
  'TINYINT': 'SMALLINT',
  'JSON': 'JSONB',
};

class MySQLToPostgreSQL {
  constructor(mysqlDb, pgDb) {
    this.mysqlDb = mysqlDb;
    this.pgDb = pgDb;
  }
  
  async migrateTable(tableName) {
    // 1. 
    const columns = await this.mysqlDb.query(`
      SELECT 
        COLUMN_NAME,
        DATA_TYPE,
        CHARACTER_MAXIMUM_LENGTH,
        IS_NULLABLE,
        COLUMN_DEFAULT
      FROM INFORMATION_SCHEMA.COLUMNS
      WHERE TABLE_NAME = ?
    `, [tableName]);
    
    // 2.  PostgreSQL 
    const createTableSQL = this.generateCreateTable(tableName, columns);
    await this.pgDb.query(createTableSQL);
    
    // 3. 
    let offset = 0;
    const batchSize = 1000;
    
    while (true) {
      const rows = await this.mysqlDb.query(`
        SELECT * FROM ${tableName}
        LIMIT ${offset}, ${batchSize}
      `);
      
      if (rows.length === 0) break;
      
      // 
      await this.pgDb.batchInsert(tableName, rows);
      
      offset += batchSize;
      console.log(` ${offset} `);
    }
  }
  
  generateCreateTable(tableName, columns) {
    const columnDefs = columns.map(col => {
      let def = `"${col.COLUMN_NAME}" ${this.mapType(col)}`;
      
      if (col.IS_NULLABLE === 'NO') {
        def += ' NOT NULL';
      }
      
      if (col.COLUMN_DEFAULT) {
        def += ` DEFAULT ${col.COLUMN_DEFAULT}`;
      }
      
      return def;
    });
    
    return `CREATE TABLE "${tableName}" (${columnDefs.join(', ')})`;
  }
  
  mapType(column) {
    const mysqlType = column.DATA_TYPE.toUpperCase();
    let pgType = typeMapping[mysqlType] || mysqlType;
    
    if (column.CHARACTER_MAXIMUM_LENGTH) {
      pgType += `(${column.CHARACTER_MAXIMUM_LENGTH})`;
    }
    
    return pgType;
  }
}
```

## 

### 1. 

```javascript
class GrayRelease {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.grayUserIds = new Set();
    this.grayPercent = 0;
  }
  
  // 
  setGrayPercent(percent) {
    this.grayPercent = percent;
  }
  
  // 
  addGrayUser(userId) {
    this.grayUserIds.add(userId);
  }
  
  // 
  isGrayUser(userId) {
    // 
    if (this.grayUserIds.has(userId)) {
      return true;
    }
    
    // 
    return (userId % 100) < this.grayPercent;
  }
  
  // 
  getDatabase(userId) {
    return this.isGrayUser(userId) ? this.newDb : this.oldDb;
  }
  
  // 
  async query(userId, sql, params) {
    const db = this.getDatabase(userId);
    return await db.query(sql, params);
  }
  
  // 
  async insert(userId, data) {
    const db = this.getDatabase(userId);
    return await db.insert(data);
  }
}

// 
const gray = new GrayRelease(oldDb, newDb);

// 10% 
gray.addGrayUser(12345);
gray.setGrayPercent(0);

// 25% 
gray.setGrayPercent(5);

// 320% 
gray.setGrayPercent(20);

// 450% 
gray.setGrayPercent(50);

// 5100% 
gray.setGrayPercent(100);
```

### 2. 

```javascript
class RegionGrayRelease {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.grayRegions = new Set();
  }
  
  // 
  addGrayRegion(region) {
    this.grayRegions.add(region);
  }
  
  // 
  getDatabase(region) {
    return this.grayRegions.has(region) ? this.newDb : this.oldDb;
  }
}

// 
const gray = new RegionGrayRelease(oldDb, newDb);

// 1
gray.addGrayRegion('beijing');

// 2
gray.addGrayRegion('shanghai');

// 3
gray.addGrayRegion('*');
```

## 

### 1. 

```javascript
class RollbackManager {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
    this.currentDb = newDb;
  }
  
  // 
  switchToNew() {
    this.currentDb = this.newDb;
    console.log('');
  }
  
  // 
  rollback() {
    this.currentDb = this.oldDb;
    console.log('');
  }
  
  // 
  getCurrentDb() {
    return this.currentDb;
  }
}
```

### 2. 

```javascript
// 
class ChangeLog {
  constructor(db) {
    this.db = db;
  }
  
  async logChange(operation, tableName, data) {
    await this.db.query(`
      INSERT INTO change_log (operation, table_name, data, created_at)
      VALUES (?, ?, ?, NOW())
    `, [operation, tableName, JSON.stringify(data)]);
  }
  
  async rollbackChanges(startTime, endTime) {
    const logs = await this.db.query(`
      SELECT * FROM change_log
      WHERE created_at BETWEEN ? AND ?
      ORDER BY id DESC
    `, [startTime, endTime]);
    
    for (const log of logs) {
      const data = JSON.parse(log.data);
      
      switch (log.operation) {
        case 'INSERT':
          // 
          await this.db.delete(log.table_name, { id: data.id });
          break;
        case 'UPDATE':
          // 
          await this.db.update(log.table_name, data.before, { id: data.id });
          break;
        case 'DELETE':
          // 
          await this.db.insert(log.table_name, data);
          break;
      }
    }
  }
}
```

## 

### 1. 

```javascript
class MigrationMonitor {
  constructor(oldDb, newDb) {
    this.oldDb = oldDb;
    this.newDb = newDb;
  }
  
  async getProgress(tableName) {
    const oldCount = await this.oldDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    const newCount = await this.newDb.query(`SELECT COUNT(*) as count FROM ${tableName}`);
    
    const progress = (newCount.count / oldCount.count * 100).toFixed(2);
    
    return {
      tableName,
      oldCount: oldCount.count,
      newCount: newCount.count,
      progress: `${progress}%`,
    };
  }
  
  async monitorAll(tables) {
    const results = [];
    
    for (const table of tables) {
      const progress = await this.getProgress(table);
      results.push(progress);
      
      console.log(`${table}: ${progress.progress}`);
    }
    
    return results;
  }
}
```

### 2. 

```javascript
class PerformanceMonitor {
  constructor(db) {
    this.db = db;
  }
  
  async getSlowQueries() {
    return await this.db.query(`
      SELECT 
        query_time,
        lock_time,
        rows_examined,
        sql_text
      FROM mysql.slow_log
      WHERE start_time > DATE_SUB(NOW(), INTERVAL 1 HOUR)
      ORDER BY query_time DESC
      LIMIT 10
    `);
  }
  
  async getConnectionCount() {
    const result = await this.db.query('SHOW STATUS LIKE "Threads_connected"');
    return result[0].Value;
  }
  
  async getQPS() {
    const result = await this.db.query('SHOW GLOBAL STATUS LIKE "Questions"');
    return result[0].Value;
  }
}
```

### 3. 

```javascript
class AlertManager {
  constructor(webhookUrl) {
    this.webhookUrl = webhookUrl;
  }
  
  async sendAlert(title, message, level = 'warning') {
    const payload = {
      title,
      message,
      level,
      timestamp: new Date().toISOString(),
    };
    
    await fetch(this.webhookUrl, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(payload),
    });
  }
  
  async alertDataInconsistency(tableName, details) {
    await this.sendAlert(
      '',
      ` ${tableName} : ${details}`,
      'error'
    );
  }
  
  async alertMigrationFailed(error) {
    await this.sendAlert(
      '',
      `: ${error.message}`,
      'critical'
    );
  }
}
```

## 

### 1. 

```markdown
## 

### 
- [ ] 
- [ ] 
- [ ] 
- [ ] 

### 
- [ ] 
- [ ] 
- [ ] 
- [ ] 

### 
- [ ] 
- [ ] 
- [ ] 
- [ ] 

### 
- [ ] 
- [ ] 
- [ ] 
- [ ] 
```

### 2. 

```markdown
## 

### 1T-7
1. 
2. 
3. 

### 2T-3
1. 
2. 
3. 

### 3T-1
1. 
2. 
3. 

### 4T
1. 5% 
2. 1
3. 20% → 50% → 100% 

### 5T+7
1. 
2. 
3. 
```

### 3. 

```markdown
## 

### 1
- 
- 
- 

### 2
- 
- 
- 

### 3
- 
- 
- 

### 4
- 
- 
- 
```

## 



1. ****
2. ****
3. ****
4. ****

## 

- [MySQL ](https://dev.mysql.com/doc/refman/8.0/en/replication.html)
- [Percona XtraBackup](https://www.percona.com/software/mysql-database/percona-xtrabackup)
- [Canal -  MySQL binlog ](https://github.com/alibaba/canal)
- [](https://aws.amazon.com/cn/dms/resources/)

