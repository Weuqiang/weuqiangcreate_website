"use strict";(globalThis.webpackChunkweuqiangcreate_website=globalThis.webpackChunkweuqiangcreate_website||[]).push([[67985],{29874(n,e,t){t.r(e),t.d(e,{assets:()=>a,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"\u4eba\u5de5\u667a\u80fd/AI-Agent","title":"AI Agent\u667a\u80fd\u4f53","description":"\u672c\u7ae0\u8282\u4ecb\u7ecdAI Agent\u7684\u539f\u7406\u3001\u67b6\u6784\u548c\u5b9e\u73b0\uff0c\u6db5\u76d6ReAct\u3001AutoGPT\u3001LangChain Agent\u7b49\u524d\u6cbf\u6280\u672f\u3002","source":"@site/docs/docs/\u4eba\u5de5\u667a\u80fd/AI-Agent.mdx","sourceDirName":"\u4eba\u5de5\u667a\u80fd","slug":"/\u4eba\u5de5\u667a\u80fd/AI-Agent","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/AI-Agent","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"title":"AI Agent\u667a\u80fd\u4f53"},"sidebar":"tutorialSidebar","previous":{"title":"\u591a\u6a21\u6001AI","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u591a\u6a21\u6001AI"},"next":{"title":"\u751f\u6210\u5f0fAI (AIGC)","permalink":"/weuqiangcreate_website/docs/\u4eba\u5de5\u667a\u80fd/\u751f\u6210\u5f0fAI"}}');var r=t(74848),l=t(28453);const i={sidebar_position:12,title:"AI Agent\u667a\u80fd\u4f53"},o="AI Agent\uff08\u667a\u80fd\u4f53\uff09",a={},c=[{value:"\u4ec0\u4e48\u662fAI Agent",id:"\u4ec0\u4e48\u662fai-agent",level:2},{value:"Agent\u7684\u6838\u5fc3\u7279\u5f81",id:"agent\u7684\u6838\u5fc3\u7279\u5f81",level:3},{value:"Agent vs \u4f20\u7edfAI",id:"agent-vs-\u4f20\u7edfai",level:3},{value:"Agent\u67b6\u6784",id:"agent\u67b6\u6784",level:2},{value:"1. \u57fa\u7840\u67b6\u6784",id:"1-\u57fa\u7840\u67b6\u6784",level:3},{value:"2. ReAct\u67b6\u6784",id:"2-react\u67b6\u6784",level:3},{value:"3. \u89c4\u5212\u578bAgent",id:"3-\u89c4\u5212\u578bagent",level:3},{value:"\u5de5\u5177\u8c03\u7528\uff08Tool Use\uff09",id:"\u5de5\u5177\u8c03\u7528tool-use",level:2},{value:"1. \u51fd\u6570\u8c03\u7528\uff08Function Calling\uff09",id:"1-\u51fd\u6570\u8c03\u7528function-calling",level:3},{value:"2. LangChain\u5de5\u5177",id:"2-langchain\u5de5\u5177",level:3},{value:"\u8bb0\u5fc6\u7cfb\u7edf",id:"\u8bb0\u5fc6\u7cfb\u7edf",level:2},{value:"1. \u77ed\u671f\u8bb0\u5fc6",id:"1-\u77ed\u671f\u8bb0\u5fc6",level:3},{value:"2. \u957f\u671f\u8bb0\u5fc6",id:"2-\u957f\u671f\u8bb0\u5fc6",level:3},{value:"\u591aAgent\u7cfb\u7edf",id:"\u591aagent\u7cfb\u7edf",level:2},{value:"1. Agent\u534f\u4f5c",id:"1-agent\u534f\u4f5c",level:3},{value:"2. Agent\u8fa9\u8bba",id:"2-agent\u8fa9\u8bba",level:3},{value:"\u5b9e\u6218\u6848\u4f8b",id:"\u5b9e\u6218\u6848\u4f8b",level:2},{value:"1. \u81ea\u52a8\u5316\u7814\u7a76\u52a9\u624b",id:"1-\u81ea\u52a8\u5316\u7814\u7a76\u52a9\u624b",level:3},{value:"2. \u4ee3\u7801\u751f\u6210Agent",id:"2-\u4ee3\u7801\u751f\u6210agent",level:3},{value:"\u6700\u4f73\u5b9e\u8df5",id:"\u6700\u4f73\u5b9e\u8df5",level:2},{value:"1. Prompt\u8bbe\u8ba1",id:"1-prompt\u8bbe\u8ba1",level:3},{value:"2. \u9519\u8bef\u5904\u7406",id:"2-\u9519\u8bef\u5904\u7406",level:3},{value:"3. \u6210\u672c\u63a7\u5236",id:"3-\u6210\u672c\u63a7\u5236",level:3},{value:"\u672a\u6765\u8d8b\u52bf",id:"\u672a\u6765\u8d8b\u52bf",level:2},{value:"\u603b\u7ed3",id:"\u603b\u7ed3",level:2}];function d(n){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...n.components},{DocCardList:t}=e;return t||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("DocCardList",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"ai-agent\u667a\u80fd\u4f53",children:"AI Agent\uff08\u667a\u80fd\u4f53\uff09"})}),"\n",(0,r.jsx)(e.admonition,{title:"\u7ae0\u8282\u6982\u8ff0",type:"info",children:(0,r.jsx)(e.p,{children:"\u672c\u7ae0\u8282\u4ecb\u7ecdAI Agent\u7684\u539f\u7406\u3001\u67b6\u6784\u548c\u5b9e\u73b0\uff0c\u6db5\u76d6ReAct\u3001AutoGPT\u3001LangChain Agent\u7b49\u524d\u6cbf\u6280\u672f\u3002"})}),"\n",(0,r.jsx)(e.h2,{id:"\u4ec0\u4e48\u662fai-agent",children:"\u4ec0\u4e48\u662fAI Agent"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"AI Agent\uff08\u667a\u80fd\u4f53\uff09"})," \u662f\u80fd\u591f\u611f\u77e5\u73af\u5883\u3001\u81ea\u4e3b\u51b3\u7b56\u5e76\u91c7\u53d6\u884c\u52a8\u4ee5\u5b9e\u73b0\u76ee\u6807\u7684AI\u7cfb\u7edf\u3002"]}),"\n",(0,r.jsx)(e.h3,{id:"agent\u7684\u6838\u5fc3\u7279\u5f81",children:"Agent\u7684\u6838\u5fc3\u7279\u5f81"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u81ea\u4e3b\u6027\uff08Autonomy\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u65e0\u9700\u4eba\u5de5\u5e72\u9884"}),"\n",(0,r.jsx)(e.li,{children:"\u81ea\u4e3b\u89c4\u5212\u548c\u6267\u884c"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u53cd\u5e94\u6027\uff08Reactivity\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u611f\u77e5\u73af\u5883\u53d8\u5316"}),"\n",(0,r.jsx)(e.li,{children:"\u53ca\u65f6\u54cd\u5e94"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u4e3b\u52a8\u6027\uff08Proactivity\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u76ee\u6807\u5bfc\u5411"}),"\n",(0,r.jsx)(e.li,{children:"\u4e3b\u52a8\u91c7\u53d6\u884c\u52a8"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u793e\u4ea4\u80fd\u529b\uff08Social Ability\uff09"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u4e0e\u4eba\u7c7b\u4ea4\u4e92"}),"\n",(0,r.jsx)(e.li,{children:"\u4e0e\u5176\u4ed6Agent\u534f\u4f5c"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"agent-vs-\u4f20\u7edfai",children:"Agent vs \u4f20\u7edfAI"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"\u7279\u6027"}),(0,r.jsx)(e.th,{children:"\u4f20\u7edfAI"}),(0,r.jsx)(e.th,{children:"AI Agent"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u4ea4\u4e92\u65b9\u5f0f"}),(0,r.jsx)(e.td,{children:"\u5355\u6b21\u95ee\u7b54"}),(0,r.jsx)(e.td,{children:"\u591a\u8f6e\u5bf9\u8bdd"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u80fd\u529b\u8303\u56f4"}),(0,r.jsx)(e.td,{children:"\u56fa\u5b9a\u4efb\u52a1"}),(0,r.jsx)(e.td,{children:"\u52a8\u6001\u4efb\u52a1"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u5de5\u5177\u4f7f\u7528"}),(0,r.jsx)(e.td,{children:"\u65e0"}),(0,r.jsx)(e.td,{children:"\u53ef\u8c03\u7528\u5de5\u5177"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u89c4\u5212\u80fd\u529b"}),(0,r.jsx)(e.td,{children:"\u65e0"}),(0,r.jsx)(e.td,{children:"\u81ea\u4e3b\u89c4\u5212"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:"\u8bb0\u5fc6"}),(0,r.jsx)(e.td,{children:"\u65e0\u72b6\u6001"}),(0,r.jsx)(e.td,{children:"\u6709\u8bb0\u5fc6"})]})]})]}),"\n",(0,r.jsx)(e.h2,{id:"agent\u67b6\u6784",children:"Agent\u67b6\u6784"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u57fa\u7840\u67b6\u6784",children:"1. \u57fa\u7840\u67b6\u6784"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class Agent:\n    """\u57fa\u7840Agent\u67b6\u6784"""\n    \n    def __init__(self, llm, tools, memory=None):\n        self.llm = llm  # \u5927\u8bed\u8a00\u6a21\u578b\n        self.tools = tools  # \u53ef\u7528\u5de5\u5177\n        self.memory = memory or []  # \u8bb0\u5fc6\n    \n    def perceive(self, observation):\n        """\u611f\u77e5\u73af\u5883"""\n        return observation\n    \n    def think(self, observation):\n        """\u601d\u8003\u548c\u89c4\u5212"""\n        # \u6784\u5efaprompt\n        prompt = self._build_prompt(observation)\n        \n        # LLM\u63a8\u7406\n        response = self.llm.generate(prompt)\n        \n        return response\n    \n    def act(self, action):\n        """\u6267\u884c\u52a8\u4f5c"""\n        # \u89e3\u6790\u52a8\u4f5c\n        tool_name, tool_input = self._parse_action(action)\n        \n        # \u8c03\u7528\u5de5\u5177\n        if tool_name in self.tools:\n            result = self.tools[tool_name](tool_input)\n        else:\n            result = f"Tool {tool_name} not found"\n        \n        return result\n    \n    def run(self, task, max_iterations=10):\n        """\u8fd0\u884cAgent"""\n        observation = task\n        \n        for i in range(max_iterations):\n            # \u601d\u8003\n            thought = self.think(observation)\n            \n            # \u5224\u65ad\u662f\u5426\u5b8c\u6210\n            if self._is_finished(thought):\n                return self._extract_answer(thought)\n            \n            # \u6267\u884c\u52a8\u4f5c\n            action = self._extract_action(thought)\n            observation = self.act(action)\n            \n            # \u66f4\u65b0\u8bb0\u5fc6\n            self.memory.append({\n                \'thought\': thought,\n                \'action\': action,\n                \'observation\': observation\n            })\n        \n        return "Max iterations reached"\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-react\u67b6\u6784",children:"2. ReAct\u67b6\u6784"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"ReAct = Reasoning + Acting"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class ReActAgent:\n    """ReAct Agent\u5b9e\u73b0"""\n    \n    def __init__(self, llm, tools):\n        self.llm = llm\n        self.tools = tools\n    \n    def _build_react_prompt(self, task, history):\n        """\u6784\u5efaReAct prompt"""\n        prompt = f"""You are an AI assistant that can use tools to solve tasks.\n\nAvailable tools:\n{self._format_tools()}\n\nUse the following format:\n\nThought: Think about what to do\nAction: the action to take, should be one of [{\', \'.join(self.tools.keys())}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nTask: {task}\n\n{self._format_history(history)}\n"""\n        return prompt\n    \n    def _format_tools(self):\n        """\u683c\u5f0f\u5316\u5de5\u5177\u63cf\u8ff0"""\n        tool_desc = []\n        for name, tool in self.tools.items():\n            tool_desc.append(f"- {name}: {tool.description}")\n        return \'\\n\'.join(tool_desc)\n    \n    def _format_history(self, history):\n        """\u683c\u5f0f\u5316\u5386\u53f2\u8bb0\u5f55"""\n        formatted = []\n        for step in history:\n            formatted.append(f"Thought: {step[\'thought\']}")\n            formatted.append(f"Action: {step[\'action\']}")\n            formatted.append(f"Action Input: {step[\'action_input\']}")\n            formatted.append(f"Observation: {step[\'observation\']}")\n        return \'\\n\'.join(formatted)\n    \n    def run(self, task, max_steps=10):\n        """\u8fd0\u884cReAct Agent"""\n        history = []\n        \n        for step in range(max_steps):\n            # \u751f\u6210\u4e0b\u4e00\u6b65\n            prompt = self._build_react_prompt(task, history)\n            response = self.llm.generate(prompt)\n            \n            # \u89e3\u6790\u54cd\u5e94\n            if "Final Answer:" in response:\n                answer = response.split("Final Answer:")[-1].strip()\n                return answer\n            \n            # \u63d0\u53d6\u601d\u8003\u3001\u52a8\u4f5c\u548c\u8f93\u5165\n            thought = self._extract_field(response, "Thought:")\n            action = self._extract_field(response, "Action:")\n            action_input = self._extract_field(response, "Action Input:")\n            \n            # \u6267\u884c\u52a8\u4f5c\n            if action in self.tools:\n                observation = self.tools[action].run(action_input)\n            else:\n                observation = f"Error: Tool \'{action}\' not found"\n            \n            # \u8bb0\u5f55\u5386\u53f2\n            history.append({\n                \'thought\': thought,\n                \'action\': action,\n                \'action_input\': action_input,\n                \'observation\': observation\n            })\n        \n        return "Max steps reached without finding answer"\n    \n    def _extract_field(self, text, field_name):\n        """\u63d0\u53d6\u5b57\u6bb5"""\n        if field_name not in text:\n            return ""\n        \n        start = text.index(field_name) + len(field_name)\n        end = text.find(\'\\n\', start)\n        if end == -1:\n            end = len(text)\n        \n        return text[start:end].strip()\n\n\n# \u793a\u4f8b\uff1a\u5b9a\u4e49\u5de5\u5177\nclass SearchTool:\n    name = "search"\n    description = "Search the internet for information"\n    \n    def run(self, query):\n        # \u5b9e\u9645\u5b9e\u73b0\u4f1a\u8c03\u7528\u641c\u7d22API\n        return f"Search results for: {query}"\n\n\nclass CalculatorTool:\n    name = "calculator"\n    description = "Perform mathematical calculations"\n    \n    def run(self, expression):\n        try:\n            result = eval(expression)\n            return str(result)\n        except Exception as e:\n            return f"Error: {str(e)}"\n\n\n# \u4f7f\u7528ReAct Agent\ntools = {\n    \'search\': SearchTool(),\n    \'calculator\': CalculatorTool()\n}\n\nagent = ReActAgent(llm, tools)\nanswer = agent.run("What is the population of Tokyo multiplied by 2?")\nprint(answer)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"3-\u89c4\u5212\u578bagent",children:"3. \u89c4\u5212\u578bAgent"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class PlanAndExecuteAgent:\n    """\u89c4\u5212-\u6267\u884cAgent"""\n    \n    def __init__(self, llm, tools):\n        self.llm = llm\n        self.tools = tools\n    \n    def plan(self, task):\n        """\u5236\u5b9a\u8ba1\u5212"""\n        prompt = f"""Break down the following task into a step-by-step plan:\n\nTask: {task}\n\nPlan:\n1."""\n        \n        response = self.llm.generate(prompt)\n        steps = self._parse_plan(response)\n        return steps\n    \n    def execute_step(self, step, context):\n        """\u6267\u884c\u5355\u4e2a\u6b65\u9aa4"""\n        prompt = f"""Execute the following step using available tools:\n\nStep: {step}\nContext: {context}\n\nAvailable tools: {list(self.tools.keys())}\n\nAction:"""\n        \n        response = self.llm.generate(prompt)\n        action, action_input = self._parse_action(response)\n        \n        if action in self.tools:\n            result = self.tools[action].run(action_input)\n        else:\n            result = f"Tool {action} not found"\n        \n        return result\n    \n    def run(self, task):\n        """\u8fd0\u884cAgent"""\n        # \u5236\u5b9a\u8ba1\u5212\n        plan = self.plan(task)\n        print(f"Plan: {plan}")\n        \n        # \u6267\u884c\u8ba1\u5212\n        context = []\n        for i, step in enumerate(plan):\n            print(f"\\nExecuting step {i+1}: {step}")\n            result = self.execute_step(step, context)\n            print(f"Result: {result}")\n            context.append({\n                \'step\': step,\n                \'result\': result\n            })\n        \n        # \u603b\u7ed3\u7ed3\u679c\n        return self._summarize(task, context)\n    \n    def _parse_plan(self, response):\n        """\u89e3\u6790\u8ba1\u5212"""\n        lines = response.strip().split(\'\\n\')\n        steps = []\n        for line in lines:\n            line = line.strip()\n            if line and line[0].isdigit():\n                step = line.split(\'.\', 1)[1].strip()\n                steps.append(step)\n        return steps\n    \n    def _summarize(self, task, context):\n        """\u603b\u7ed3\u7ed3\u679c"""\n        prompt = f"""Summarize the results of the following task:\n\nTask: {task}\n\nExecution history:\n{self._format_context(context)}\n\nFinal Answer:"""\n        \n        return self.llm.generate(prompt)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u5de5\u5177\u8c03\u7528tool-use",children:"\u5de5\u5177\u8c03\u7528\uff08Tool Use\uff09"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u51fd\u6570\u8c03\u7528function-calling",children:"1. \u51fd\u6570\u8c03\u7528\uff08Function Calling\uff09"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import json\nfrom openai import OpenAI\n\nclass FunctionCallingAgent:\n    """\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684Agent"""\n    \n    def __init__(self):\n        self.client = OpenAI()\n        self.functions = self._define_functions()\n        self.available_functions = self._register_functions()\n    \n    def _define_functions(self):\n        """\u5b9a\u4e49\u53ef\u7528\u51fd\u6570"""\n        return [\n            {\n                "name": "get_weather",\n                "description": "\u83b7\u53d6\u6307\u5b9a\u57ce\u5e02\u7684\u5929\u6c14\u4fe1\u606f",\n                "parameters": {\n                    "type": "object",\n                    "properties": {\n                        "city": {\n                            "type": "string",\n                            "description": "\u57ce\u5e02\u540d\u79f0\uff0c\u5982\uff1a\u5317\u4eac"\n                        },\n                        "unit": {\n                            "type": "string",\n                            "enum": ["celsius", "fahrenheit"],\n                            "description": "\u6e29\u5ea6\u5355\u4f4d"\n                        }\n                    },\n                    "required": ["city"]\n                }\n            },\n            {\n                "name": "search_web",\n                "description": "\u5728\u7f51\u4e0a\u641c\u7d22\u4fe1\u606f",\n                "parameters": {\n                    "type": "object",\n                    "properties": {\n                        "query": {\n                            "type": "string",\n                            "description": "\u641c\u7d22\u67e5\u8be2"\n                        }\n                    },\n                    "required": ["query"]\n                }\n            }\n        ]\n    \n    def _register_functions(self):\n        """\u6ce8\u518c\u5b9e\u9645\u7684\u51fd\u6570\u5b9e\u73b0"""\n        return {\n            "get_weather": self.get_weather,\n            "search_web": self.search_web\n        }\n    \n    def get_weather(self, city, unit="celsius"):\n        """\u83b7\u53d6\u5929\u6c14\uff08\u793a\u4f8b\u5b9e\u73b0\uff09"""\n        # \u5b9e\u9645\u5e94\u8be5\u8c03\u7528\u5929\u6c14API\n        return json.dumps({\n            "city": city,\n            "temperature": 22,\n            "unit": unit,\n            "condition": "\u6674\u6717"\n        })\n    \n    def search_web(self, query):\n        """\u641c\u7d22\u7f51\u9875\uff08\u793a\u4f8b\u5b9e\u73b0\uff09"""\n        # \u5b9e\u9645\u5e94\u8be5\u8c03\u7528\u641c\u7d22API\n        return json.dumps({\n            "query": query,\n            "results": ["\u7ed3\u679c1", "\u7ed3\u679c2", "\u7ed3\u679c3"]\n        })\n    \n    def run(self, user_message):\n        """\u8fd0\u884cAgent"""\n        messages = [{"role": "user", "content": user_message}]\n        \n        while True:\n            # \u8c03\u7528LLM\n            response = self.client.chat.completions.create(\n                model="gpt-4",\n                messages=messages,\n                functions=self.functions,\n                function_call="auto"\n            )\n            \n            message = response.choices[0].message\n            \n            # \u5982\u679c\u6ca1\u6709\u51fd\u6570\u8c03\u7528\uff0c\u8fd4\u56de\u7ed3\u679c\n            if not message.function_call:\n                return message.content\n            \n            # \u6267\u884c\u51fd\u6570\u8c03\u7528\n            function_name = message.function_call.name\n            function_args = json.loads(message.function_call.arguments)\n            \n            print(f"\u8c03\u7528\u51fd\u6570: {function_name}")\n            print(f"\u53c2\u6570: {function_args}")\n            \n            function_response = self.available_functions[function_name](**function_args)\n            \n            # \u5c06\u51fd\u6570\u7ed3\u679c\u6dfb\u52a0\u5230\u5bf9\u8bdd\n            messages.append({\n                "role": "function",\n                "name": function_name,\n                "content": function_response\n            })\n\n\n# \u4f7f\u7528\nagent = FunctionCallingAgent()\nresult = agent.run("\u5317\u4eac\u4eca\u5929\u5929\u6c14\u600e\u4e48\u6837\uff1f")\nprint(result)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-langchain\u5de5\u5177",children:"2. LangChain\u5de5\u5177"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.agents import Tool, AgentExecutor, create_react_agent\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\nfrom langchain.tools import DuckDuckGoSearchRun\nfrom langchain.utilities import WikipediaAPIWrapper\n\n# \u5b9a\u4e49\u5de5\u5177\nsearch = DuckDuckGoSearchRun()\nwikipedia = WikipediaAPIWrapper()\n\ntools = [\n    Tool(\n        name="Search",\n        func=search.run,\n        description="\u7528\u4e8e\u641c\u7d22\u4e92\u8054\u7f51\u4fe1\u606f"\n    ),\n    Tool(\n        name="Wikipedia",\n        func=wikipedia.run,\n        description="\u7528\u4e8e\u67e5\u8be2\u7ef4\u57fa\u767e\u79d1"\n    ),\n    Tool(\n        name="Calculator",\n        func=lambda x: str(eval(x)),\n        description="\u7528\u4e8e\u6570\u5b66\u8ba1\u7b97"\n    )\n]\n\n# \u521b\u5efaAgent\nllm = OpenAI(temperature=0)\n\nprompt = PromptTemplate.from_template("""\nAnswer the following questions as best you can. You have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question\n\nBegin!\n\nQuestion: {input}\nThought: {agent_scratchpad}\n""")\n\nagent = create_react_agent(llm, tools, prompt)\nagent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n# \u8fd0\u884c\nresult = agent_executor.invoke({\n    "input": "What is the population of Tokyo? Calculate it multiplied by 2."\n})\nprint(result)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u8bb0\u5fc6\u7cfb\u7edf",children:"\u8bb0\u5fc6\u7cfb\u7edf"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u77ed\u671f\u8bb0\u5fc6",children:"1. \u77ed\u671f\u8bb0\u5fc6"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class ShortTermMemory:\n    """\u77ed\u671f\u8bb0\u5fc6\uff08\u5bf9\u8bdd\u5386\u53f2\uff09"""\n    \n    def __init__(self, max_length=10):\n        self.messages = []\n        self.max_length = max_length\n    \n    def add(self, role, content):\n        """\u6dfb\u52a0\u6d88\u606f"""\n        self.messages.append({\n            "role": role,\n            "content": content\n        })\n        \n        # \u4fdd\u6301\u6700\u5927\u957f\u5ea6\n        if len(self.messages) > self.max_length:\n            self.messages = self.messages[-self.max_length:]\n    \n    def get_messages(self):\n        """\u83b7\u53d6\u6240\u6709\u6d88\u606f"""\n        return self.messages\n    \n    def clear(self):\n        """\u6e05\u7a7a\u8bb0\u5fc6"""\n        self.messages = []\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u957f\u671f\u8bb0\u5fc6",children:"2. \u957f\u671f\u8bb0\u5fc6"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from langchain.vectorstores import FAISS\nfrom langchain.embeddings import OpenAIEmbeddings\n\nclass LongTermMemory:\n    """\u957f\u671f\u8bb0\u5fc6\uff08\u5411\u91cf\u6570\u636e\u5e93\uff09"""\n    \n    def __init__(self):\n        self.embeddings = OpenAIEmbeddings()\n        self.vectorstore = None\n        self.documents = []\n    \n    def add(self, text, metadata=None):\n        """\u6dfb\u52a0\u8bb0\u5fc6"""\n        self.documents.append({\n            "text": text,\n            "metadata": metadata or {}\n        })\n        \n        # \u66f4\u65b0\u5411\u91cf\u6570\u636e\u5e93\n        texts = [doc["text"] for doc in self.documents]\n        metadatas = [doc["metadata"] for doc in self.documents]\n        \n        self.vectorstore = FAISS.from_texts(\n            texts,\n            self.embeddings,\n            metadatas=metadatas\n        )\n    \n    def search(self, query, k=5):\n        """\u641c\u7d22\u76f8\u5173\u8bb0\u5fc6"""\n        if not self.vectorstore:\n            return []\n        \n        results = self.vectorstore.similarity_search(query, k=k)\n        return [doc.page_content for doc in results]\n    \n    def save(self, path):\n        """\u4fdd\u5b58\u8bb0\u5fc6"""\n        if self.vectorstore:\n            self.vectorstore.save_local(path)\n    \n    def load(self, path):\n        """\u52a0\u8f7d\u8bb0\u5fc6"""\n        self.vectorstore = FAISS.load_local(path, self.embeddings)\n\n\nclass MemoryAgent:\n    """\u5e26\u8bb0\u5fc6\u7684Agent"""\n    \n    def __init__(self, llm):\n        self.llm = llm\n        self.short_term = ShortTermMemory()\n        self.long_term = LongTermMemory()\n    \n    def run(self, user_input):\n        """\u8fd0\u884cAgent"""\n        # \u641c\u7d22\u76f8\u5173\u957f\u671f\u8bb0\u5fc6\n        relevant_memories = self.long_term.search(user_input)\n        \n        # \u6784\u5efaprompt\n        prompt = self._build_prompt(user_input, relevant_memories)\n        \n        # \u751f\u6210\u54cd\u5e94\n        response = self.llm.generate(prompt)\n        \n        # \u66f4\u65b0\u77ed\u671f\u8bb0\u5fc6\n        self.short_term.add("user", user_input)\n        self.short_term.add("assistant", response)\n        \n        # \u66f4\u65b0\u957f\u671f\u8bb0\u5fc6\n        self.long_term.add(\n            f"User: {user_input}\\nAssistant: {response}",\n            metadata={"timestamp": time.time()}\n        )\n        \n        return response\n    \n    def _build_prompt(self, user_input, relevant_memories):\n        """\u6784\u5efaprompt"""\n        prompt = "Relevant past conversations:\\n"\n        for memory in relevant_memories:\n            prompt += f"- {memory}\\n"\n        \n        prompt += "\\nCurrent conversation:\\n"\n        for msg in self.short_term.get_messages():\n            prompt += f"{msg[\'role\']}: {msg[\'content\']}\\n"\n        \n        prompt += f"user: {user_input}\\nassistant:"\n        \n        return prompt\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u591aagent\u7cfb\u7edf",children:"\u591aAgent\u7cfb\u7edf"}),"\n",(0,r.jsx)(e.h3,{id:"1-agent\u534f\u4f5c",children:"1. Agent\u534f\u4f5c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class MultiAgentSystem:\n    """\u591aAgent\u7cfb\u7edf"""\n    \n    def __init__(self):\n        self.agents = {}\n    \n    def register_agent(self, name, agent):\n        """\u6ce8\u518cAgent"""\n        self.agents[name] = agent\n    \n    def route_task(self, task):\n        """\u8def\u7531\u4efb\u52a1\u5230\u5408\u9002\u7684Agent"""\n        # \u4f7f\u7528LLM\u5224\u65ad\u5e94\u8be5\u7531\u54ea\u4e2aAgent\u5904\u7406\n        prompt = f"""Given the following task, which agent should handle it?\n\nTask: {task}\n\nAvailable agents:\n{self._format_agents()}\n\nAgent:"""\n        \n        agent_name = self.llm.generate(prompt).strip()\n        \n        if agent_name in self.agents:\n            return self.agents[agent_name]\n        else:\n            return self.agents[list(self.agents.keys())[0]]\n    \n    def run(self, task):\n        """\u8fd0\u884c\u4efb\u52a1"""\n        agent = self.route_task(task)\n        return agent.run(task)\n\n\n# \u793a\u4f8b\uff1a\u521b\u5efa\u4e13\u95e8\u7684Agent\nclass ResearchAgent:\n    """\u7814\u7a76Agent"""\n    def run(self, task):\n        # \u641c\u7d22\u548c\u603b\u7ed3\u4fe1\u606f\n        pass\n\n\nclass CodingAgent:\n    """\u7f16\u7a0bAgent"""\n    def run(self, task):\n        # \u7f16\u5199\u548c\u8c03\u8bd5\u4ee3\u7801\n        pass\n\n\nclass WritingAgent:\n    """\u5199\u4f5cAgent"""\n    def run(self, task):\n        # \u64b0\u5199\u6587\u7ae0\n        pass\n\n\n# \u4f7f\u7528\nsystem = MultiAgentSystem()\nsystem.register_agent("research", ResearchAgent())\nsystem.register_agent("coding", CodingAgent())\nsystem.register_agent("writing", WritingAgent())\n\nresult = system.run("Write a Python script to analyze data")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-agent\u8fa9\u8bba",children:"2. Agent\u8fa9\u8bba"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class DebateSystem:\n    """Agent\u8fa9\u8bba\u7cfb\u7edf"""\n    \n    def __init__(self, agents, judge):\n        self.agents = agents\n        self.judge = judge\n    \n    def debate(self, topic, rounds=3):\n        """\u8fdb\u884c\u8fa9\u8bba"""\n        history = []\n        \n        for round_num in range(rounds):\n            print(f"\\n=== Round {round_num + 1} ===")\n            \n            for agent_name, agent in self.agents.items():\n                # \u6784\u5efaprompt\n                prompt = self._build_debate_prompt(\n                    topic,\n                    agent_name,\n                    history\n                )\n                \n                # \u751f\u6210\u89c2\u70b9\n                response = agent.generate(prompt)\n                \n                print(f"\\n{agent_name}: {response}")\n                \n                history.append({\n                    "agent": agent_name,\n                    "response": response\n                })\n        \n        # \u88c1\u5224\u603b\u7ed3\n        summary = self.judge_debate(topic, history)\n        return summary\n    \n    def judge_debate(self, topic, history):\n        """\u88c1\u5224\u603b\u7ed3"""\n        prompt = f"""As a judge, summarize the debate on: {topic}\n\nDebate history:\n{self._format_history(history)}\n\nSummary:"""\n        \n        return self.judge.generate(prompt)\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u5b9e\u6218\u6848\u4f8b",children:"\u5b9e\u6218\u6848\u4f8b"}),"\n",(0,r.jsx)(e.h3,{id:"1-\u81ea\u52a8\u5316\u7814\u7a76\u52a9\u624b",children:"1. \u81ea\u52a8\u5316\u7814\u7a76\u52a9\u624b"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class ResearchAssistant:\n    """\u81ea\u52a8\u5316\u7814\u7a76\u52a9\u624b"""\n    \n    def __init__(self):\n        self.llm = OpenAI()\n        self.search_tool = DuckDuckGoSearchRun()\n        self.memory = LongTermMemory()\n    \n    def research_topic(self, topic, depth=3):\n        """\u7814\u7a76\u4e3b\u9898"""\n        results = {\n            "topic": topic,\n            "findings": [],\n            "summary": ""\n        }\n        \n        # \u751f\u6210\u7814\u7a76\u95ee\u9898\n        questions = self._generate_questions(topic, depth)\n        \n        # \u641c\u7d22\u6bcf\u4e2a\u95ee\u9898\n        for question in questions:\n            print(f"\u7814\u7a76\u95ee\u9898: {question}")\n            \n            # \u641c\u7d22\n            search_results = self.search_tool.run(question)\n            \n            # \u603b\u7ed3\n            summary = self._summarize(question, search_results)\n            \n            results["findings"].append({\n                "question": question,\n                "summary": summary\n            })\n            \n            # \u4fdd\u5b58\u5230\u8bb0\u5fc6\n            self.memory.add(f"Q: {question}\\nA: {summary}")\n        \n        # \u751f\u6210\u6700\u7ec8\u603b\u7ed3\n        results["summary"] = self._generate_final_summary(results["findings"])\n        \n        return results\n    \n    def _generate_questions(self, topic, depth):\n        """\u751f\u6210\u7814\u7a76\u95ee\u9898"""\n        prompt = f"""Generate {depth} research questions about: {topic}\n\nQuestions:\n1."""\n        \n        response = self.llm.generate(prompt)\n        questions = self._parse_questions(response)\n        return questions\n    \n    def _summarize(self, question, search_results):\n        """\u603b\u7ed3\u641c\u7d22\u7ed3\u679c"""\n        prompt = f"""Summarize the following search results for the question:\n\nQuestion: {question}\n\nSearch results:\n{search_results}\n\nSummary:"""\n        \n        return self.llm.generate(prompt)\n    \n    def _generate_final_summary(self, findings):\n        """\u751f\u6210\u6700\u7ec8\u603b\u7ed3"""\n        prompt = "Synthesize the following research findings:\\n\\n"\n        \n        for i, finding in enumerate(findings):\n            prompt += f"{i+1}. {finding[\'question\']}\\n"\n            prompt += f"   {finding[\'summary\']}\\n\\n"\n        \n        prompt += "Final Summary:"\n        \n        return self.llm.generate(prompt)\n\n\n# \u4f7f\u7528\nassistant = ResearchAssistant()\nresults = assistant.research_topic("\u4eba\u5de5\u667a\u80fd\u7684\u6700\u65b0\u8fdb\u5c55", depth=5)\nprint(results["summary"])\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u4ee3\u7801\u751f\u6210agent",children:"2. \u4ee3\u7801\u751f\u6210Agent"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class CodingAgent:\n    """\u4ee3\u7801\u751f\u6210Agent"""\n    \n    def __init__(self):\n        self.llm = OpenAI()\n    \n    def generate_code(self, requirement):\n        """\u751f\u6210\u4ee3\u7801"""\n        # \u5206\u6790\u9700\u6c42\n        analysis = self._analyze_requirement(requirement)\n        \n        # \u8bbe\u8ba1\u65b9\u6848\n        design = self._design_solution(analysis)\n        \n        # \u751f\u6210\u4ee3\u7801\n        code = self._write_code(design)\n        \n        # \u6d4b\u8bd5\u4ee3\u7801\n        test_results = self._test_code(code)\n        \n        # \u5982\u679c\u6d4b\u8bd5\u5931\u8d25\uff0c\u4fee\u590d\u4ee3\u7801\n        if not test_results["passed"]:\n            code = self._fix_code(code, test_results["errors"])\n        \n        return {\n            "code": code,\n            "design": design,\n            "tests": test_results\n        }\n    \n    def _analyze_requirement(self, requirement):\n        """\u5206\u6790\u9700\u6c42"""\n        prompt = f"""Analyze the following coding requirement:\n\nRequirement: {requirement}\n\nAnalysis (include: inputs, outputs, constraints, edge cases):"""\n        \n        return self.llm.generate(prompt)\n    \n    def _design_solution(self, analysis):\n        """\u8bbe\u8ba1\u65b9\u6848"""\n        prompt = f"""Design a solution based on this analysis:\n\n{analysis}\n\nDesign (include: algorithm, data structures, functions):"""\n        \n        return self.llm.generate(prompt)\n    \n    def _write_code(self, design):\n        """\u7f16\u5199\u4ee3\u7801"""\n        prompt = f"""Write Python code based on this design:\n\n{design}\n\nCode:\n```python"""\n        \n        response = self.llm.generate(prompt)\n        code = response.split("```")[0]\n        return code\n    \n    def _test_code(self, code):\n        """\u6d4b\u8bd5\u4ee3\u7801"""\n        try:\n            # \u5728\u5b89\u5168\u73af\u5883\u4e2d\u6267\u884c\u4ee3\u7801\n            exec(code)\n            return {"passed": True, "errors": []}\n        except Exception as e:\n            return {"passed": False, "errors": [str(e)]}\n    \n    def _fix_code(self, code, error_list):\n        """\u4fee\u590d\u4ee3\u7801"""\n        errors_str = \'\\n\'.join(error_list)\n        prompt = f"""Fix the following code errors:\n\nCode:\n{code}\n\nErrors:\n{errors_str}\n\nFixed code:"""\n        \n        response = self.llm.generate(prompt)\n        return response\n\n\n# \u4f7f\u7528\nagent = CodingAgent()\nresult = agent.generate_code("\u521b\u5efa\u4e00\u4e2a\u51fd\u6570\uff0c\u8ba1\u7b97\u6590\u6ce2\u90a3\u5951\u6570\u5217\u7684\u7b2cn\u9879")\nprint(result["code"])\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u6700\u4f73\u5b9e\u8df5",children:"\u6700\u4f73\u5b9e\u8df5"}),"\n",(0,r.jsx)(e.h3,{id:"1-prompt\u8bbe\u8ba1",children:"1. Prompt\u8bbe\u8ba1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# \u597d\u7684Agent Prompt\u6a21\u677f\nAGENT_PROMPT = """You are a helpful AI assistant with access to tools.\n\nYour goal: {goal}\n\nAvailable tools:\n{tools}\n\nGuidelines:\n1. Think step by step\n2. Use tools when necessary\n3. Verify your answers\n4. Be concise and accurate\n\nCurrent task: {task}\n\nLet\'s begin:\n"""\n'})}),"\n",(0,r.jsx)(e.h3,{id:"2-\u9519\u8bef\u5904\u7406",children:"2. \u9519\u8bef\u5904\u7406"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class RobustAgent:\n    """\u5065\u58ee\u7684Agent"""\n    \n    def run(self, task, max_retries=3):\n        """\u8fd0\u884cAgent with\u91cd\u8bd5"""\n        for attempt in range(max_retries):\n            try:\n                result = self._execute(task)\n                return result\n            except Exception as e:\n                print(f"Attempt {attempt + 1} failed: {e}")\n                if attempt == max_retries - 1:\n                    return f"Failed after {max_retries} attempts: {e}"\n                time.sleep(2 ** attempt)  # \u6307\u6570\u9000\u907f\n'})}),"\n",(0,r.jsx)(e.h3,{id:"3-\u6210\u672c\u63a7\u5236",children:"3. \u6210\u672c\u63a7\u5236"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class CostAwareAgent:\n    """\u6210\u672c\u611f\u77e5Agent"""\n    \n    def __init__(self, budget=10.0):\n        self.budget = budget\n        self.spent = 0.0\n    \n    def run(self, task):\n        """\u8fd0\u884cAgent with\u6210\u672c\u63a7\u5236"""\n        estimated_cost = self._estimate_cost(task)\n        \n        if self.spent + estimated_cost > self.budget:\n            return "Budget exceeded"\n        \n        result = self._execute(task)\n        self.spent += estimated_cost\n        \n        return result\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\u672a\u6765\u8d8b\u52bf",children:"\u672a\u6765\u8d8b\u52bf"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u66f4\u5f3a\u7684\u81ea\u4e3b\u6027"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u66f4\u5c11\u7684\u4eba\u5de5\u5e72\u9884"}),"\n",(0,r.jsx)(e.li,{children:"\u66f4\u590d\u6742\u7684\u4efb\u52a1\u5904\u7406"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u591aAgent\u534f\u4f5c"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Agent\u4e4b\u95f4\u7684\u901a\u4fe1\u534f\u8bae"}),"\n",(0,r.jsx)(e.li,{children:"\u5206\u5e03\u5f0fAgent\u7cfb\u7edf"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u5177\u8eabAgent"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u673a\u5668\u4eba\u63a7\u5236"}),"\n",(0,r.jsx)(e.li,{children:"\u7269\u7406\u4e16\u754c\u4ea4\u4e92"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u53ef\u4fe1\u8d56\u7684Agent"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u53ef\u89e3\u91ca\u6027"}),"\n",(0,r.jsx)(e.li,{children:"\u5b89\u5168\u6027\u4fdd\u8bc1"}),"\n",(0,r.jsx)(e.li,{children:"\u5bf9\u9f50\u4eba\u7c7b\u4ef7\u503c\u89c2"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"\u603b\u7ed3",children:"\u603b\u7ed3"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5173\u952e\u8981\u70b9"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Agent = \u611f\u77e5 + \u601d\u8003 + \u884c\u52a8"}),"\n",(0,r.jsx)(e.li,{children:"ReAct\u662f\u4e3b\u6d41\u67b6\u6784"}),"\n",(0,r.jsx)(e.li,{children:"\u5de5\u5177\u8c03\u7528\u6269\u5c55Agent\u80fd\u529b"}),"\n",(0,r.jsx)(e.li,{children:"\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e0a\u4e0b\u6587"}),"\n",(0,r.jsx)(e.li,{children:"\u591aAgent\u534f\u4f5c\u89e3\u51b3\u590d\u6742\u4efb\u52a1"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u5b66\u4e60\u5efa\u8bae"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u7406\u89e3Agent\u7684\u6838\u5fc3\u6982\u5ff5"}),"\n",(0,r.jsx)(e.li,{children:"\u5b9e\u8df5ReAct\u67b6\u6784"}),"\n",(0,r.jsx)(e.li,{children:"\u5b66\u4e60\u5de5\u5177\u8c03\u7528"}),"\n",(0,r.jsx)(e.li,{children:"\u6784\u5efa\u81ea\u5df1\u7684Agent\u7cfb\u7edf"}),"\n"]}),"\n",(0,r.jsx)(t,{})]})}function u(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},28453(n,e,t){t.d(e,{R:()=>i,x:()=>o});var s=t(96540);const r={},l=s.createContext(r);function i(n){const e=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:i(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);