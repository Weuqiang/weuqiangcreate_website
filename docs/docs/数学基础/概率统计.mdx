---
sidebar_position: 2
title:  - AI
---

#  - AI

AI****AI

## 

### 

****01

```python
import numpy as np
import matplotlib.pyplot as plt

# 
def flip_coin(n=1000):
    """n"""
    results = np.random.choice(['', ''], size=n)
    prob_head = np.sum(results == '') / n
    return prob_head

# 
experiments = [10, 100, 1000, 10000]
for n in experiments:
    prob = flip_coin(n)
    print(f"{n:5d}: {prob:.4f}")

# 
n_flips = np.arange(1, 1001)
cumulative_probs = []

results = np.random.choice([0, 1], size=1000)
for i in range(1, 1001):
    cumulative_probs.append(np.mean(results[:i]))

plt.figure(figsize=(10, 6))
plt.plot(n_flips, cumulative_probs, label='')
plt.axhline(y=0.5, color='r', linestyle='--', label='')
plt.xlabel('')
plt.ylabel('')
plt.title('')
plt.legend()
plt.grid(True)
plt.show()
```

### AI

**1. **

```python
# 
predictions = np.array([0.7, 0.2, 0.1])
classes = ['', '', '']

print(":")
for cls, prob in zip(classes, predictions):
    print(f"  {cls}: {prob:.1%}")

# 
predicted_class = classes[np.argmax(predictions)]
confidence = np.max(predictions)
print(f"\n: {predicted_class} (: {confidence:.1%})")
```

**2. **

```python
# 
vocab = ['', '', '', '', '']
probs = np.array([0.3, 0.25, 0.2, 0.15, 0.1])

# 
next_word = np.random.choice(vocab, p=probs)
print(f": {next_word}")

# 
samples = np.random.choice(vocab, size=1000, p=probs)
for word in vocab:
    count = np.sum(samples == word)
    print(f"{word}: {count/1000:.2%} (: {probs[vocab.index(word)]:.2%})")
```

###  - 

```python
# P(A|B) = P(A and B) / P(B)

# 
P_disease = 0.01  # 1%
P_positive_given_disease = 0.99  # 99%
P_positive_given_healthy = 0.05  # 5%

# 

# P() = P(|)×P() + P(|)×P()
P_positive = (P_positive_given_disease * P_disease + 
              P_positive_given_healthy * (1 - P_disease))

# P(|) = P(|)×P() / P()
P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive

print(f": {P_disease_given_positive:.1%}")
print("16.6%")
```

**AI**

```python
class SpamClassifier:
    """"""
    
    def __init__(self):
        self.word_probs = {}
        self.spam_prob = 0.5
    
    def train(self, emails, labels):
        """"""
        # 
        self.spam_prob = np.mean(labels)
        
        # 
        spam_emails = [email for email, label in zip(emails, labels) if label == 1]
        ham_emails = [email for email, label in zip(emails, labels) if label == 0]
        
        all_words = set()
        for email in emails:
            all_words.update(email.split())
        
        for word in all_words:
            # 
            spam_count = sum(1 for email in spam_emails if word in email)
            spam_prob = (spam_count + 1) / (len(spam_emails) + 2)  # 
            
            # 
            ham_count = sum(1 for email in ham_emails if word in email)
            ham_prob = (ham_count + 1) / (len(ham_emails) + 2)
            
            self.word_probs[word] = (spam_prob, ham_prob)
    
    def predict(self, email):
        """"""
        words = email.split()
        
        # 
        log_spam_prob = np.log(self.spam_prob)
        log_ham_prob = np.log(1 - self.spam_prob)
        
        for word in words:
            if word in self.word_probs:
                spam_prob, ham_prob = self.word_probs[word]
                log_spam_prob += np.log(spam_prob)
                log_ham_prob += np.log(ham_prob)
        
        # 
        spam_score = np.exp(log_spam_prob)
        ham_score = np.exp(log_ham_prob)
        
        spam_probability = spam_score / (spam_score + ham_score)
        
        return spam_probability

# 
emails = [
    " ",
    "",
    " ",
    "",
    " ",
    ""
]
labels = [1, 0, 1, 0, 1, 0]  # 1=, 0=

classifier = SpamClassifier()
classifier.train(emails, labels)

# 
test_emails = [
    "",
    ""
]

for email in test_emails:
    prob = classifier.predict(email)
    print(f"'{email}' : {prob:.1%}")
```

## 

###  - 

****

```python
# 
dice_values = np.array([1, 2, 3, 4, 5, 6])
probabilities = np.array([1/6] * 6)

expectation = np.sum(dice_values * probabilities)
print(f": {expectation}")  # 3.5

# 10000
results = np.random.randint(1, 7, size=10000)
print(f": {np.mean(results):.2f}")

# 
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.bar(dice_values, probabilities)
plt.axvline(x=expectation, color='r', linestyle='--', label=f'={expectation}')
plt.xlabel('')
plt.ylabel('')
plt.title('')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(results, bins=6, density=True, alpha=0.7, edgecolor='black')
plt.axvline(x=np.mean(results), color='r', linestyle='--', label=f'={np.mean(results):.2f}')
plt.xlabel('')
plt.ylabel('')
plt.title('10000')
plt.legend()

plt.tight_layout()
plt.show()
```

**AI**

```python
class SimpleAgent:
    """"""
    
    def __init__(self):
        # 
        self.Q = {
            '': 0,
            '': 0,
            '': 0,
            '': 0
        }
        self.counts = {action: 0 for action in self.Q}
    
    def choose_action(self, epsilon=0.1):
        """ε-"""
        if np.random.random() < epsilon:
            # 
            return np.random.choice(list(self.Q.keys()))
        else:
            # 
            return max(self.Q, key=self.Q.get)
    
    def update(self, action, reward):
        """"""
        self.counts[action] += 1
        n = self.counts[action]
        
        # Q(a) = Q(a) + (1/n) * (reward - Q(a))
        self.Q[action] += (reward - self.Q[action]) / n
    
    def train(self, env, episodes=1000):
        """"""
        for episode in range(episodes):
            action = self.choose_action()
            reward = env.get_reward(action)
            self.update(action, reward)
            
            if episode % 100 == 0:
                print(f"Episode {episode}:")
                for action, q in self.Q.items():
                    print(f"  {action}: {q:.2f}")

# 
class Environment:
    def __init__(self):
        # 
        self.true_rewards = {
            '': 1,
            '': 5,
            '': 3,
            '': 2
        }
    
    def get_reward(self, action):
        """"""
        mean = self.true_rewards[action]
        return mean + np.random.randn()

# 
env = Environment()
agent = SimpleAgent()
agent.train(env, episodes=1000)

print("\n:")
for action, q in agent.Q.items():
    true_q = env.true_rewards[action]
    print(f"{action}: ={q:.2f}, ={true_q:.2f}")
```

###  - 

****

```python
# 
data1 = np.array([5, 5, 5, 5, 5])
data2 = np.array([1, 3, 5, 7, 9])
data3 = np.array([0, 0, 5, 10, 10])

print(":")
for i, data in enumerate([data1, data2, data3], 1):
    mean = np.mean(data)
    var = np.var(data)
    std = np.std(data)
    print(f"{i}: ={mean:.1f}, ={var:.1f}, ={std:.1f}")

# 
plt.figure(figsize=(12, 4))
for i, data in enumerate([data1, data2, data3], 1):
    plt.subplot(1, 3, i)
    plt.scatter(range(len(data)), data, s=100)
    plt.axhline(y=np.mean(data), color='r', linestyle='--', label=f'={np.mean(data):.1f}')
    plt.ylim(-1, 11)
    plt.title(f'{i} (={np.var(data):.1f})')
    plt.legend()
    plt.grid(True)

plt.tight_layout()
plt.show()
```

**AIBatch Normalization**

```python
class BatchNorm:
    """"""
    
    def __init__(self, num_features, eps=1e-5, momentum=0.1):
        self.eps = eps
        self.momentum = momentum
        
        # 
        self.gamma = np.ones(num_features)
        self.beta = np.zeros(num_features)
        
        # 
        self.running_mean = np.zeros(num_features)
        self.running_var = np.ones(num_features)
    
    def forward(self, x, training=True):
        """"""
        if training:
            # 
            batch_mean = np.mean(x, axis=0)
            batch_var = np.var(x, axis=0)
            
            # 
            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * batch_mean
            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * batch_var
            
            # 
            x_norm = (x - batch_mean) / np.sqrt(batch_var + self.eps)
        else:
            # 
            x_norm = (x - self.running_mean) / np.sqrt(self.running_var + self.eps)
        
        # 
        out = self.gamma * x_norm + self.beta
        
        return out

# 
np.random.seed(42)
x = np.random.randn(100, 10) * 10 + 50  # 5010

bn = BatchNorm(num_features=10)

print(":")
print(f"  : {np.mean(x, axis=0)[:3]}")
print(f"  : {np.var(x, axis=0)[:3]}")

x_norm = bn.forward(x, training=True)

print("\n:")
print(f"  : {np.mean(x_norm, axis=0)[:3]}")
print(f"  : {np.var(x_norm, axis=0)[:3]}")

# 
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.hist(x[:, 0], bins=30, alpha=0.7, edgecolor='black')
plt.title(f'\n={np.mean(x[:, 0]):.1f}, ={np.var(x[:, 0]):.1f}')
plt.xlabel('')
plt.ylabel('')

plt.subplot(1, 2, 2)
plt.hist(x_norm[:, 0], bins=30, alpha=0.7, edgecolor='black')
plt.title(f'\n={np.mean(x_norm[:, 0]):.1f}, ={np.var(x_norm[:, 0]):.1f}')
plt.xlabel('')
plt.ylabel('')

plt.tight_layout()
plt.show()
```

## 

### 

****

```python
from scipy import stats

# 01
mu, sigma = 0, 1
x = np.linspace(-4, 4, 1000)
y = stats.norm.pdf(x, mu, sigma)

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(x, y, linewidth=2)
plt.fill_between(x, y, alpha=0.3)
plt.title(' N(0,1)')
plt.xlabel('x')
plt.ylabel('')
plt.grid(True)

# 
plt.subplot(1, 2, 2)
for mu, sigma in [(0, 1), (0, 2), (2, 1)]:
    y = stats.norm.pdf(x, mu, sigma)
    plt.plot(x, y, label=f'μ={mu}, σ={sigma}', linewidth=2)
plt.title('')
plt.xlabel('x')
plt.ylabel('')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

# 68-95-99.7
print(":")
print(f"68% [μ-σ, μ+σ] ")
print(f"95% [μ-2σ, μ+2σ] ")
print(f"99.7% [μ-3σ, μ+3σ] ")
```

**AI**

```python
def initialize_weights(shape, method='xavier'):
    """"""
    if method == 'xavier':
        # Xaviertanhsigmoid
        fan_in, fan_out = shape
        limit = np.sqrt(6 / (fan_in + fan_out))
        return np.random.uniform(-limit, limit, shape)
    
    elif method == 'he':
        # HeReLU
        fan_in = shape[0]
        std = np.sqrt(2 / fan_in)
        return np.random.randn(*shape) * std
    
    elif method == 'normal':
        # 
        return np.random.randn(*shape) * 0.01

# 
methods = ['xavier', 'he', 'normal']
shape = (100, 100)

plt.figure(figsize=(15, 4))
for i, method in enumerate(methods, 1):
    weights = initialize_weights(shape, method)
    
    plt.subplot(1, 3, i)
    plt.hist(weights.flatten(), bins=50, alpha=0.7, edgecolor='black')
    plt.title(f'{method}\n={np.mean(weights):.4f}, ={np.var(weights):.4f}')
    plt.xlabel('')
    plt.ylabel('')
    plt.grid(True)

plt.tight_layout()
plt.show()
```

### 

```python
# 
p = 0.7  # 
result = np.random.binomial(1, p)
print(f": {'' if result == 1 else ''}")

# n
n = 10
results = np.random.binomial(n, p, size=1000)

plt.figure(figsize=(10, 6))
plt.hist(results, bins=range(n+2), alpha=0.7, edgecolor='black', density=True)

# 
x = range(n+1)
y = [stats.binom.pmf(k, n, p) for k in x]
plt.plot(x, y, 'ro-', linewidth=2, markersize=8, label='')

plt.xlabel('')
plt.ylabel('')
plt.title(f' B({n}, {p})')
plt.legend()
plt.grid(True)
plt.show()
```

## 

### 1A/B

```python
class ABTest:
    """A/B"""
    
    def __init__(self):
        self.results = {'A': [], 'B': []}
    
    def add_result(self, version, success):
        """"""
        self.results[version].append(1 if success else 0)
    
    def get_stats(self, version):
        """"""
        data = self.results[version]
        n = len(data)
        successes = sum(data)
        rate = successes / n if n > 0 else 0
        
        # 95%
        se = np.sqrt(rate * (1 - rate) / n) if n > 0 else 0
        ci_lower = rate - 1.96 * se
        ci_upper = rate + 1.96 * se
        
        return {
            'n': n,
            'successes': successes,
            'rate': rate,
            'ci': (ci_lower, ci_upper)
        }
    
    def compare(self):
        """AB"""
        stats_a = self.get_stats('A')
        stats_b = self.get_stats('B')
        
        print("A/B:")
        print(f"\nA:")
        print(f"  : {stats_a['n']}")
        print(f"  : {stats_a['rate']:.2%}")
        print(f"  95%: [{stats_a['ci'][0]:.2%}, {stats_a['ci'][1]:.2%}]")
        
        print(f"\nB:")
        print(f"  : {stats_b['n']}")
        print(f"  : {stats_b['rate']:.2%}")
        print(f"  95%: [{stats_b['ci'][0]:.2%}, {stats_b['ci'][1]:.2%}]")
        
        # 
        if stats_a['ci'][1] < stats_b['ci'][0]:
            print("\n: BA ")
        elif stats_b['ci'][1] < stats_a['ci'][0]:
            print("\n: AB ")
        else:
            print("\n: ")

# A/B
test = ABTest()

# A10%
for _ in range(1000):
    success = np.random.random() < 0.10
    test.add_result('A', success)

# B12%
for _ in range(1000):
    success = np.random.random() < 0.12
    test.add_result('B', success)

test.compare()
```

### 2

```python
class AnomalyDetector:
    """"""
    
    def __init__(self, threshold=0.01):
        self.threshold = threshold
        self.mean = None
        self.std = None
    
    def fit(self, X):
        """"""
        self.mean = np.mean(X, axis=0)
        self.std = np.std(X, axis=0)
    
    def probability(self, X):
        """"""
        # 
        probs = np.ones(len(X))
        for i in range(X.shape[1]):
            probs *= stats.norm.pdf(X[:, i], self.mean[i], self.std[i])
        return probs
    
    def predict(self, X):
        """"""
        probs = self.probability(X)
        return probs < self.threshold
    
    def visualize(self, X, y_true=None):
        """2"""
        if X.shape[1] != 2:
            print("2")
            return
        
        # 
        y_pred = self.predict(X)
        
        plt.figure(figsize=(12, 5))
        
        # 
        if y_true is not None:
            plt.subplot(1, 2, 1)
            plt.scatter(X[y_true==0, 0], X[y_true==0, 1], c='blue', label='', alpha=0.6)
            plt.scatter(X[y_true==1, 0], X[y_true==1, 1], c='red', label='', alpha=0.6)
            plt.title('')
            plt.legend()
            plt.grid(True)
        
        # 
        plt.subplot(1, 2, 2)
        plt.scatter(X[~y_pred, 0], X[~y_pred, 1], c='blue', label='', alpha=0.6)
        plt.scatter(X[y_pred, 0], X[y_pred, 1], c='red', label='', alpha=0.6)
        
        # 
        xx, yy = np.meshgrid(
            np.linspace(X[:, 0].min()-1, X[:, 0].max()+1, 100),
            np.linspace(X[:, 1].min()-1, X[:, 1].max()+1, 100)
        )
        Z = self.probability(np.c_[xx.ravel(), yy.ravel()])
        Z = Z.reshape(xx.shape)
        plt.contour(xx, yy, Z, levels=[self.threshold], colors='green', linewidths=2)
        
        plt.title('')
        plt.legend()
        plt.grid(True)
        
        plt.tight_layout()
        plt.show()

# 
np.random.seed(42)

# 
X_normal = np.random.randn(300, 2)

# 
X_anomaly = np.random.uniform(-4, 4, (20, 2))

X = np.vstack([X_normal, X_anomaly])
y = np.array([0]*300 + [1]*20)

# 
detector = AnomalyDetector(threshold=0.01)
detector.fit(X_normal)

# 
detector.visualize(X, y)

# 
y_pred = detector.predict(X)
from sklearn.metrics import classification_report
print(classification_report(y, y_pred, target_names=['', '']))
```

## 

AI

1. ****
2. ****
3. ****
4. ****
5. ****

**AI**

## 

1. 
2. 
3. Dropout
4. A/B



