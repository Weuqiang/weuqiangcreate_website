---
sidebar_position: 9
title: 
tags: [, , Kafka, RabbitMQ]
---

# 



## 

### 

```javascript
const mqConcepts = {
  // 
  producer: {
    role: '',
    responsibilities: [
      '',
      '',
      ''
    ]
  },
  
  // 
  consumer: {
    role: '',
    responsibilities: [
      '',
      '',
      ''
    ]
  },
  
  // /
  topic: {
    role: '',
    features: [
      '',
      '',
      ''
    ]
  },
  
  // 
  consumerGroup: {
    role: '',
    features: [
      '',
      '',
      ''
    ]
  }
};
```

### 

```javascript
// 
class QueueModel {
  constructor() {
    this.queue = [];
    this.consumers = [];
  }
  
  send(message) {
    this.queue.push(message);
    this.notifyConsumer();
  }
  
  receive() {
    return this.queue.shift();
  }
  
  notifyConsumer() {
    // 
    if (this.consumers.length > 0) {
      const consumer = this.consumers[this.currentIndex % this.consumers.length];
      consumer.onMessage(this.receive());
      this.currentIndex++;
    }
  }
}

// 
class PubSubModel {
  constructor() {
    this.topics = new Map();
  }
  
  subscribe(topic, subscriber) {
    if (!this.topics.has(topic)) {
      this.topics.set(topic, []);
    }
    this.topics.get(topic).push(subscriber);
  }
  
  publish(topic, message) {
    const subscribers = this.topics.get(topic) || [];
    
    // 
    for (const subscriber of subscribers) {
      subscriber.onMessage(message);
    }
  }
}
```

## Kafka

### Producer

```javascript
const { Kafka } = require('kafkajs');

class KafkaProducer {
  constructor(brokers) {
    this.kafka = new Kafka({
      clientId: 'my-app',
      brokers
    });
    
    this.producer = this.kafka.producer({
      // 
      allowAutoTopicCreation: true,
      transactionTimeout: 30000
    });
  }
  
  async connect() {
    await this.producer.connect();
  }
  
  async send(topic, messages) {
    try {
      const result = await this.producer.send({
        topic,
        messages: messages.map(msg => ({
          key: msg.key,
          value: JSON.stringify(msg.value),
          partition: msg.partition,
          headers: msg.headers
        }))
      });
      
      return result;
    } catch (error) {
      console.error('Failed to send message:', error);
      throw error;
    }
  }
  
  // 
  async sendBatch(topic, messages) {
    const batch = this.producer.sendBatch({
      topicMessages: [{
        topic,
        messages: messages.map(msg => ({
          value: JSON.stringify(msg)
        }))
      }]
    });
    
    return await batch;
  }
  
  // 
  async sendTransaction(topic, messages) {
    const transaction = await this.producer.transaction();
    
    try {
      await transaction.send({
        topic,
        messages: messages.map(msg => ({
          value: JSON.stringify(msg)
        }))
      });
      
      await transaction.commit();
    } catch (error) {
      await transaction.abort();
      throw error;
    }
  }
  
  async disconnect() {
    await this.producer.disconnect();
  }
}

// 
const producer = new KafkaProducer(['localhost:9092']);

await producer.connect();

await producer.send('user-events', [
  {
    key: 'user-123',
    value: {
      type: 'user_created',
      userId: '123',
      timestamp: Date.now()
    }
  }
]);
```

### Consumer

```javascript
class KafkaConsumer {
  constructor(brokers, groupId) {
    this.kafka = new Kafka({
      clientId: 'my-app',
      brokers
    });
    
    this.consumer = this.kafka.consumer({
      groupId,
      sessionTimeout: 30000,
      heartbeatInterval: 3000
    });
    
    this.handlers = new Map();
  }
  
  async connect() {
    await this.consumer.connect();
  }
  
  async subscribe(topics) {
    await this.consumer.subscribe({
      topics,
      fromBeginning: false
    });
  }
  
  registerHandler(topic, handler) {
    this.handlers.set(topic, handler);
  }
  
  async run() {
    await this.consumer.run({
      eachMessage: async ({ topic, partition, message }) => {
        const handler = this.handlers.get(topic);
        
        if (!handler) {
          console.warn(`No handler for topic: ${topic}`);
          return;
        }
        
        try {
          const value = JSON.parse(message.value.toString());
          
          await handler({
            topic,
            partition,
            offset: message.offset,
            key: message.key?.toString(),
            value,
            headers: message.headers,
            timestamp: message.timestamp
          });
          
        } catch (error) {
          console.error('Error processing message:', error);
          // 
          await this.handleError(topic, message, error);
        }
      }
    });
  }
  
  async handleError(topic, message, error) {
    // 
    await producer.send(`${topic}.dlq`, [{
      value: {
        originalMessage: message,
        error: error.message,
        timestamp: Date.now()
      }
    }]);
  }
  
  async disconnect() {
    await this.consumer.disconnect();
  }
}

// 
const consumer = new KafkaConsumer(['localhost:9092'], 'my-group');

await consumer.connect();
await consumer.subscribe(['user-events']);

consumer.registerHandler('user-events', async (message) => {
  console.log('Received message:', message.value);
  
  // 
  await processUserEvent(message.value);
});

await consumer.run();
```

## RabbitMQ

### 

```javascript
const amqp = require('amqplib');

class RabbitMQProducer {
  constructor(url) {
    this.url = url;
    this.connection = null;
    this.channel = null;
  }
  
  async connect() {
    this.connection = await amqp.connect(this.url);
    this.channel = await this.connection.createChannel();
  }
  
  async sendToQueue(queue, message, options = {}) {
    // 
    await this.channel.assertQueue(queue, {
      durable: true,
      ...options
    });
    
    // 
    const sent = this.channel.sendToQueue(
      queue,
      Buffer.from(JSON.stringify(message)),
      {
        persistent: true,
        contentType: 'application/json'
      }
    );
    
    if (!sent) {
      // drain
      await new Promise(resolve => {
        this.channel.once('drain', resolve);
      });
    }
  }
  
  async publishToExchange(exchange, routingKey, message, options = {}) {
    // 
    await this.channel.assertExchange(exchange, 'topic', {
      durable: true,
      ...options
    });
    
    // 
    this.channel.publish(
      exchange,
      routingKey,
      Buffer.from(JSON.stringify(message)),
      {
        persistent: true,
        contentType: 'application/json'
      }
    );
  }
  
  async close() {
    await this.channel.close();
    await this.connection.close();
  }
}

// 
const producer = new RabbitMQProducer('amqp://localhost');
await producer.connect();

// 
await producer.sendToQueue('tasks', {
  type: 'email',
  to: 'user@example.com',
  subject: 'Hello'
});

// 
await producer.publishToExchange(
  'events',
  'user.created',
  { userId: '123' }
);
```

### 

```javascript
class RabbitMQConsumer {
  constructor(url) {
    this.url = url;
    this.connection = null;
    this.channel = null;
  }
  
  async connect() {
    this.connection = await amqp.connect(this.url);
    this.channel = await this.connection.createChannel();
    
    // 
    await this.channel.prefetch(10);
  }
  
  async consumeQueue(queue, handler, options = {}) {
    // 
    await this.channel.assertQueue(queue, {
      durable: true,
      ...options
    });
    
    // 
    await this.channel.consume(queue, async (msg) => {
      if (!msg) return;
      
      try {
        const content = JSON.parse(msg.content.toString());
        
        await handler(content, msg);
        
        // 
        this.channel.ack(msg);
        
      } catch (error) {
        console.error('Error processing message:', error);
        
        // 
        this.channel.nack(msg, false, true);
      }
    });
  }
  
  async subscribeToExchange(exchange, pattern, handler) {
    // 
    await this.channel.assertExchange(exchange, 'topic', {
      durable: true
    });
    
    // 
    const { queue } = await this.channel.assertQueue('', {
      exclusive: true
    });
    
    // 
    await this.channel.bindQueue(queue, exchange, pattern);
    
    // 
    await this.consumeQueue(queue, handler);
  }
  
  async close() {
    await this.channel.close();
    await this.connection.close();
  }
}

// 
const consumer = new RabbitMQConsumer('amqp://localhost');
await consumer.connect();

// 
await consumer.consumeQueue('tasks', async (message) => {
  console.log('Processing task:', message);
  await processTask(message);
});

// 
await consumer.subscribeToExchange(
  'events',
  'user.*',
  async (message) => {
    console.log('User event:', message);
  }
);
```

## 

### 

```javascript
class ReliableProducer {
  constructor(producer) {
    this.producer = producer;
    this.pendingMessages = new Map();
  }
  
  async sendWithConfirm(topic, message) {
    const messageId = this.generateMessageId();
    
    // 
    this.pendingMessages.set(messageId, {
      topic,
      message,
      timestamp: Date.now(),
      retries: 0
    });
    
    try {
      await this.producer.send(topic, [{
        key: messageId,
        value: message
      }]);
      
      // 
      this.pendingMessages.delete(messageId);
      
    } catch (error) {
      // 
      await this.retry(messageId);
    }
  }
  
  async retry(messageId) {
    const pending = this.pendingMessages.get(messageId);
    
    if (!pending) return;
    
    if (pending.retries >= 3) {
      // 
      console.error('Message failed after retries:', pending);
      this.pendingMessages.delete(messageId);
      return;
    }
    
    pending.retries++;
    
    // 
    const delay = Math.pow(2, pending.retries) * 1000;
    
    setTimeout(async () => {
      try {
        await this.producer.send(pending.topic, [{
          key: messageId,
          value: pending.message
        }]);
        
        this.pendingMessages.delete(messageId);
      } catch (error) {
        await this.retry(messageId);
      }
    }, delay);
  }
  
  generateMessageId() {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

### 

```javascript
class IdempotentConsumer {
  constructor(consumer, redis) {
    this.consumer = consumer;
    this.redis = redis;
  }
  
  async processMessage(message, handler) {
    const messageId = message.key || this.getMessageId(message);
    
    // 
    const processed = await this.redis.get(`processed:${messageId}`);
    
    if (processed) {
      console.log('Message already processed:', messageId);
      return;
    }
    
    // 
    await handler(message);
    
    // 24
    await this.redis.setex(`processed:${messageId}`, 86400, '1');
  }
  
  getMessageId(message) {
    // ID
    const crypto = require('crypto');
    return crypto
      .createHash('md5')
      .update(JSON.stringify(message))
      .digest('hex');
  }
}
```

## 

```javascript
class DelayQueue {
  constructor(redis) {
    this.redis = redis;
    this.queueKey = 'delay_queue';
  }
  
  async add(message, delaySeconds) {
    const executeAt = Date.now() + delaySeconds * 1000;
    
    await this.redis.zadd(
      this.queueKey,
      executeAt,
      JSON.stringify(message)
    );
  }
  
  async poll() {
    const now = Date.now();
    
    // 
    const messages = await this.redis.zrangebyscore(
      this.queueKey,
      0,
      now,
      'LIMIT',
      0,
      100
    );
    
    if (messages.length === 0) {
      return [];
    }
    
    // 
    await this.redis.zremrangebyscore(this.queueKey, 0, now);
    
    return messages.map(msg => JSON.parse(msg));
  }
  
  async start(handler) {
    setInterval(async () => {
      const messages = await this.poll();
      
      for (const message of messages) {
        try {
          await handler(message);
        } catch (error) {
          console.error('Error processing delayed message:', error);
        }
      }
    }, 1000);
  }
}

// 
const delayQueue = new DelayQueue(redis);

// 
await delayQueue.add({
  type: 'reminder',
  userId: '123',
  message: 'Your order is ready'
}, 3600); // 1

// 
delayQueue.start(async (message) => {
  console.log('Processing delayed message:', message);
  await sendNotification(message);
});
```

## 

```javascript
class DeadLetterQueue {
  constructor(producer, consumer) {
    this.producer = producer;
    this.consumer = consumer;
    this.maxRetries = 3;
  }
  
  async handleFailedMessage(topic, message, error) {
    const retries = message.retries || 0;
    
    if (retries < this.maxRetries) {
      // 
      await this.retry(topic, message, retries + 1);
    } else {
      // 
      await this.sendToDLQ(topic, message, error);
    }
  }
  
  async retry(topic, message, retries) {
    // 
    const delay = Math.pow(2, retries) * 1000;
    
    setTimeout(async () => {
      await this.producer.send(topic, [{
        value: {
          ...message,
          retries
        }
      }]);
    }, delay);
  }
  
  async sendToDLQ(topic, message, error) {
    const dlqTopic = `${topic}.dlq`;
    
    await this.producer.send(dlqTopic, [{
      value: {
        originalTopic: topic,
        originalMessage: message,
        error: error.message,
        stack: error.stack,
        timestamp: Date.now()
      }
    }]);
    
    console.error('Message sent to DLQ:', {
      topic: dlqTopic,
      message
    });
  }
  
  async processDLQ(dlqTopic, handler) {
    await this.consumer.subscribe([dlqTopic]);
    
    this.consumer.registerHandler(dlqTopic, async (message) => {
      // 
      await handler(message.value);
    });
  }
}
```

## 

```javascript
class OrderedMessageProcessor {
  constructor() {
    this.processing = new Map();
  }
  
  async process(message, handler) {
    const key = message.key;
    
    // key
    while (this.processing.has(key)) {
      await new Promise(resolve => setTimeout(resolve, 10));
    }
    
    this.processing.set(key, true);
    
    try {
      await handler(message);
    } finally {
      this.processing.delete(key);
    }
  }
}

// Kafka
class PartitionedProducer {
  async send(topic, messages) {
    // key
    await this.producer.send({
      topic,
      messages: messages.map(msg => ({
        key: msg.userId, // userId
        value: JSON.stringify(msg),
        partition: this.getPartition(msg.userId)
      }))
    });
  }
  
  getPartition(key) {
    // 
    const hash = this.hashCode(key);
    return hash % this.partitionCount;
  }
  
  hashCode(str) {
    let hash = 0;
    for (let i = 0; i < str.length; i++) {
      hash = ((hash << 5) - hash) + str.charCodeAt(i);
      hash = hash & hash;
    }
    return Math.abs(hash);
  }
}
```

## 

```javascript
class MessageQueueMonitor {
  async monitor() {
    // 1. 
    const lag = await this.getConsumerLag();
    if (lag > 10000) {
      await this.alert('High consumer lag', { lag });
    }
    
    // 2. 
    const consumeRate = await this.getConsumeRate();
    if (consumeRate < 100) {
      await this.alert('Low consume rate', { consumeRate });
    }
    
    // 3. 
    const errorRate = await this.getErrorRate();
    if (errorRate > 0.01) {
      await this.alert('High error rate', { errorRate });
    }
    
    // 4. 
    const dlqSize = await this.getDLQSize();
    if (dlqSize > 1000) {
      await this.alert('DLQ size too large', { dlqSize });
    }
  }
  
  async getConsumerLag() {
    // 
    const admin = this.kafka.admin();
    await admin.connect();
    
    const groups = await admin.fetchOffsets({
      groupId: 'my-group'
    });
    
    let totalLag = 0;
    for (const topic of groups) {
      for (const partition of topic.partitions) {
        totalLag += partition.lag;
      }
    }
    
    await admin.disconnect();
    return totalLag;
  }
}
```

## 


-  **** + 
-  **** + 
- ‚è∞ **** + 
-  **** + 
-  **** + 
-  **** + 

****

