---
title: 
sidebar_position: 9
---

## 

 Ollama  VLLM

|                  | Ollama                                    | VLLM                     |
| :-------------------- | :------------------------------------------ | :---------------------------------------------- |
| ****             | [https://ollama.com/](https://ollama.com/) | [https://vllm.ai/](https://vllm.ai/) |
| **GitHub**           | [https://github.com/ollama/ollama](https://github.com/ollama/ollama) | [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm) |
| ****         |  |  Transformer       |
| ****         |        | dynamic batching |
| ****             |                        |                |
| ****         | CPU/GPU                                    | GPU                                            |
| ****         |                      |                      |         |
| ****         |                      |                      |
| ****         |                            |                |
| ****         |            |          |
| ** Python ** |  Python  REST API  |  Python                  |

### ollama

1:ollamahuggingface

```bash showLineNumbers
ollama run hf.co/{username}/{reponame}:latest
```

2:
```bash showLineNumbers
ollama run hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:latest
```

3:
```bash showLineNumbers
ollama run hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF:Q8_0
```

### vllm

1:vllmhuggingface

```bash showLineNumbers
vllm serve NousResearch/Meta-Llama-3-8B-Instruct --dtype auto --api-key token-abc123
```

2vllm8
```bash showLineNumbers
vllm serve /home/ly/qwen2.5/Qwen2.5-32B-Instruct/ --tensor-parallel-size 8 --dtype auto --api-key 123 --gpu-memory-utilization 0.95 --max-model-len 27768  --enable-auto-tool-choice --tool-call-parser hermes --served-model-name Qwen2.5-32B-Instruct --kv-cache-dtype fp8_e5m2
```
3vllmGPU
```bash showLineNumbers
CUDA_VISIBLE_DEVICES=2 vllm serve /home/ly/qwen2.5/Qwen2-VL-7B-Instruct --dtype auto --tensor-parallel-size 1 auto --api-key 123 --gpu-memory-utilization 0.5 --max-model-len 5108  --enable-auto-tool-choice --tool-call-parser hermes --served-model-name Qwen2-VL-7B-Instruct --port 1236
```
:::info
Vllmollama

vllm80001236
:::
