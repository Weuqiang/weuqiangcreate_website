---
sidebar_position: 6
title: 
---

2

Computer Vision“”“”Machine Vision



|  |  |  |  |
|---------|---------|---------|---------|
| ** + ** |  | Vision TransformerCLIPGPT-4VLLaVA | ChatGPTGoogle Lens |
| ** + ** |  | SLAM | FSD |
| ** + ** |  | CT/MRI |  |
| ** + ** |  | NeRF3D Gaussian Splatting | iPhoneMatterport 3D |

OpenCV 



## 

opencvopensource computer vision

[opencv-python](https://github.com/opencv/opencv-python)

4<Highlight></Highlight>

`cv2` `pip uninstall` 

**a.**  WindowsmacOS GNU/Linux 

-  1 - `pip install opencv-python`
-  2 -  contrib/extra `pip install opencv-contrib-python` [OpenCV ](https://docs.opencv.org/master/)  contrib/extra 

**b.**  Docker GUI 

 Qt  GUI  X11  Docker  `cv2.imshow`  PyQt OpenCV

-  3 - `pip install opencv-python-headless`
-  4 -  contrib/extra `pip install opencv-contrib-python-headless` [OpenCV ](https://docs.opencv.org/master/)  contrib/extra 


OpenCv[OpenCV-Python](https://opencv-python-tutorials.readthedocs.io/)


## 

### 

`cv2.imread(filename, flags=cv2.IMREAD_COLOR) -> image`



- `filename`
- `flags`cv2.IMREAD_COLORBGR
    - cv2.IMREAD_COLORBGR1
    - cv2.IMREAD_GRAYSCALE0
    - cv2.IMREAD_UNCHANGEDalpha-1



- , <Highlight>, None</Highlight>
- <Highlight>CV2`utf-8`</Highlight>


- `shape`(height, width, channels) channels34RGBRGBAA1(height, width)
- `size`height * width * channels
- `dtype`
- `ndim`
- `itemsize`
- `nbytes`

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
print(img.shape) 
```

### 

`cv2.imwrite(filename, img, [params])`



- `filename`
- `img`()
- `params`<Highlight></Highlight>
    - cv2.IMWRITE_JPEG_QUALITYJPEG0-10095
    - cv2.IMWRITE_PNG_COMPRESSIONPNG0-93
    - cv2.IMWRITE_PXM_BINARYPPM/PGM/PBMFalse

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
cv2.imwrite('new_img.jpg',img, [cv2.IMWRITE_JPEG_QUALITY, 100])
```

### 

cv2.imshow`cv2.imshow(winname, img)`



- `winname`
- `img`

cv2.waitKey`cv2.waitKey([delay]) -> retval`



- `delay`0



- ASCII<Highlight></Highlight>-1


- <Highlight></Highlight>
- <Highlight></Highlight>

`cv2.imshow``cv2.waitKey`

`destroyWindow``destroyAllWindows`

destroyWindow`cv2.destroyWindow(winname)`

- `winname`

destroyAllWindows`cv2.destroyAllWindows()`

```python showLineNumbers
import cv2
path= "10.jpg"
img = cv2.imread(path)
# , img: , 'Image': 
# 
cv2.imshow('Image', img)
# 0
# ASCII
key = cv2.waitKey(0)    
# q
if key == ord('q'):
    # 
    cv2.destroyWindow('Image') 
# 
cv2.destroyAllWindows()
```


## 

### 

```python showLineNumbers
# cv2.VideoCapture()

# :
# 0:
# 1:

# :1.mp4

# : http://192.168.1.100:8080

cap = cv2.VideoCapture(0) # 
if not cap.isOpened():
    print("Error: Could not open video.")
    cap.release() # 
while True:
    ret,frame = cap.read() # 
    # ret:True/False
    # frame:numpy
    if not ret:
        print("Error: Could not read frame.")
        break
    cv2.imshow("frame",frame) # 
    if cv2.waitKey(1) == ord('q'): # q
        break
cap.release() # 
cv2.destroyAllWindows() # 
```

### 

`cv2.VideoWriter(filename, fourcc, fps, frameSize)`



- filename
- fourcc
- fps
- frameSize

```python showLineNumbers {16,18,31,35}
import cv2
import numpy as np
# cv2.VideoCapture()

# :
# 0:
# 1:

# :1.mp4

# :rtsp://192.168.1.100:8554/test  http://192.168.1.100:8080

cap = cv2.VideoCapture(0) # 

# 
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
# 
out = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640,480))


if not cap.isOpened():
    print("Error: Could not open video.")
    cap.release() # 
while True:
    ret,frame = cap.read() # 
    # ret:True/False
    # frame:numpy
    if not ret:
        print("Error: Could not read frame.")
        break
    out.write(frame) # 
    cv2.imshow("frame",frame) # 
    if cv2.waitKey(1) == ord('q'): # q
        break
out.release() # 
cap.release() # 
cv2.destroyAllWindows() # 
```

## 

### 

- `line``cv2.line(img, pt1, pt2, color, thickness, lineType, shift)`
- `rectangle``cv2.rectangle(img, pt1, pt2, color, thickness, lineType, shift)`



- `img`
- `pt1`
- `pt2`
- `color`
- `thickness`
- `lineType`
- `shift`01shift=2
- <Highlight>`pt1``pt2`</Highlight>

### 

- `circle``cv2.circle(img, center, radius, color, thickness, lineType, shift)`
- `ellipse``cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color, thickness, lineType, shift)`



- `img`
- `center`
- `radius`
- `axes`
- `angle`
- `startAngle`
- `endAngle`
- `color`
- `thickness`
- `lineType`
- `shift`01shift=2

### 

polylines`cv2.polylines(img, pts, isClosed, color, thickness, lineType, shift)`



- `img`
- `pts`
- `isClosed`
- `color`
- `thickness`
- `lineType`
- `shift`01shift=2

```python showLineNumbers
# 
import cv2
# 
img = cv2.imread('10.jpg')
# 
# img: , (100, 100): , (200, 200): , (0, 0, 255): , 2: 
cv2.line(img, (100, 100), (200, 200), (0, 0, 255), 2)
# 
# img: , (100, 100): , (200, 200): , (0, 0, 255): , 2: 
cv2.rectangle(img, (100, 100), (200, 200), (0, 0, 255), 2)
# 
# img: , (150, 150): , 50: , (0, 0, 255): , 2: 
cv2.circle(img, (150, 150), 50, (0, 0, 255), 2)
# 
# img: , [pts]: , True: , (0, 0, 255): , 2: 
pts = np.array([[100, 100], [200, 100], [200, 200], [100, 200]])
cv2.polylines(img, [pts], True, (0, 0, 255), 2)
# 
# img: , (150, 150): , (100, 50): , 0: , 0: , 360: , (0, 0, 255): , 2: 
cv2.ellipse(img, (150, 150), (100, 50), 0, 0, 360, (0, 0, 255), 2)
# 
cv2.imshow('Image', img)
# 
cv2.waitKey(0)
# 
cv2.destroyAllWindows()
```

### 

`cv2.putText(img, text, org, fontFace, fontScale, color, thickness, lineType, bottomLeftOrigin)`



- `img`
- `text`
- `org`
- `fontFace`
- `fontScale`10~10
- `color`
- `thickness`
- `lineType`
- `bottomLeftOrigin`



```python showLineNumbers
import cv2

# 
img = cv2.imread('10.jpg')
# Hello, World! (100, 100)cv2.FONT_HERSHEY_SIMPLEX12
cv2.putText(img, 'Hello, World!', (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
# 
cv2.imshow('Image', img)
# 1
cv2.waitKey(1000)
# 
cv2.destroyAllWindows()
```

### PIL

cv2PIL



```python showLineNumbers
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
# 
img = Image.open('imgs/img/10.jpg')  # 
# Windows
font_path = "simhei.ttf"  # 
font_size = 60
font = ImageFont.truetype(font_path, font_size)
# 
text = ""
# 
draw = ImageDraw.Draw(img)
# 
text_width, text_height = draw.textsize(text, font=font)
# 
img_width, img_height = img.size
x = (img_width - text_width) // 2
y = (img_height - text_height) // 2
# 
draw.text((x, y), text, font=font, fill=(255, 0, 0))  # 
# 
img.show()
# img.save('output.jpg')
```

## 



### 

```python showLineNumbers {12,23}
import cv2
import numpy as np
path = "xxx.bmp"
def draw_add(path):
    img = cv2.imread(path)
    img_height, img_width = img.shape[:2]
    # mask_img
    mask_img = np.zeros((img_height, img_width, 3), dtype=np.uint8) + 255
    # mask_imgShowcase
    cv2.putText(mask_img, "Showcase", (img_width//4, img_height//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 5)
    # mask_imgimg
    img3 = cv2.add(img, mask_img)
    cv2.imwrite(f"add_{path}", img3)

def draw_subtract(path):
    img = cv2.imread(path)
    img_height, img_width = img.shape[:2]
    # mask_img
    mask_img = np.zeros((img_height, img_width, 3), dtype=np.uint8) + 255
    # mask_img
    cv2.circle(mask_img, (img_width//2, img_height//2), int(min(img_width, img_height)*0.45), (0, 0, 0), -1)
    # mask_imgimg
    img3 = cv2.subtract(img, mask_img)
    cv2.imwrite(f"subtract_{path}", img3)

draw_add(path)
draw_subtract(path)
```

:::info

cv2.addWeighted

`cv2.addWeighted(src1, alpha, src2, beta, gamma) -> dst`



- `src1`1
- `alpha`10-1
- `src2`2
- `beta`20-1
- `gamma`0

12111

```python showLineNumbers
import cv2
import numpy as np

img1 = cv2.imread("green.png")
img2 = cv2.imread("red.png")

img3 = cv2.addWeighted(img1, 1, img2, 1,0)

cv2.imshow("img4", img3)
cv2.waitKey(0)
```
:::

## 

### 

`cv2.resize(src, dsize, fx, fy, interpolation) -> dst`



- `src`
- `dsize`Nonefxfy(width, height)
- `fx`
- `fy`
- `interpolation`cv2.INTER_LINEAR:


resize

```python showLineNumbers
import cv2
import numpy as np

img1 = cv2.imread("xxx.png")
# 
img2 = cv2.resize(img1, (100, 100))
# 
img2 = cv2.resize(img1, dsize = None, fx = 0.5, fy = 0.5)
```

### 

`cv2.split(img) -> list`

`cv2.merge(list) -> img`



- `img`



- `list`

```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
b, g, r = cv2.split(img)

img2 = cv2.merge([b, g, r])

cv2.imshow("img", img)
cv2.imshow("img2", img2)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.flip(src, flipCode) -> dst`



- `src`
- `flipCode`
  - 0
  - 1
  - -1



- 

```python showLineNumbers
import cv2

img = cv2.imread("xxx.png")

# 
img_vertical = cv2.flip(img, 0)

# 
img_horizontal = cv2.flip(img, 1)

# 
img_both = cv2.flip(img, -1)

cv2.imshow("Original", img)
cv2.imshow("Vertical Flip", img_vertical)
cv2.imshow("Horizontal Flip", img_horizontal)
cv2.imshow("Both Flip", img_both)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

NumPyOpenCV

`img[start_y:end_y, start_x:end_x]`



- `start_y`y
- `end_y`y
- `start_x`x
- `end_x`x

<Highlight>yx</Highlight>

```python showLineNumbers
import cv2

img = cv2.imread("xxx.png")

# 
height, width = img.shape[:2]

# (100,100)(300,300)
cropped_img = img[100:300, 100:300]

# 
top_half = img[0:height//2, 0:width]

# 
bottom_right = img[height//2:height, width//2:width]

cv2.imshow("Original", img)
cv2.imshow("Cropped", cropped_img)
cv2.imshow("Top Half", top_half)
cv2.imshow("Bottom Right", bottom_right)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.warpAffine(src, M, dsize, flags, borderMode, borderValue) -> dst`



- `src`
- `M`2×3
- `dsize`(width, height)
- `flags`cv2.INTER_LINEAR
- `borderMode`cv2.BORDER_CONSTANT
- `borderValue`0

`[[1, 0, dx], [0, 1, dy]]`dxxdyy

```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
height, width = img.shape[:2]

# 10050
M = np.float32([[1, 0, 100], [0, 1, 50]])
translated_img = cv2.warpAffine(img, M, (width, height))

# 5030
M2 = np.float32([[1, 0, -50], [0, 1, -30]])
translated_img2 = cv2.warpAffine(img, M2, (width, height))

cv2.imshow("Original", img)
cv2.imshow("Translated Right-Down", translated_img)
cv2.imshow("Translated Left-Up", translated_img2)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.getRotationMatrix2D(center, angle, scale) -> M`



- `center`(x, y)
- `angle`
- `scale`1.0

`cv2.warpAffine`

```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
height, width = img.shape[:2]

# 45
center = (width // 2, height // 2)
M = cv2.getRotationMatrix2D(center, 45, 1.0)
rotated_img = cv2.warpAffine(img, M, (width, height))

# 301.5
M2 = cv2.getRotationMatrix2D(center, -30, 1.5)
rotated_scaled_img = cv2.warpAffine(img, M2, (width, height))

cv2.imshow("Original", img)
cv2.imshow("Rotated 45°", rotated_img)
cv2.imshow("Rotated -30° Scaled 1.5x", rotated_scaled_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.getAffineTransform(src, dst) -> M`



- `src`numpy
- `dst`numpy



- 2×3



```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
height, width = img.shape[:2]

# 
pts1 = np.float32([[0, 0], [width-1, 0], [0, height-1]])

# 
pts2 = np.float32([[0, height*0.33], [width*0.85, height*0.25], [width*0.15, height*0.7]])

# 
M = cv2.getAffineTransform(pts1, pts2)

# 
affine_img = cv2.warpAffine(img, M, (width, height))

# 
cv2.circle(img, (0, 0), 5, (255, 0, 0), -1)
cv2.circle(img, (width-1, 0), 5, (255, 0, 0), -1)
cv2.circle(img, (0, height-1), 5, (255, 0, 0), -1)

cv2.imshow("Original", img)
cv2.imshow("Affine Transform", affine_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.getPerspectiveTransform(src, dst) -> M`

`cv2.warpPerspective(src, M, dsize, flags, borderMode, borderValue) -> dst`



- `src`numpy
- `dst`numpy
- `M`3×3
- `dsize`(width, height)



```python showLineNumbers
import cv2
import numpy as np

img = cv2.imread("xxx.png")
height, width = img.shape[:2]

# 
pts1 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])

# 
pts2 = np.float32([[0, 0], [width, 0], [width*0.3, height], [width*0.7, height]])

# 
M = cv2.getPerspectiveTransform(pts1, pts2)

# 
perspective_img = cv2.warpPerspective(img, M, (width, height))

cv2.imshow("Original", img)
cv2.imshow("Perspective Transform", perspective_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 

`cv2.copyMakeBorder(src, top, bottom, left, right, borderType, value) -> dst`



- `src`
- `top`
- `bottom`
- `left`
- `right`
- `borderType`
  - cv2.BORDER_CONSTANTvalue
  - cv2.BORDER_REFLECT
  - cv2.BORDER_REPLICATE
  - cv2.BORDER_WRAP
- `value`borderTypeBORDER_CONSTANT

```python showLineNumbers
import cv2

img = cv2.imread("xxx.png")

# 
border_constant = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_CONSTANT, value=(0, 0, 0))

# 
border_red = cv2.copyMakeBorder(img, 30, 30, 30, 30, cv2.BORDER_CONSTANT, value=(0, 0, 255))

# 
border_reflect = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_REFLECT)

# 
border_replicate = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_REPLICATE)

# 
border_wrap = cv2.copyMakeBorder(img, 50, 50, 50, 50, cv2.BORDER_WRAP)

cv2.imshow("Original", img)
cv2.imshow("Constant Border (Black)", border_constant)
cv2.imshow("Constant Border (Red)", border_red)
cv2.imshow("Reflect Border", border_reflect)
cv2.imshow("Replicate Border", border_replicate)
cv2.imshow("Wrap Border", border_wrap)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## 

:::info
HSV

HSVRGBHSV
- H: 0-180
- S: 0-255
- V: 0-255
:::


:::info
24

0~255828

 R G B  8 + 8 + 8 = 24 



 255 * 255 * 255 

<HoverText text="16bit" explanation="5 + 6 + 5"/>

:::

### 



10-255

```python showLineNumbers
import numpy as np
import cv2

# 1 
img = cv2.imread("xxx.png")
B,G,R = cv2.split(img)
gray = R*0.299 + G*0.587 + B*0.114
gray = gray.astype(np.uint8)

# 2 ()
gray = cv2.imread("xxx.png",0)

# 3 
img = cv2.imread("xxx.png")
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)


cv2.imshow("gray",gray)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 



101


|  |  |  |  |  |  |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **** | “” |  127 127255 1270 1 0 | ****  | ****  127 | **** |
| **** | “” |  | ****  | ****  | ******** |
| **** | “” |  | ****  | ****  | ************ |
| **** | “” |  |  |  |  |
| **Otsu's ** | “” |  | ****  | ****  | ******** |

:::info


0255




:::

:::info
Normalization

,[0,1][-1,1]


:::


```python showLineNumbers
import cv2
import numpy as np
import matplotlib.pyplot as plt

#  'xxx.bmp' 
IMAGE_PATH = 'xxx.bmp'

def show_all_images(original_img, binary_images, titles):
    """
     matplotlib 
    :param original_img: 
    :param binary_images: 
    :param titles: 
    """
    num_images = len(binary_images) + 1  # +1 for original image
    
    #  ()
    cols = int(np.ceil(np.sqrt(num_images)))
    rows = int(np.ceil(num_images / cols))
    
    fig, axes = plt.subplots(rows, cols, figsize=(15, 10))
    fig.suptitle('Image Thresholding Comparison', fontsize=16)
    
    # axes
    if num_images == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    
    # 
    axes[0].imshow(original_img, cmap='gray')
    axes[0].set_title('Original Grayscale Image')
    axes[0].axis('off')
    
    # 
    for i, (binary_img, title) in enumerate(zip(binary_images, titles)):
        axes[i + 1].imshow(binary_img, cmap='gray')
        axes[i + 1].set_title(title)
        axes[i + 1].axis('off')
    
    # 
    for i in range(num_images, len(axes)):
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.show()

def get_binary_image(img, method, *args, **kwargs):
    """
    
    :param img: 
    :param method:  'fixed', 'global_mean', 'adaptive_mean', 'adaptive_gaussian', 'otsu'
    """
    if method == 'fixed':
        # 
        _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)
    elif method == 'global_mean':
        # 
        _, binary = cv2.threshold(img, img.mean(), 255, cv2.THRESH_BINARY)
    elif method == 'adaptive_mean':
        # 
        binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                       cv2.THRESH_BINARY, 11, 2)
    elif method == 'adaptive_gaussian':
        # 
        binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                       cv2.THRESH_BINARY, 11, 2)
    elif method == 'otsu':
        # Otsu's 
        _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        raise ValueError("Invalid method. Choose from 'fixed', 'global_mean', 'adaptive_mean', 'adaptive_gaussian', 'otsu'")

    #  0/255  0/1
    return (binary / 255).astype(int)

def main():
    """"""
    
    # 
    img = cv2.imread(IMAGE_PATH, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"Error: Could not read image at {IMAGE_PATH}")
        return

    # 
    methods = [
        ('fixed', 'Fixed Thresholding (127)'),
        ('global_mean', 'Global Mean Thresholding'),
        ('adaptive_mean', 'Adaptive Mean Thresholding'),
        ('adaptive_gaussian', 'Adaptive Gaussian Thresholding'),
        ('otsu', "Otsu's Thresholding")
    ]
    
    # 
    binary_images = []
    titles = []
    for method, title in methods:
        binary_image = get_binary_image(img, method)
        binary_images.append(binary_image)
        titles.append(title)
    
    # 
    show_all_images(img, binary_images, titles)

if __name__ == "__main__":
    main()
```


## 

### 

`cv2.dilate(img,kernel,iterations=5)`

`cv2.erode(img,kernel,iterations=5)`



- img
- kernel
- iterations






```python showLineNumbers
import cv2
import numpy as np
img = cv2.imread("dt2.png")
# 
kernel = np.ones((3,3),np.uint8)
# 
erode = cv2.erode(img,kernel,iterations=5)
# 
dilate = cv2.dilate(img,kernel,iterations=5)
cv2.imshow("img",img)
cv2.imshow("dilate",dilate)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

:::info
- : 
- : 
- :  - 
- :  - 
- :  - 
:::


### 





- `cv2.GaussianBlur`
- `cv2.medianBlur`
- Box`cv2.boxFilter`
- `cv2.blur`Box
- `cv2.bilateralFilter`
- `cv2.filter2D`

```python showLineNumbers
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties
import cv2

# 
# (windows)
font_path = r'C:\Windows\Fonts\simhei.ttf'  
# mac
# font_path = '/System/Library/Fonts/STHeiti Light.ttc' 
font_prop = FontProperties(fname=font_path)

# 
image = np.array(cv2.imread('xxx.bmp',cv2.IMREAD_GRAYSCALE))

# 
kernels = {
    '': np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]]),
    '': np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]),
    'Sobel': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),
    'Sobel': np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]),
    '': np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),
    '': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),
    '3x3': np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16,
    '': np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]),
    'Box': np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]]) / 9
    '': np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) / 9,
}

# NumPy
def convolve2d(image, kernel):
    # 
    i_height, i_width = image.shape
    k_height, k_width = kernel.shape
    
    # 
    o_height = i_height - k_height + 1
    o_width = i_width - k_width + 1
    
    # 
    output = np.zeros((o_height, o_width))
    
    # 
    for y in range(o_height):
        for x in range(o_width):
            # 
            region = image[y:y+k_height, x:x+k_width]
            # 
            output[y, x] = np.sum(region * kernel)
    
    return output

# 
results = {}
for name, kernel in kernels.items():
    # 
    if kernel.shape[0] == 5:  # 5x5
        pad_width = 2
    else:  # 3x3
        pad_width = 1
    
    padded_image = np.pad(image, pad_width, mode='constant')
    filtered_image = convolve2d(padded_image, kernel)
    
    # 
    filtered_image = np.clip(filtered_image, 0, 255).astype(np.uint8)
    results[name] = filtered_image

# 
plt.figure(figsize=(15, 8))
for i, (name, result) in enumerate(results.items()):
    plt.subplot(3, 4, i + 1)
    plt.imshow(result, cmap='gray')
    plt.title(name, fontproperties=font_prop)
    plt.axis('off')

plt.tight_layout()
plt.show()
```
## 

### cv2.Canny
### cv2.findContours
### cv2.contourAreacv2.arcLength

```python showLineNumbers
import cv2
img = cv2.imread("xxx.png")
# 
# 
#  >  → 
#  <  <  → 
#  <  → 
canny = cv2.Canny(img,threshold1=100,threshold2=200)

# 
contours,hierarchy = cv2.findContours(canny,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

# 
area = cv2.contourArea(contours[0])
# 
perimeter = cv2.arcLength(contours[0],True)

max_area = max([cv2.contourArea(contour) for contour in contours])
for contour in contours:
    if cv2.contourArea(contour) >= max_area:
        # 
        cv2.drawContours(img,contour,-1,(0,0,255),1)

cv2.imshow("img",img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## 

Opencv

[OpenCV Bootcamp](https://courses.opencv.org/courses/course-v1:OpenCV+Bootcamp+CV0/course/)

### 



```python showLineNumbers
"""
Image Registration




https://www.dropbox.com/s/zuwnn6rqe0f4zgh/opencv_bootcamp_assets_NB8.zip?dl=1


1. 
2. 
3. ORB
4. 
5. 
6. 
7. 
"""

# 
import cv2              # OpenCV
import numpy as np      # 
import matplotlib.pyplot as plt  # 

# 
refFilename = "form.jpg"
print("Reading reference image:", refFilename)
im1 = cv2.imread(refFilename, cv2.IMREAD_COLOR)  # 
# BGRRGB
# OpenCVBGRmatplotlibRGB
im1 = cv2.cvtColor(im1, cv2.COLOR_BGR2RGB)

# 
imFilename = "scanned-form.jpg"
print("Reading image to align:", imFilename)
im2 = cv2.imread(imFilename, cv2.IMREAD_COLOR)  # 
# BGRRGB
im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)

# 
# 
im1_gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)
im2_gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)

# ORB
MAX_NUM_FEATURES = 500  # 500
# ORB (Oriented FAST and Rotated BRIEF) 
# ""
orb = cv2.ORB_create(MAX_NUM_FEATURES)
# 
# keypoints
# descriptors""
keypoints1, descriptors1 = orb.detectAndCompute(im1_gray, None)
keypoints2, descriptors2 = orb.detectAndCompute(im2_gray, None)

# 
print(descriptors1[0])
"""
ORB32256


""""
""
""

[  2 233  53 155 108 141 186 164 142 121  81  73 172 220  44  73 134  91
  31  71 194  48  74 245 164  24  74 242  28  27 129 217]
"""

# 
# color=(255, 0, 0)
# DRAW_RICH_KEYPOINTS
im1_display = cv2.drawKeypoints(im1, keypoints1, outImage=np.array([]), 
                                color=(255, 0, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

im2_display = cv2.drawKeypoints(im2, keypoints2, outImage=np.array([]), 
                                color=(255, 0, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

# 
# cv2.imshow("im1_display", im1_display)
# cv2.imshow("im2_display", im2_display)
# cv2.waitKey(0)
# cv2.destroyAllWindows()

# 
# 
# HAMMING
matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)
print(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE)
print(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)


# 
matches = list(matcher.match(descriptors1, descriptors2, None))

# 
matches.sort(key=lambda x: x.distance, reverse=False)

# 10%
# 
numGoodMatches = int(len(matches) * 0.1)
matches = matches[:numGoodMatches]

# 
# 
points1 = np.zeros((len(matches), 2), dtype=np.float32)  # 
points2 = np.zeros((len(matches), 2), dtype=np.float32)  # 

# (x,y)
for i, match in enumerate(matches):
    points1[i, :] = keypoints1[match.queryIdx].pt    # 
    points2[i, :] = keypoints2[match.trainIdx].pt    # 

# Homography
# 3x3
# 
# RANSAC
h, mask = cv2.findHomography(points2, points1, cv2.RANSAC)

# 
height, width, channels = im1.shape  # 
# 
# warpPerspective
im2_reg = cv2.warpPerspective(im2, h, (width, height))

# 
cv2.imwrite("im2_reg.jpg", im2_reg)


[
  (0,0),
  (223,232),
  (131,391),
  (383,390)
]
```

### HDR

HDR

HDR 

```python showLineNumbers
"""

https://www.dropbox.com/s/qa1hsyxt66pvj02/opencv_bootcamp_assets_NB10.zip?dl=1
"""

import os
import cv2
import numpy as np

def readImagesAndTimes():
    # 
    filenames = ["img_0.033.jpg", "img_0.25.jpg", "img_2.5.jpg", "img_15.jpg"]

    # List of exposure times
    times = np.array([1 / 30.0, 0.25, 2.5, 15.0], dtype=np.float32)

    # Read images
    images = []
    for filename in filenames:
        im = cv2.imread(filename)
        images.append(im)

    return images, times

# 

images, times = readImagesAndTimes()

# Align Images
alignMTB = cv2.createAlignMTB()
alignMTB.process(images, images)

# 
calibrateDebevec = cv2.createCalibrateDebevec()
responseDebevec = calibrateDebevec.process(images, times)

#  HDR 
mergeDebevec = cv2.createMergeDebevec()
hdrDebevec = mergeDebevec.process(images, times, responseDebevec)

# 

# 1
tonemapDrago = cv2.createTonemapDrago(1.0, 0.7)
ldrDrago = tonemapDrago.process(hdrDebevec)
ldrDrago = 3 * ldrDrago

# 2
tonemapReinhard = cv2.createTonemapReinhard(1.5, 0, 0, 0)
ldrReinhard = tonemapReinhard.process(hdrDebevec)

# 3
tonemapMantiuk = cv2.createTonemapMantiuk(2.2, 0.85, 1.2)
ldrMantiuk = tonemapMantiuk.process(hdrDebevec)
ldrMantiuk = 3 * ldrMantiuk

# Saving image
cv2.imwrite("ldr-Drago.jpg", 255*ldrDrago)
cv2.imwrite("ldr-Reinhard.jpg", 255*ldrReinhard)
cv2.imwrite("ldr-Mantiuk.jpg", 255*ldrMantiuk)
```

### 

VR/AR



```python showLineNumbers
"""

https://www.dropbox.com/s/0o5yqql1ynx31bi/opencv_bootcamp_assets_NB9.zip?dl=1
"""
import os
import cv2
import math
import glob
import numpy as np


def find_largest_rectangle(mask):
    """
    
    
    """
    def largest_rectangle_in_histogram(heights):
        stack = []
        max_area = 0
        best_rect = (0, 0, 0, 0)  # (x, y, w, h)
        
        for i, h in enumerate(heights):
            start = i
            while stack and stack[-1][1] > h:
                index, height = stack.pop()
                area = height * (i - index)
                if area > max_area:
                    max_area = area
                    best_rect = (index, 0, i - index, height)
                start = index
            stack.append((start, h))
        
        # 
        for index, height in stack:
            area = height * (len(heights) - index)
            if area > max_area:
                max_area = area
                best_rect = (index, 0, len(heights) - index, height)
        
        return best_rect, max_area
    
    # 
    if len(mask.shape) == 3:
        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
    
    height, width = mask.shape
    
    # 
    histogram = np.zeros(width, dtype=np.int32)
    max_area = 0
    best_rect = (0, 0, 0, 0)
    
    for row in range(height):
        # 
        for col in range(width):
            if mask[row, col] > 0:  # 
                histogram[col] += 1
            else:  # 
                histogram[col] = 0
        
        # 
        rect, area = largest_rectangle_in_histogram(histogram)
        if area > max_area:
            max_area = area
            best_rect = (rect[0], row - rect[3] + 1, rect[2], rect[3])
    
    return best_rect


def create_valid_mask(image, threshold=10):
    """
    
    """
    # 
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # 2550
    mask = np.where(gray > threshold, 255, 0).astype(np.uint8)
    
    # 
    kernel = np.ones((5, 5), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # 
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)   # 
    
    return mask


def smart_crop_panorama(image, threshold=10, padding=5):
    """
    
    """
    print(f": {image.shape}")
    
    # 
    mask = create_valid_mask(image, threshold)
    
    # 
    x, y, w, h = find_largest_rectangle(mask)
    
    # 
    x = max(0, x + padding)
    y = max(0, y + padding)
    w = min(image.shape[1] - x, w - 2 * padding)
    h = min(image.shape[0] - y, h - 2 * padding)
    
    if w <= 0 or h <= 0:
        return image
    cropped_image = image[y:y+h, x:x+w]
    return cropped_image


# 
# boat
imagefiles = glob.glob(f"boat{os.sep}*")
imagefiles.sort()

images = []
for filename in imagefiles:
    img = cv2.imread(filename)
    images.append(img)

stitcher = cv2.Stitcher_create()
status, result = stitcher.stitch(images)

if status == cv2.Stitcher_OK:
    cv2.imwrite("result_raw.png", result)
    cropped_result = smart_crop_panorama(result, threshold=10, padding=5)
    cv2.imwrite("result.png", cropped_result)
```


### 



```python showLineNumbers
"""

https://www.dropbox.com/s/ld535c8e0vueq6x/opencv_bootcamp_assets_NB11.zip?dl=1
"""
import os
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt

from zipfile import ZipFile
from urllib.request import urlretrieve

from IPython.display import HTML
from matplotlib.animation import FuncAnimation

from IPython.display import YouTubeVideo, display, HTML
from base64 import b64encode
video_input_file_name = "race_car.mp4"


def drawRectangle(frame, bbox):
    p1 = (int(bbox[0]), int(bbox[1]))
    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))
    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)


def displayRectangle(frame, bbox):
    plt.figure(figsize=(20, 10))
    frameCopy = frame.copy()
    drawRectangle(frameCopy, bbox)
    frameCopy = cv2.cvtColor(frameCopy, cv2.COLOR_RGB2BGR)
    plt.imshow(frameCopy)
    plt.axis("off")


def drawText(frame, txt, location, color=(50, 170, 50)):
    cv2.putText(frame, txt, location, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3)

# Set up tracker
tracker_types = [
    "BOOSTING",
    "MIL",
    "KCF",
    "CSRT",
    "TLD",
    "MEDIANFLOW",
    "GOTURN",
    "MOSSE",
]

# Change the index to change the tracker type
tracker_type = tracker_types[2]

if tracker_type == "BOOSTING":
    tracker = cv2.legacy.TrackerBoosting.create()
elif tracker_type == "MIL":
    tracker = cv2.legacy.TrackerMIL.create()
elif tracker_type == "KCF":
    tracker = cv2.TrackerKCF.create()
elif tracker_type == "CSRT":
    tracker = cv2.TrackerCSRT.create()
elif tracker_type == "TLD":
    tracker = cv2.legacy.TrackerTLD.create()
elif tracker_type == "MEDIANFLOW":
    tracker = cv2.legacy.TrackerMedianFlow.create()
elif tracker_type == "GOTURN":
    tracker = cv2.TrackerGOTURN.create()
else:
    tracker = cv2.legacy.TrackerMOSSE.create()

# Read video
video = cv2.VideoCapture(video_input_file_name)
ok, frame = video.read()

# Exit if video not opened
if not video.isOpened():
    print("Could not open video")
    sys.exit()
else:
    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))

video_output_file_name = "race_car-" + tracker_type + ".mp4"
video_out = cv2.VideoWriter(video_output_file_name, cv2.VideoWriter_fourcc(*"XVID"), 10, (width, height))


# Define a bounding box
bbox = (1300, 405, 160, 120)
# bbox = cv2.selectROI(frame, False)
# print(bbox)
displayRectangle(frame, bbox)


ok = tracker.init(frame, bbox)

while True:
    ok, frame = video.read()

    if not ok:
        break

    # Start timer
    timer = cv2.getTickCount()

    # Update tracker
    ok, bbox = tracker.update(frame)

    # Calculate Frames per second (FPS)
    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)

    # Draw bounding box
    if ok:
        drawRectangle(frame, bbox)
    else:
        drawText(frame, "Tracking failure detected", (80, 140), (0, 0, 255))

    # Display Info
    drawText(frame, tracker_type + " Tracker", (80, 60))
    drawText(frame, "FPS : " + str(int(fps)), (80, 100))

    # Write frame to video
    video_out.write(frame)

video.release()
video_out.release()


```

### 

#### 




- 
- 
- 

CID = 0

- `dataSet`  


- `haarcascade_frontalface_default.xml`  `everthing`  


```python showLineNumbers
import os
import cv2
import numpy as np

# IDwindow0linux1AIBox9~13
CID = 0


# ,ididid
def get_face(id="1"):
    faceDetect = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
    cam = cv2.VideoCapture(CID)
    sampleNum = 0
    while True:
        ret, img = cam.read()
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = faceDetect.detectMultiScale(gray, 1.3, 5)
        for x, y, w, h in faces:
            sampleNum = sampleNum + 1
            cv2.imwrite(
                "dataSet/User." + str(id) + "." + str(sampleNum) + ".png",
                gray[y : y + h, x : x + w],
            )
            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)
            cv2.waitKey(100)
        cv2.imshow("Face", img)
        cv2.waitKey(1)
        if sampleNum > 20:
            break
    cam.release()
    cv2.destroyAllWindows()


# 
def trainer_face(path="dataSet"):
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    imagePaths = [os.path.join(path, f) for f in os.listdir(path)]
    faces = []
    IDs = []
    for imagePath in imagePaths:
        faceImg = cv2.imread(imagePath,0)
        faceNp = np.array(faceImg, "uint8")
        ID = int(os.path.split(imagePath)[-1].split(".")[1])
        faces.append(faceNp)
        IDs.append(ID)
        cv2.imshow("training", faceNp)
        cv2.waitKey(10)
    recognizer.train(faces, np.array(IDs))
    recognizer.save("trainningData.yml")
    cv2.destroyAllWindows()


# 
def recognizer(labels={"p1": 1, "p2": 2}):
    # 
    face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")

    # 
    recognizer = cv2.face.LBPHFaceRecognizer_create()
    recognizer.read("trainningData.yml")

    # 
    cap = cv2.VideoCapture(CID)
    font = cv2.FONT_HERSHEY_COMPLEX_SMALL
    while True:
        ret, frame = cap.read()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 
        faces = face_cascade.detectMultiScale(
            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)
        )

        rgb_color = (0, 0, 0)
        for x, y, w, h in faces:
            # 
            id, confidence = recognizer.predict(gray[y : y + h, x : x + w])
            person = ""
            if confidence < 100:
                for name, label in labels.items():
                    if label == id:
                        person = name
                        break
                confidence = int(100 - confidence)
                if int(confidence) > 40:
                    rgb_color = (0, 255, 0)  # 
                    person = f"{person}: {confidence}%"

                elif 0 < int(confidence) < 40:
                    rgb_color = (255, 0, 0)  # 
                    person = "unkonw"
            cv2.putText(
                frame,
                str(person),
                (x, y + h),
                cv2.FONT_HERSHEY_SIMPLEX,
                1,
                (0, 0, 255),
                2,
            )  # cv2.putText()
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.imshow("Face Recognition", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    get_face(id="1")
    trainer_face(path="dataSet")
    recognizer()
```

#### 





VR/AR



